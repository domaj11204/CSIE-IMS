Active code page: 437
Active code page: 437

(base) E:\Research\extension\chrome-extension>chcp 65001
Active code page: 65001

(base) E:\Research\extension\chrome-extension>[03:11:05]conda activate serer

EnvironmentNameNotFound: Could not find conda environment: serer
You can list all discoverable environments with `conda info --envs`.



(base) E:\Research\extension\chrome-extension>[03:11:14]conda activate server

(server) E:\Research\extension\chrome-extension>[03:13:01]exit
Active code page: 437
Active code page: 437

(base) E:\Research\extension\chrome-extension>chcp 65001
Active code page: 65001

(base) E:\Research\extension\chrome-extension>Active code page: 437
Active code page: 437

(base) E:\Research\extension\chrome-extension>chcp 65001
Active code page: 65001

(base) E:\Research\extension\chrome-extension>[03:16:26]conda activate sever

EnvironmentNameNotFound: Could not find conda environment: sever
You can list all discoverable environments with `conda info --envs`.



(base) E:\Research\extension\chrome-extension>[03:16:36]conda activate server

(server) E:\Research\extension\chrome-extension>[03:16:59]eActive code page: 437
Active code page: 437

(base) E:\Research\extension\chrome-extension>chcp 65001
Active code page: 65001

(base) E:\Research\extension\chrome-extension>[03:17:39]conda activate server

(server) E:\Research\extension\chrome-extension>[03:17:48]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 61, in <module>
    rag_obj = rag()
              ^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 8, in __init__
    self.config = read_config()["rag"]
                  ~~~~~~~~~~~~~^^^^^^^
KeyError: 'rag'

(server) E:\Research\extension\chrome-extension>[03:17:55]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 62, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 20, in query
    self.embedded()
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 42, in embedded
    from .embedded import embedded
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 10, in <module>
    class MyEmbeddedings:
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 17, in MyEmbeddedings
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
                                     ^^^^
NameError: name 'List' is not defined. Did you mean: 'list'?

(server) E:\Research\extension\chrome-extension>[03:18:41]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 62, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 20, in query
    self.embedded()
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 45, in embedded
    self.embedded_db_path = embedded_obj.embedded_once()
                            ^^^^^^^^^^^^
NameError: name 'embedded_obj' is not defined
嵌入模型載入中...
嵌入模型載入完成
{'error': 'No query parameter provided'}

(server) E:\Research\extension\chrome-extension>[03:22:22]exiActive code page: 437
Active code page: 437

(base) E:\Research\extension\chrome-extension>chcp 65001
Active code page: 65001

(base) E:\Research\extension\chrome-extension>[03:22:43]conda activate serve

EnvironmentNameNotFound: Could not find conda environment: serve
You can list all discoverable environments with `conda info --envs`.



(base) E:\Research\extension\chrome-extension>[03:22:48]conda activate server

(server) E:\Research\extension\chrome-extension>[03:22:53]pp
'pp' is not recognized as an internal or external command,
operable program or batch file.

(server) E:\Research\extension\chrome-extension>[03:23:01]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 62, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 20, in query
    self.embedded()
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 45, in embedded
    self.embedded_db_path = embedded_obj.embedded_once()
                            ^^^^^^^^^^^^
NameError: name 'embedded_obj' is not defined
嵌入模型載入中...
嵌入模型載入完成
{'error': 'No query parameter provided'}

(server) E:\Research\extension\chrome-extension>[03:25:05]python -m modules.rag
Traceback (most recent call last):
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 95, in embedded_once
    self.collection = self.chromadb_client.get_collection(name=self.model_name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\api\client.py", line 218, in get_collection
    return self._server.get_collection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\telemetry\opentelemetry\__init__.py", line 143, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\api\segment.py", line 270, in get_collection
    raise ValueError(f"Collection {name} does not exist.")
ValueError: Collection infgrad/puff-base-v1 does not exist.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 62, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 20, in query
    self.embedded()
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 45, in embedded
    self.embedded_db_path = self.embedded_obj.embedded_once()
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 99, in embedded_once
    self.collection = self.chromadb_client.create_collection(name=self.model_name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\api\client.py", line 198, in create_collection
    return self._server.create_collection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\telemetry\opentelemetry\__init__.py", line 143, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\api\segment.py", line 169, in create_collection
    check_index_name(name)
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\api\segment.py", line 81, in check_index_name
    raise ValueError(msg)
ValueError: Expected collection name that (1) contains 3-63 characters, (2) starts and ends with an alphanumeric character, (3) otherwise contains only alphanumeric characters, underscores or hyphens (-), (4) contains no two consecutive periods (..) and (5) is not a valid IPv4 address, got infgrad/puff-base-v1
嵌入模型載入中...
嵌入模型載入完成
{'error': 'No query parameter provided'}

(server) E:\Research\extension\chrome-extension>[03:27:12]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 61, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    context = self.retrival(query)
              ^^^^^^^^^^^^^
AttributeError: 'rag' object has no attribute 'retrival'. Did you mean: 'retrieval'?
嵌入模型載入中...
嵌入模型載入完成
{'error': 'No query parameter provided'}
資料庫已存在

(server) E:\Research\extension\chrome-extension>[03:28:23]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 62, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    context = self.retrieval(query)
              ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 48, in retrieval
    if self.config["use_langchain"]:
       ~~~~~~~~~~~^^^^^^^^^^^^^^^^^
KeyError: 'use_langchain'
嵌入模型載入中...
嵌入模型載入完成
{'error': 'No query parameter provided'}
資料庫已存在

(server) E:\Research\extension\chrome-extension>[03:28:37]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 62, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    context = self.retrieval(query)
              ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 49, in retrieval
    self.use_langchain()
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 52, in use_langchain
    from langchain_chroma import Chroma
ModuleNotFoundError: No module named 'langchain_chroma'
嵌入模型載入中...
嵌入模型載入完成
{'error': 'No query parameter provided'}
資料庫已存在

(server) E:\Research\extension\chrome-extension>[03:29:26]pip install langchain-chroma
Collecting langchain-chroma
  Downloading langchain_chroma-0.1.1-py3-none-any.whl.metadata (1.3 kB)
Requirement already satisfied: chromadb<0.6.0,>=0.4.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-chroma) (0.5.0)
Requirement already satisfied: fastapi<1,>=0.95.2 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-chroma) (0.110.0)
Requirement already satisfied: langchain-core<0.3,>=0.1.40 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-chroma) (0.2.0)
Requirement already satisfied: numpy<2,>=1 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-chroma) (1.26.4)
Requirement already satisfied: build>=1.0.3 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.2.1)
Requirement already satisfied: requests>=2.28 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.31.0)
Requirement already satisfied: pydantic>=1.9 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.6.4)
Requirement already satisfied: chroma-hnswlib==0.7.3 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.7.3)
Requirement already satisfied: uvicorn>=0.18.3 in d:\programdata\anaconda3\envs\server\lib\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.28.0)
Requirement already satisfied: posthog>=2.4.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.5.0)
Requirement already satisfied: typing-extensions>=4.5.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.10.0)
Requirement already satisfied: onnxruntime>=1.14.1 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.18.0)
Requirement already satisfied: opentelemetry-api>=1.2.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.24.0)
Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.24.0)
Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.45b0)
Requirement already satisfied: opentelemetry-sdk>=1.2.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.24.0)
Requirement already satisfied: tokenizers>=0.13.2 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.19.1)
Requirement already satisfied: pypika>=0.48.9 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.48.9)
Requirement already satisfied: tqdm>=4.65.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.66.2)
Requirement already satisfied: overrides>=7.3.1 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (7.7.0)
Requirement already satisfied: importlib-resources in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (6.4.0)
Requirement already satisfied: grpcio>=1.58.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.64.0)
Requirement already satisfied: bcrypt>=4.0.1 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.1.3)
Requirement already satisfied: typer>=0.9.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.12.3)
Requirement already satisfied: kubernetes>=28.1.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (29.0.0)
Requirement already satisfied: tenacity>=8.2.3 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (8.3.0)
Requirement already satisfied: PyYAML>=6.0.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (6.0.1)
Requirement already satisfied: mmh3>=4.0.1 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.1.0)
Requirement already satisfied: orjson>=3.9.12 in d:\programdata\anaconda3\envs\server\lib\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.10.0)
Requirement already satisfied: starlette<0.37.0,>=0.36.3 in d:\programdata\anaconda3\envs\server\lib\site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.36.3)
Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (1.33)
Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (0.1.60)
Requirement already satisfied: packaging<24.0,>=23.2 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (23.2)
Requirement already satisfied: pyproject_hooks in d:\programdata\anaconda3\envs\server\lib\site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.1.0)
Requirement already satisfied: colorama in d:\programdata\anaconda3\envs\server\lib\site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.4.6)
Requirement already satisfied: jsonpointer>=1.9 in d:\programdata\anaconda3\envs\server\lib\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.40->langchain-chroma) (2.4)
Requirement already satisfied: certifi>=14.05.14 in d:\programdata\anaconda3\envs\server\lib\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2024.2.2)
Requirement already satisfied: six>=1.9.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)
Requirement already satisfied: python-dateutil>=2.5.3 in d:\programdata\anaconda3\envs\server\lib\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.9.0.post0)
Requirement already satisfied: google-auth>=1.0.1 in d:\programdata\anaconda3\envs\server\lib\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.29.0)
Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)
Requirement already satisfied: requests-oauthlib in d:\programdata\anaconda3\envs\server\lib\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.0.0)
Requirement already satisfied: oauthlib>=3.2.2 in d:\programdata\anaconda3\envs\server\lib\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)
Requirement already satisfied: urllib3>=1.24.2 in d:\programdata\anaconda3\envs\server\lib\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)
Requirement already satisfied: coloredlogs in d:\programdata\anaconda3\envs\server\lib\site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (15.0.1)
Requirement already satisfied: flatbuffers in d:\programdata\anaconda3\envs\server\lib\site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)
Requirement already satisfied: protobuf in d:\programdata\anaconda3\envs\server\lib\site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.25.3)
Requirement already satisfied: sympy in d:\programdata\anaconda3\envs\server\lib\site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.12)
Requirement already satisfied: deprecated>=1.2.6 in d:\programdata\anaconda3\envs\server\lib\site-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.2.14)
Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (7.0.0)
Requirement already satisfied: googleapis-common-protos~=1.52 in d:\programdata\anaconda3\envs\server\lib\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.63.0)
Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.24.0)
Requirement already satisfied: opentelemetry-proto==1.24.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.24.0)
Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.45b0)
Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.45b0)
Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.45b0)
Requirement already satisfied: opentelemetry-util-http==0.45b0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.45b0)
Requirement already satisfied: setuptools>=16.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (68.2.2)
Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)
Requirement already satisfied: asgiref~=3.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.8.1)
Requirement already satisfied: monotonic>=1.5 in d:\programdata\anaconda3\envs\server\lib\site-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.6)
Requirement already satisfied: backoff>=1.10.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)
Requirement already satisfied: annotated-types>=0.4.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.6.0)
Requirement already satisfied: pydantic-core==2.16.3 in d:\programdata\anaconda3\envs\server\lib\site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.16.3)
Requirement already satisfied: charset-normalizer<4,>=2 in d:\programdata\anaconda3\envs\server\lib\site-packages (from requests>=2.28->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in d:\programdata\anaconda3\envs\server\lib\site-packages (from requests>=2.28->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.6)
Requirement already satisfied: anyio<5,>=3.4.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from starlette<0.37.0,>=0.36.3->fastapi<1,>=0.95.2->langchain-chroma) (4.3.0)
Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in d:\programdata\anaconda3\envs\server\lib\site-packages (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.23.1)
Requirement already satisfied: click>=8.0.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)
Requirement already satisfied: shellingham>=1.3.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)
Requirement already satisfied: rich>=10.11.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (13.7.1)
Requirement already satisfied: h11>=0.8 in d:\programdata\anaconda3\envs\server\lib\site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.14.0)
Requirement already satisfied: httptools>=0.5.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)
Requirement already satisfied: python-dotenv>=0.13 in d:\programdata\anaconda3\envs\server\lib\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.0.1)
Requirement already satisfied: watchfiles>=0.13 in d:\programdata\anaconda3\envs\server\lib\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.21.0)
Requirement already satisfied: websockets>=10.4 in d:\programdata\anaconda3\envs\server\lib\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (11.0.3)
Requirement already satisfied: sniffio>=1.1 in d:\programdata\anaconda3\envs\server\lib\site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi<1,>=0.95.2->langchain-chroma) (1.3.1)
Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (5.3.3)
Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\programdata\anaconda3\envs\server\lib\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.4.0)
Requirement already satisfied: rsa<5,>=3.1.4 in d:\programdata\anaconda3\envs\server\lib\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.9)
Requirement already satisfied: filelock in d:\programdata\anaconda3\envs\server\lib\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.13.4)
Requirement already satisfied: fsspec>=2023.5.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2024.3.1)
Requirement already satisfied: zipp>=0.5 in d:\programdata\anaconda3\envs\server\lib\site-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.18.2)
Requirement already satisfied: markdown-it-py>=2.2.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)
Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.17.2)
Requirement already satisfied: humanfriendly>=9.1 in d:\programdata\anaconda3\envs\server\lib\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (10.0)
Requirement already satisfied: mpmath>=0.19 in d:\programdata\anaconda3\envs\server\lib\site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.3.0)
Requirement already satisfied: pyreadline3 in d:\programdata\anaconda3\envs\server\lib\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.4.1)
Requirement already satisfied: mdurl~=0.1 in d:\programdata\anaconda3\envs\server\lib\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)
Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\programdata\anaconda3\envs\server\lib\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.6.0)
Downloading langchain_chroma-0.1.1-py3-none-any.whl (8.5 kB)
Installing collected packages: langchain-chroma
Successfully installed langchain-chroma-0.1.1

(server) E:\Research\extension\chrome-extension>[03:30:03]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 62, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    context = self.retrieval(query)
              ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 49, in retrieval
    self.use_langchain()
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 54, in use_langchain
    langchain_chroma = Chroma(client = chroma_client,
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Chroma.__init__() got an unexpected keyword argument 'embedded_function'
嵌入模型載入中...
嵌入模型載入完成
{'error': 'No query parameter provided'}
資料庫已存在

(server) E:\Research\extension\chrome-extension>[03:30:34]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 62, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    context = self.retrieval(query)
              ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 49, in retrieval
    self.use_langchain()
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 54, in use_langchain
    langchain_chroma = Chroma(client = chroma_client,
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 167, in __init__
    self._collection = self._client.get_or_create_collection(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\api\client.py", line 237, in get_or_create_collection
    return self._server.get_or_create_collection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\telemetry\opentelemetry\__init__.py", line 143, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\api\segment.py", line 226, in get_or_create_collection
    return self.create_collection(  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\telemetry\opentelemetry\__init__.py", line 143, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\api\segment.py", line 169, in create_collection
    check_index_name(name)
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\api\segment.py", line 81, in check_index_name
    raise ValueError(msg)
ValueError: Expected collection name that (1) contains 3-63 characters, (2) starts and ends with an alphanumeric character, (3) otherwise contains only alphanumeric characters, underscores or hyphens (-), (4) contains no two consecutive periods (..) and (5) is not a valid IPv4 address, got infgrad/puff-base-v1
嵌入模型載入中...
嵌入模型載入完成
{'error': 'No query parameter provided'}
資料庫已存在

(server) E:\Research\extension\chrome-extension>[03:31:12]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 62, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    context = self.retrieval(query)
              ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 49, in retrieval
    self.use_langchain()
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 58, in use_langchain
    retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": top_k, "include_metadata": True})
                ^^^^^^^^^^^
NameError: name 'vectorstore' is not defined
嵌入模型載入中...
嵌入模型載入完成
{'error': 'No query parameter provided'}
資料庫已存在

(server) E:\Research\extension\chrome-extension>[03:32:35]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 62, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    context = self.retrieval(query)
              ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 49, in retrieval
    self.use_langchain()
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 58, in use_langchain
    retriever = langchain_chroma.as_retriever(search_type="similarity", search_kwargs={"k": top_k, "include_metadata": True})
                                                                                            ^^^^^
NameError: name 'top_k' is not defined
嵌入模型載入中...
嵌入模型載入完成
{'error': 'No query parameter provided'}
資料庫已存在

(server) E:\Research\extension\chrome-extension>[03:33:04]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 62, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate(query, context)
                  ^^^^^^^^^^^^^
AttributeError: 'rag' object has no attribute 'generate'
嵌入模型載入中...
嵌入模型載入完成
{'error': 'No query parameter provided'}
資料庫已存在
tags=['Chroma', 'method'] vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000027423444390> search_kwargs={'k': 5, 'include_metadata': True}

(server) E:\Research\extension\chrome-extension>[03:52:43]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 85, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    context = self.retrieval(query)
              ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 49, in retrieval
    self.use_langchain()
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 59, in use_langchain
    retriever.search(query)
    ^^^^^^^^^^^^^^^^
AttributeError: 'VectorStoreRetriever' object has no attribute 'search'
嵌入模型載入中...
嵌入模型載入完成
{'error': 'No query parameter provided'}
資料庫已存在

(server) E:\Research\extension\chrome-extension>[03:54:00]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 85, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    context = self.retrieval(query)
              ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 49, in retrieval
    return self.use_langchain()
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 59, in use_langchain
    result = retriever.invoke(query)
                              ^^^^^
NameError: name 'query' is not defined
嵌入模型載入中...
嵌入模型載入完成
{'error': 'No query parameter provided'}
資料庫已存在

(server) E:\Research\extension\chrome-extension>[03:54:27]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 85, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    context = self.retrieval(query)
              ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 49, in retrieval
    return self.use_langchain(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 59, in use_langchain
    result = retriever.invoke(query)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 194, in invoke
    return self.get_relevant_documents(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\_api\deprecation.py", line 148, in warning_emitting_wrapper
    return wrapped(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 323, in get_relevant_documents
    raise e
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 316, in get_relevant_documents
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\vectorstores.py", line 696, in _get_relevant_documents
    docs = self.vectorstore.similarity_search(query, **self.search_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 384, in similarity_search
    docs_and_scores = self.similarity_search_with_score(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 473, in similarity_search_with_score
    query_embedding = self._embedding_function.embed_query(query)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'embed_query'
嵌入模型載入中...
嵌入模型載入完成
{'error': 'No query parameter provided'}
資料庫已存在

(server) E:\Research\extension\chrome-extension>[03:56:29]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 85, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 20, in query
    self.embedded()
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 42, in embedded
    from .embedded import embedded
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 24, in <module>
    class embedded(object):
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 66, in embedded
    def embed_query(self, query:str)-> List[float]:
                                       ^^^^
NameError: name 'List' is not defined. Did you mean: 'list'?

(server) E:\Research\extension\chrome-extension>[03:56:41]python -m modules.rag
Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\models.py", line 971, in json
    return complexjson.loads(self.text, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 85, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    context = self.retrieval(query)
              ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 49, in retrieval
    return self.use_langchain(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 59, in use_langchain
    result = retriever.invoke(query)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 194, in invoke
    return self.get_relevant_documents(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\_api\deprecation.py", line 148, in warning_emitting_wrapper
    return wrapped(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 323, in get_relevant_documents
    raise e
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 316, in get_relevant_documents
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\vectorstores.py", line 696, in _get_relevant_documents
    docs = self.vectorstore.similarity_search(query, **self.search_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 384, in similarity_search
    docs_and_scores = self.similarity_search_with_score(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 473, in similarity_search_with_score
    query_embedding = self._embedding_function.embed_query(query)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 67, in embed_query
    return self.embedded([query])
           ^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 53, in embedded
    response_json = response.json()
                    ^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\models.py", line 975, in json
    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)
requests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
嵌入模型載入中...
嵌入模型載入完成
{'error': 'No query parameter provided'}
資料庫已存在

(server) E:\Research\extension\chrome-extension>[04:00:05]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 85, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    context = self.retrieval(query)
              ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 49, in retrieval
    return self.use_langchain(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 59, in use_langchain
    result = retriever.invoke(query)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 194, in invoke
    return self.get_relevant_documents(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\_api\deprecation.py", line 148, in warning_emitting_wrapper
    return wrapped(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 323, in get_relevant_documents
    raise e
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 316, in get_relevant_documents
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\vectorstores.py", line 696, in _get_relevant_documents
    docs = self.vectorstore.similarity_search(query, **self.search_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 384, in similarity_search
    docs_and_scores = self.similarity_search_with_score(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 474, in similarity_search_with_score
    results = self.__query_collection(
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py", line 36, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 191, in __query_collection
    return self._collection.query(
           ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Collection.query() got an unexpected keyword argument 'include_metadata'
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32

(server) E:\Research\extension\chrome-extension>[04:00:50]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 85, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    context = self.retrieval(query)
              ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 49, in retrieval
    return self.use_langchain(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 59, in use_langchain
    result = retriever.invoke(query)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 194, in invoke
    return self.get_relevant_documents(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\_api\deprecation.py", line 148, in warning_emitting_wrapper
    return wrapped(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 323, in get_relevant_documents
    raise e
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 316, in get_relevant_documents
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\vectorstores.py", line 696, in _get_relevant_documents
    docs = self.vectorstore.similarity_search(query, **self.search_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 384, in similarity_search
    docs_and_scores = self.similarity_search_with_score(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 474, in similarity_search_with_score
    results = self.__query_collection(
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py", line 36, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 191, in __query_collection
    return self._collection.query(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\api\models\Collection.py", line 300, in query
    validate_embeddings(
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\api\types.py", line 488, in validate_embeddings
    raise ValueError(
ValueError: Expected each embedding in the embeddings to be a list, got ['ndarray']
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32

(server) E:\Research\extension\chrome-extension>[04:01:46]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 85, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    context = self.retrieval(query)
              ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 49, in retrieval
    return self.use_langchain(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 59, in use_langchain
    result = retriever.invoke(query)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 194, in invoke
    return self.get_relevant_documents(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\_api\deprecation.py", line 148, in warning_emitting_wrapper
    return wrapped(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 323, in get_relevant_documents
    raise e
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 316, in get_relevant_documents
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\vectorstores.py", line 696, in _get_relevant_documents
    docs = self.vectorstore.similarity_search(query, **self.search_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 384, in similarity_search
    docs_and_scores = self.similarity_search_with_score(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 474, in similarity_search_with_score
    results = self.__query_collection(
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py", line 36, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 191, in __query_collection
    return self._collection.query(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\api\models\Collection.py", line 300, in query
    validate_embeddings(
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\api\types.py", line 503, in validate_embeddings
    raise ValueError(
ValueError: Expected each value in the embedding to be a int or float, got an embedding with ['list'] - [[-0.2742879092693329, -0.13044822216033936, 0.17604096233844757, 0.13947296142578125, -0.11417403817176819, 0.36184409260749817, -0.3625182509422302, -0.025016993284225464, -0.0034568095579743385, -0.17798404395580292, 0.45124492049217224, 0.16061799228191376, 0.29514846205711365, 0.06316421180963516, -0.09118659049272537, 0.17019280791282654, 0.29278451204299927, 0.13742239773273468, 0.4902885854244232, -0.12515032291412354, 0.1511945128440857, -0.005590082611888647, 0.11800555884838104, 0.05825700983405113, 0.25007742643356323, 0.477908730506897, -0.13476380705833435, 0.005458430387079716, -0.17871937155723572, 0.1017264649271965, 0.041725292801856995, -0.17842024564743042, -0.10601452738046646, -0.4550081193447113, 0.10395002365112305, -0.05315302312374115, -0.36928170919418335, -0.02080412022769451, 0.018022678792476654, 0.0653730258345604, -0.3349311649799347, 0.409768670797348, 0.3782247304916382, -0.17486196756362915, 0.26793649792671204, -0.34613120555877686, -0.24960528314113617, 0.3410329520702362, -0.3462725579738617, -0.02243419550359249, -0.11478990316390991, 0.026960231363773346, 0.03535907715559006, 0.2519082725048065, -0.12810473144054413, 0.10814449936151505, 0.20627489686012268, -0.0411030575633049, -0.4066510498523712, 0.27925926446914673, -0.2537994086742401, -0.047539882361888885, -0.17213670909404755, 0.005619403440505266, 0.058456823229789734, 0.12499447166919708, -0.1609855592250824, 0.16839346289634705, 0.7166364789009094, -0.32717224955558777, -0.39314356446266174, -0.2070871889591217, 0.22577643394470215, 0.07650752365589142, 0.19947852194309235, 0.025318186730146408, -0.0397639274597168, 0.054733265191316605, -0.2340591847896576, 0.03955630213022232, -0.07131257653236389, -0.110553078353405, -0.15588614344596863, -0.3488883078098297, -0.2145032286643982, 0.10304475575685501, -0.49672427773475647, -0.1967126876115799, -0.17731572687625885, -0.07311361283063889, 0.5470401644706726, 0.3603740632534027, -0.08295691758394241, -0.38247501850128174, -0.19962577521800995, 0.3236904740333557, -0.15789668262004852, -0.4564845561981201, 0.005420492962002754, 0.023792138323187828, -0.2991100251674652, 0.02427452802658081, -0.14884305000305176, -0.35585349798202515, -0.2724370062351227, 0.35269761085510254, -0.31192830204963684, 0.4091106951236725, 0.4608810544013977, -0.18643653392791748, -0.2832412123680115, -0.15686453878879547, 0.08751092106103897, -0.5020077228546143, -0.22326815128326416, 0.27623042464256287, -0.016316093504428864, 0.31761786341667175, 0.05023250728845596, 0.46395841240882874, 0.48137176036834717, -0.11677868664264679, 0.2137538194656372, -0.18275947868824005, 0.1896805763244629, 0.0546327643096447, -0.11684868484735489, -0.5129655599594116, -0.03189390152692795, 0.18268896639347076, 0.08804655075073242, -0.19424155354499817, -0.08248082548379898, 0.1277475208044052, 0.4830034673213959, -0.057649824768304825, -0.21149452030658722, -0.12643682956695557, 0.10575124621391296, 0.35627347230911255, 0.010199185460805893, 0.22570864856243134, 0.06202470511198044, -0.11279582232236862, -0.04883784428238869, 0.2465464174747467, 0.05929134786128998, 0.033016402274370193, -0.037653665989637375, -0.6190891861915588, 0.14694947004318237, -0.03043263964354992, -0.11925170570611954, -0.03782683610916138, -0.24825318157672882, -0.19307547807693481, -0.1652824878692627, -0.19734515249729156, 0.1212378516793251, 0.3008577227592468, -0.08093393594026566, -0.3052663505077362, -0.2031056433916092, 0.1724414825439453, -0.20295412838459015, -0.08667696267366409, 0.053025417029857635, -0.38897091150283813, -0.045118026435375214, 0.02362837642431259, -0.12060544639825821, -0.012670975178480148, 0.17698165774345398, 0.3984816074371338, 0.18800008296966553, -0.23636634647846222, -0.07292824238538742, -0.06018722057342529, -0.2630676329135895, 0.3738009035587311, 0.2711254358291626, 0.09033334255218506, 0.07651983201503754, 0.061814989894628525, 0.047256678342819214, -0.3112860918045044, -0.4283282458782196, 0.030206892639398575, -0.0025038800667971373, 0.3866552710533142, 0.10501423478126526, -0.2174767553806305, 0.12005608528852463, -0.06002437323331833, -0.34064140915870667, -0.19036470353603363, 0.07475338131189346, -0.1843978613615036, 0.45552369952201843, -0.46850812435150146, -0.2634795904159546, -0.19937922060489655, 0.011534280143678188, 0.5108577609062195, 0.09804028272628784, 0.3747034966945648, -0.025462321937084198, 0.1301984041929245, -0.08450264483690262, 0.23948216438293457, -0.39393118023872375, 0.28634342551231384, 0.09597912430763245, -0.1253930628299713, 0.24148428440093994, 0.1623624563217163, -0.24125763773918152, 0.09050855040550232, 0.1692173033952713, -0.23799830675125122, -0.7222397327423096, 0.462581604719162, 0.3080170750617981, 0.32338109612464905, -0.04091871529817581, -0.22964464128017426, 0.2713523209095001, -0.07738249748945236, -0.05842581018805504, -0.8473502397537231, 0.02607719600200653, 0.06744423508644104, 0.23087674379348755, 0.23208019137382507, 0.11179649829864502, -0.2720782160758972, -0.45882347226142883, -0.06305016577243805, 0.021826742216944695, -0.642602801322937, -0.464193195104599, -0.6215335130691528, -0.678906261920929, 0.154962420463562, -0.294853150844574, -0.22498631477355957, 0.07739575207233429, -0.14992842078208923, 0.3341912031173706, -0.12999677658081055, -0.04215347021818161, -0.2926298975944519, 0.0240732803940773, 0.12773708999156952, -0.1738855242729187, 0.2045716643333435, -0.3367558717727661, -0.07472442090511322, -0.12060729414224625, 0.013654127717018127, -0.1485614776611328, 0.11437027156352997, 0.03080577217042446, -0.10470698773860931, -0.11696053296327591, 0.13440518081188202, 0.20275722444057465, 0.36388513445854187, -0.2776752710342407, 0.180478036403656, 0.21656616032123566, -0.18555369973182678, -0.3448809087276459, 0.051711954176425934, -0.3371044397354126, 0.5356751680374146, -0.48495206236839294, 0.09140407294034958, -0.09114435315132141, 0.07067583501338959, 0.317471444606781, -0.11218138039112091, -0.2471904158592224, 0.22619453072547913, -0.4318494200706482, 0.19244615733623505, -0.30189231038093567, 0.2907385528087616, 0.09970516711473465, -0.06542839854955673, 0.40283188223838806, -0.02869277633726597, -0.2707408368587494, -0.11858519911766052, -0.020188873633742332, -0.030697759240865707, -0.212148979306221, 0.21845945715904236, 0.46702268719673157, -0.24248306453227997, 0.261590838432312, 0.11724957823753357, 0.020196370780467987, -0.2665136158466339, 0.10697095096111298, -0.15390713512897491, -0.07735824584960938, -0.1146802082657814, -0.0649675577878952, 0.4102618098258972, -0.12131408601999283, -0.17476016283035278, 0.017998388037085533, 0.19872038066387177, -0.04343028366565704, 0.3005051016807556, 0.04325054585933685, 0.09608712047338486, -0.011186043731868267, -0.33021485805511475, -0.272044837474823, 0.3073785603046417, 0.33441099524497986, 0.060739919543266296, 0.3207448124885559, 0.36864614486694336, -0.16905857622623444, 0.07183371484279633, -0.5901479721069336, -0.09598040580749512, -0.07268869876861572, 0.05850076675415039, 0.03275324031710625, 0.0018889936618506908, 0.08718838542699814, 0.004973194561898708, -0.15383747220039368, -0.1340632438659668, -0.2686460018157959, -0.08435279130935669, -0.060436759144067764, 0.04820847138762474, 0.19910190999507904, 0.37154582142829895, 0.07526443153619766, 0.21223382651805878, -0.10558994859457016, 0.4897485077381134, -0.03110635280609131, -0.31350427865982056, -0.0035204030573368073, -0.37653061747550964, 0.05727367848157883, 0.20557931065559387, 0.08448752015829086, -0.01756283827126026, -0.22462141513824463, 0.034243497997522354, 0.32605788111686707, 0.3275850713253021, -0.4588806927204132, 0.039275165647268295, 0.011680406518280506, 0.11907047033309937, -0.19142958521842957, -0.16492216289043427, 0.12620587646961212, 0.0034791575744748116, 0.12357145547866821, -0.2682268023490906, -0.32485219836235046, 0.22914661467075348, -0.35092246532440186, -0.24866443872451782, 0.22884736955165863, 0.05233552306890488, 0.5000241994857788, -0.39715003967285156, 0.09814213961362839, 0.012482114136219025, 0.2578750252723694, -0.032058656215667725, -0.3895499110221863, 0.31820300221443176, -0.4079902172088623, -0.11710188537836075, -0.26501819491386414, 0.33261141180992126, -0.011931300163269043, 0.23498672246932983, -0.1491895318031311, 0.41228169202804565, -0.32464081048965454, 0.1722024828195572, -0.3733361065387726, -0.2798570394515991, 0.0035556675866246223, 0.025524673983454704, -0.3905620872974396, 0.4763253331184387, 0.0021521663293242455, -0.019455326721072197, 0.5983675718307495, 0.10017484426498413, 0.347511887550354, 0.25967374444007874, -0.28710052371025085, -0.16286149621009827, 0.09047257155179977, 0.5131091475486755, 0.20266005396842957, 0.2895597219467163, 0.1834978312253952, 0.12107406556606293, 0.6158685088157654, 0.1642352044582367, 0.03209858387708664, -0.08972672373056412, 0.2586643397808075, 0.3490433990955353, 0.2910500168800354, -0.13547149300575256, 0.23250456154346466, 0.5381237864494324, 0.30395591259002686, -0.19982875883579254, 0.03488927334547043, 0.1769154965877533, 0.1148797869682312, 0.34440889954566956, -0.3994644284248352, 0.1428065001964569, 0.17968209087848663, 0.31700119376182556, -0.18583622574806213, 0.12459325790405273, 0.031226634979248047, -0.3109797239303589, 0.1092645525932312, -0.35502296686172485, -0.046519529074430466, -0.19658111035823822, -0.34695127606391907, 0.011567497625946999, 0.3845653235912323, -0.19071868062019348, -0.26455971598625183, 0.7220948338508606, -0.03001718781888485, -0.18353818356990814, 0.12910671532154083, 0.043196722865104675, -0.05542376637458801, -0.2364180088043213, -0.06219293922185898, -0.06516449898481369, -0.21091094613075256, 0.30766022205352783, -0.06225334852933884, -0.06149369478225708, 0.23571819067001343, 0.019319433718919754, -0.029897507280111313, -0.15861985087394714, 0.777885377407074, -0.5245983600616455, 0.14090131223201752, 0.08670748770236969, -0.14601841568946838, 0.07372169196605682, -0.278263121843338, 0.15912333130836487, 0.29018083214759827, -0.010625602677464485, -0.16145162284374237, -0.22774197161197662, 0.2936413884162903, 0.08837346732616425, 0.12356822937726974, -0.15685832500457764, 0.06735177338123322, -0.07428907603025436, 0.33472174406051636, -0.1879282295703888, 0.21989049017429352, -0.04907556623220444, -0.37733182311058044, 0.1100773811340332, 0.09518880397081375, 0.1741948127746582, 0.11468800902366638, -0.1710762083530426, -0.22992925345897675, -0.2962954044342041, 0.13304759562015533, -0.023272672668099403, 0.16827376186847687, 0.045391857624053955, 0.11754406988620758, -0.10434026271104813, 0.20081700384616852, 0.17079415917396545, 0.07990764081478119, -0.035496167838573456, 0.13587327301502228, -0.29773175716400146, -0.10799199342727661, -0.09723079204559326, 0.36202162504196167, -0.3019786775112152, -0.14188934862613678, 0.3432214856147766, -0.14122799038887024, -0.2377912402153015, -0.24721625447273254, 0.6932456493377686, -0.22543293237686157, 0.28533461689949036, 0.3817858099937439, -0.3318753242492676, 0.18756534159183502, -0.1397237628698349, -0.12659932672977448, 0.39031144976615906, -0.06479315459728241, 0.19497862458229065, 0.1228814423084259, 0.10678435117006302, 0.34799182415008545, -0.16669206321239471, 0.013773186132311821, -0.12034148722887039, 0.10459764301776886, 0.009879391640424728, -0.15030936896800995, -0.008841435424983501, 0.2924431264400482, 0.23855647444725037, 0.3014747202396393, 0.20650438964366913, 0.06845182180404663, -0.20512108504772186, -0.0796416848897934, -0.09918497502803802, -0.0810990184545517, -0.125593364238739, 0.00208581006154418, -0.057101424783468246, 0.20993085205554962, -0.43828916549682617, 0.08637283742427826, -0.14856795966625214, 0.1448785364627838, -0.20084834098815918, -0.16177718341350555, 0.12107774615287781, 0.3394073247909546, 0.19100874662399292, -0.08577750623226166, -0.0836125910282135, 0.08263729512691498, 0.3377240002155304, -0.3042271137237549, -0.1388813555240631, -0.1594136655330658, -0.015482941642403603, 0.14521841704845428, 0.05719903111457825, -0.1576700657606125, 0.0931883230805397, 0.11593551188707352, -0.5104842782020569, 0.08900360763072968, 0.2328486442565918, -0.03571920096874237, -0.1799815148115158, 0.603269636631012, -0.1825256496667862, 0.12959344685077667, 0.337422251701355, 0.11071017384529114, 0.3501752018928528, -0.3139645457267761, 0.18705151975154877, 0.047455303370952606, 0.18389545381069183, 0.09607090055942535, 0.4314271807670593, 0.25564563274383545, 0.3066962957382202, 0.4400292932987213, -0.29751473665237427, 0.2893871068954468, 0.15409329533576965, -0.0015074871480464935, -0.17654737830162048, -0.22523395717144012, -0.026157189160585403, -0.20586170256137848, -0.005973260849714279, 0.34219810366630554, -0.21291238069534302, 0.41090214252471924, 0.2671302855014801, 0.35721123218536377, 0.0401141494512558, 0.05771627649664879, -0.2136366218328476, -0.034676581621170044, -0.2278432697057724, 0.03004097193479538, 0.20524802803993225, -0.0712127834558487, -0.35387009382247925, -0.03355855122208595, -0.16856780648231506, -0.16396065056324005, -0.1644740104675293, -0.10554364323616028, 0.195786252617836, -0.0683448538184166, -0.10236430168151855, 0.3096112608909607, -0.193482905626297, -0.06922151893377304, -0.06538824737071991, -0.3914511501789093, 0.37304210662841797, -0.4109008312225342, -0.07478567212820053, 0.05374767258763313, 0.2484545111656189, -0.6794910430908203, -0.2670014500617981, 0.06199587136507034, 0.1176471933722496, -0.24282291531562805, -0.08581971377134323, 0.19617077708244324, 0.5661516785621643, 0.3372087776660919, 0.20935815572738647, 0.03603295236825943, 0.2083049714565277, 0.14698107540607452, -0.06320412456989288, -0.10546465218067169, -0.1757674515247345, -0.22398579120635986, -0.03339345380663872, -0.3437485694885254, -0.17150162160396576, -0.28159216046333313, -0.381214439868927, -0.3206380605697632, -0.20269188284873962, 0.09385625272989273, 0.3037932813167572, 0.17862480878829956, 0.3345765769481659, 0.36544233560562134, -0.26827922463417053, 0.13709194958209991, -0.46514037251472473, 0.2538902759552002, 0.08336413651704788, 0.1445397585630417, -0.044243089854717255, -0.1972436159849167, 0.4608617126941681, -0.11082571744918823, 0.6739251613616943, -0.14736947417259216, -0.13961197435855865, -0.07597631216049194, 0.4106232821941376, 0.4643446207046509, -0.4336734712123871, -0.08346392959356308, 0.27695897221565247, 0.08828479796648026, -0.11656972765922546, 0.1080809235572815, 0.11975473165512085, -0.14085352420806885, 0.07370211184024811, 0.13170824944972992, -0.10149674862623215, 0.12464748322963715, 0.3215559124946594, 0.06941753625869751, 0.06381309032440186, -0.23099009692668915, 0.3228164613246918, 0.43477576971054077, -0.1397886872291565, 0.1182766854763031, 0.2721112072467804, 0.18687821924686432, -0.37951555848121643, -0.05963432416319847, 0.08471287786960602, 0.14187735319137573, -0.12543410062789917, -0.10174207389354706, -0.010662529617547989, 0.2568768560886383, 0.2780790627002716, -0.22144129872322083, 0.38165584206581116, 0.08872150629758835, 0.5268333554267883, 0.4575471878051758, 0.22291047871112823, 0.18319855630397797, 0.07686260342597961, 0.2575182616710663, 0.1636703610420227, -0.43419525027275085, 0.06894532591104507, -0.30251753330230713, -0.04832432419061661, -0.29838070273399353, -0.07293976843357086, 0.1225607618689537, 0.04147373512387276, -0.01661372371017933, 0.035052284598350525, 0.21317100524902344, -0.09538058936595917, -0.07504720240831375, 0.1274954378604889, 0.074744313955307, 0.25963205099105835, -0.3196486532688141, 0.0022325264289975166, 0.21036526560783386, -0.04625602066516876, -0.04106098785996437, 0.18610915541648865, -0.08883988112211227, -0.05925479158759117, -0.18035829067230225, -0.3528214693069458, -0.2818252444267273, -0.09949785470962524, -0.10181067883968353, -0.2511008679866791, 0.02603749744594097, -0.06979120522737503, -0.3706524074077606, 0.06898956745862961, -0.2648387551307678, -0.28665605187416077, 0.013381563127040863, -0.349597305059433, -0.5142621397972107, -0.25600457191467285, -0.0895465835928917, 0.17062349617481232, -0.3644730746746063, 0.2431405484676361, -0.0797855481505394, 0.07938020676374435, 0.36159446835517883, 0.13922667503356934, 0.029378585517406464, 0.23922473192214966, 0.0609419122338295, 0.25431838631629944, 0.24616490304470062, -0.08724570274353027, 0.07219825685024261, 0.06458009779453278, -0.6590755581855774, -0.11230404675006866, -0.11482105404138565, 0.3325386345386505, 0.021938305348157883, -0.20836128294467926, 0.1541307419538498, 0.14424633979797363, -0.6088345646858215, -0.20606504380702972, 0.17228028178215027, 0.15907840430736542, -0.31805408000946045, 0.06744738668203354, 0.44644442200660706, 0.13818900287151337, -0.060642458498477936, -0.06972921639680862, -0.08218532800674438, 0.2515941560268402, -0.06031656637787819, -0.06307423859834671, -0.2571655809879303, -0.3944667875766754, -0.18122175335884094, -0.05903506651520729, 0.03314531221985817, -0.35773637890815735, -0.13167904317378998, 0.0025019480381160975, 0.08119180053472519, -0.1728818118572235, -0.11492248624563217, 0.6502485275268555, -0.047821734100580215, -0.16364522278308868, -0.1918325126171112, -0.05433027446269989, 0.12261775135993958, -0.3968014419078827, 0.012013183906674385, 0.11149042844772339, 0.0003264583647251129, 0.16576461493968964, 0.10858330130577087, 0.14845894277095795, -0.27474308013916016, -0.18603873252868652, -0.09177719801664352, -0.2936927080154419, -0.03531496599316597, 0.1942463368177414, 0.15569329261779785, -0.005225629545748234, -0.46016761660575867, -0.2601306736469269, 0.7400419116020203, 0.05407419800758362, 0.17538025975227356, 0.309266060590744, -0.006980162113904953, -0.10887397825717926, -0.34893885254859924, 0.1892370730638504, -0.2640499770641327, 0.12333766371011734, 0.068311408162117, 0.07745819538831711, 0.45920267701148987, -0.0025569223798811436, -0.4203982353210449, 0.11775520443916321, 0.1363595426082611, 0.11134803295135498, -0.43883901834487915, 0.4462808072566986, -0.19563211500644684, 0.0818488746881485, -0.15703028440475464, -0.20837610960006714, -0.3286433219909668, 0.15515409409999847, 0.03631962090730667, 0.09373623877763748, 0.15994387865066528, -0.37107452750205994, -0.2170482575893402, 0.05806251987814903, 0.11973202228546143, 0.036835309118032455, -0.14110270142555237, -0.06934142857789993, -0.5303272604942322, 0.06141537427902222, 0.15691271424293518, -0.2246704399585724, 0.33525460958480835, -0.15870699286460876, 0.3356495201587677, -0.1644887626171112, -0.11111133545637131, -0.010363585315644741, 0.012310443446040154, -0.05721573531627655, 0.4497673809528351, -0.48776668310165405, -0.563400387763977, 0.16461630165576935, -0.2194766104221344, 0.1105986014008522, -0.014369670301675797, 0.13068802654743195, 0.12649112939834595, 0.36089661717414856, 0.1779184341430664, 0.13736914098262787, -0.05102204531431198, 0.1904168277978897, -0.24908936023712158, 0.16006454825401306, 0.0978626161813736, 0.11643750965595245, -0.4372921288013458, 0.3176441192626953, 0.009764004498720169, -0.11963949352502823, 0.10142600536346436, -0.049259863793849945, -0.02572866529226303, -0.09987274557352066, -0.1634896993637085, -0.16097396612167358, -0.32619592547416687, 0.44917309284210205, 0.31778159737586975, -0.22991932928562164, 0.07192012667655945, 0.27210506796836853, 0.0933208018541336, 0.08030395209789276, -0.09025805443525314, 0.23992455005645752, -0.08687005937099457, -0.01283266767859459, -0.17100155353546143, -0.3148336112499237, 0.10778443515300751, 0.18241815268993378, -0.31535109877586365, -0.0001417221501469612, -0.08260983228683472, 0.034304045140743256, -0.16632336378097534, -0.11683519929647446, -0.2969181537628174, -0.07828874886035919, -0.26438072323799133, 0.4718506932258606, -0.05555510148406029, -0.28329265117645264, -0.2987655699253082, -0.12704819440841675, -0.04960600286722183, 0.13125821948051453, 0.0961981788277626, 0.12492597103118896, 0.3312017321586609, -0.06847909837961197, -0.10248792916536331, 0.22616411745548248, -0.4072972238063812, -0.11017202585935593, 0.021458297967910767, 0.1279030591249466, 0.006485757417976856, -0.010507664643228054, 0.10749994963407516, 0.39038926362991333, 0.4326591193675995, -0.49262428283691406, -0.026323780417442322, 0.05790921300649643, 0.3419540226459503, 0.007820948027074337, 0.13491131365299225, -0.158910870552063, -0.34234362840652466, -0.34842824935913086, 0.029098808765411377, 0.12580469250679016, 0.38019701838493347, 0.073828786611557, 0.2890324592590332, -0.1321929693222046, 0.1271277368068695, 0.43191424012184143, 0.2867702543735504, 0.07925545424222946, 0.049621134996414185, 0.6071217060089111, -0.24057123064994812, -0.08335847407579422, -0.0277620367705822, 0.048393309116363525, -0.14067210257053375, -0.2378341257572174, 0.02021363563835621, -0.23483765125274658, -0.2702186107635498, 0.10151814669370651, -0.14195550978183746, -0.14124611020088196, 0.5334150195121765, -0.10468534380197525, 0.1562088578939438, -0.17612814903259277, 0.06640404462814331, -0.05581875517964363, 0.1834692806005478, -0.17647753655910492, 0.16325365006923676, 0.3117251694202423, 0.0780220478773117, 0.15490368008613586, 0.07200906425714493, -0.14218443632125854, 0.03341010957956314, -0.001430491916835308, 0.015297300182282925, 0.4819260835647583, -0.22215624153614044, 0.20058973133563995, -0.3772137463092804, 0.07822214066982269, 0.13179489970207214, -0.007814167067408562, 0.14864738285541534, 0.14059104025363922, -0.14838829636573792, 0.07402130961418152, 0.08371244370937347, -0.13354186713695526, -0.18539904057979584, 0.3188249170780182, -0.44678232073783875, 0.03189331293106079, 0.029496654868125916, 0.1447519212961197, 0.1656341850757599, 0.2571813762187958, -0.5023946166038513, -0.16285832226276398, -0.5043262243270874, -0.1493348926305771, 0.1669451743364334, 0.4464845061302185, -0.07407955825328827, 0.29249516129493713, 0.33037054538726807, 0.15042035281658173, -0.06311371922492981, 0.10789037495851517, -0.5248398780822754, 0.02582838572561741, 0.15925994515419006, -0.4340386390686035, 0.27933913469314575, 0.31596699357032776, 0.21965032815933228, -0.37114742398262024, 0.2901219427585602, -0.2613976001739502, 0.28845590353012085, -0.026442930102348328, 0.3071904480457306, -0.25489896535873413, 0.2121172845363617, -0.24198542535305023, 0.03629601001739502, 0.43038806319236755, 0.10568012297153473, -0.16771017014980316, -0.33916494250297546, 0.32048845291137695, -0.07569574564695358, -0.2603186070919037, -0.4582175612449646, 0.3415912985801697, -0.37480321526527405, -0.20113644003868103, 0.2762402296066284, -0.30034172534942627, -0.33212438225746155, -0.347947359085083, -0.3201850950717926, -0.047444671392440796, 0.32719364762306213, -0.39181506633758545, -0.024339964613318443, 0.08527899533510208, 0.3079487383365631, 0.10766089707612991, 0.15906977653503418, 0.1671184003353119, -0.06379279494285583, 0.07571033388376236, -0.18149900436401367, 0.3088465631008148, -0.5531818270683289, 0.24056445062160492, -0.08914345502853394, -0.597480297088623, 0.4982370436191559, 0.0512101948261261, 0.4480414092540741, 0.4020555913448334, 0.040833085775375366, -0.011171546764671803, -0.03966979309916496, 0.3478015661239624, 0.39023369550704956, 0.3441312909126282, 0.024773383513092995, 0.12471897155046463, 0.17877289652824402, 0.07139944285154343, 0.2519286870956421, 0.12601013481616974, -0.12108032405376434, -0.2740728557109833, -0.2611837387084961, -0.07832084596157074, -0.02230237051844597, 0.38240188360214233, 0.0508272647857666, -0.033687785267829895, 0.729381799697876, -0.01963718608021736, 0.5130424499511719, 0.25035399198532104, -0.044518858194351196, 0.009380420669913292, 0.03720929101109505, -0.24059949815273285, 0.022009018808603287, 0.01020396314561367, 0.12093400955200195, 0.04696550592780113, -0.09413042664527893, -0.25848233699798584, -0.10443339496850967, 0.06648343056440353, 0.05059019848704338, 0.04563362896442413, -0.06342221796512604, -0.09743386507034302, -0.3592708110809326, 0.26342272758483887, 0.19137196242809296, 0.12897410988807678, -0.48937860131263733, -0.2775392532348633, 0.01350417360663414, 0.14469066262245178, -0.08428658545017242, 0.1345881223678589, -0.4456689953804016, -0.44266289472579956, -0.0212814100086689, 0.25095388293266296, -0.25507885217666626, 0.2493397295475006, 0.04797464609146118, -0.28653863072395325, -0.07719194144010544, -0.5343239903450012, 0.4171736240386963, 0.07673978805541992, -0.09020040929317474, 0.060938283801078796, 0.17580175399780273, -0.04325805976986885, -0.12674006819725037, -0.07820984721183777, -0.07903094589710236, 0.17838676273822784, 0.14108042418956757, -0.48240989446640015, -0.2102997750043869, 0.09955977648496628, -0.08083171397447586, 0.24023675918579102, -0.09315968304872513, -0.08011293411254883, 0.21664080023765564, 0.01970333233475685, 0.6103957891464233, 0.3631546199321747, -0.09161916375160217, 0.1905246526002884, -0.25023818016052246, -0.15394900739192963, -0.12445143610239029, -0.20252393186092377, 0.06318620592355728, 0.26348426938056946, -0.23567157983779907, 0.2623141407966614, 0.2593705952167511, -0.0974370539188385, -0.26892873644828796, 0.4656195640563965, -0.0009155683219432831, 0.3892400562763214, -0.16632212698459625, 0.14237818121910095, 0.05079447478055954, 0.17845962941646576, 0.04291510581970215, -0.44258853793144226, 0.08296170830726624, 0.1727585643529892, 0.2994786202907562, -0.3248237371444702, 0.16139604151248932, 0.7065744400024414, -0.3419802784919739, -0.07091318070888519, 0.21259111166000366, 0.4712870419025421, -0.02774077281355858, 0.17178817093372345, -0.0616854652762413, 0.7461392283439636, -0.5723239779472351, -0.21460312604904175, 0.10397101938724518, -0.17721840739250183, 0.04126725718379021, 0.14156951010227203, 0.10685092210769653, 0.009159289300441742, -0.41340190172195435, -0.09865760803222656, -0.1289687156677246, -0.0792163759469986, -0.40495792031288147, -0.0978274717926979, -0.14258623123168945, 0.1756913810968399, -0.3111026883125305, -0.21856118738651276, 0.10444378852844238, -0.08064784109592438, 0.10969816893339157, 0.07233595848083496, 0.11254187673330307, 0.0044378312304615974, -0.23503315448760986, -0.004542423877865076, -0.010051124729216099, 0.10163498669862747, -0.22968325018882751, 0.05947316065430641, 0.38540729880332947, 0.4788491427898407, 0.25937941670417786, -0.15756623446941376, -0.3832096755504608, -0.08161424845457077, -0.13632594048976898, 0.1396593153476715, -0.23439209163188934, 0.11803694069385529, 0.02905949577689171, -0.5823540091514587, 0.08770551532506943, -0.18738366663455963, -0.25147879123687744, -0.13683636486530304, 0.024186279624700546, -0.12875093519687653, -0.11922923475503922, 0.07092154026031494, -0.05628820136189461, -0.13828951120376587, 0.34590041637420654, 0.218740776181221, -0.2566525638103485, 0.1626567840576172, 0.4077790379524231, 0.18146222829818726, -0.6539121866226196, 0.3532821238040924, -0.12018135190010071, -0.10633261501789093, -0.2066352814435959, -0.27278321981430054, -0.3852035105228424, -0.3530302941799164, -0.2969273030757904, 0.335435688495636, 0.15736733376979828, -0.04410257190465927, 0.2297183722257614, 0.3583376705646515, -0.22925671935081482, 0.5378578305244446, -0.22838431596755981, 0.3518204689025879, 0.17919988930225372, -0.14156807959079742, 0.2318057417869568, 0.29183709621429443, -0.1404554545879364, -0.2727292776107788, -0.210173562169075, 0.4292958676815033, -0.14095468819141388, -0.3045100271701813, -0.3373779356479645, -0.09295057505369186, 0.3156682848930359, 0.14765918254852295, -0.23792190849781036, 0.2537285387516022, 0.2277306318283081, 0.19940771162509918, -0.1522240787744522, -0.08609939366579056, 0.13100998103618622, 0.1349848210811615, -0.3773481249809265, 0.10162831842899323, -0.1594473272562027, -0.3729854226112366, -0.12322822213172913, 0.1431988775730133, 0.2513817250728607, -0.2363012582063675, 0.4645008444786072, 0.05890367180109024, 0.12522244453430176, 0.24963496625423431, 0.030216343700885773, 0.027610495686531067, 0.050465285778045654, 0.27229613065719604, -0.06393802165985107, 0.02918182499706745, -0.0210086852312088, -0.04709641635417938, -0.17347143590450287, -0.2223072350025177, -0.10989335179328918, -0.10793434083461761, 0.03790238872170448, -0.007151782512664795, -0.5914676785469055, -0.16251304745674133, -0.18306928873062134, -0.049038857221603394, 0.08839301019906998, -0.15593360364437103, -0.137552410364151, -0.2945781946182251, -0.06792587786912918, 0.11145444214344025, 0.10083117336034775, -0.14093512296676636, -0.0838577151298523, 0.34322530031204224, -0.14312958717346191, -0.02907591685652733, -0.1506197601556778, 0.1271669715642929, 0.16123205423355103, 0.006187841296195984, 0.034595787525177, -0.38472265005111694, 0.04156973585486412, 0.4619925916194916, 0.233442023396492, -0.37237292528152466, 0.34501805901527405, 0.000893792137503624, -0.09335705637931824, 0.2699853777885437, 0.39399945735931396, -0.16519862413406372, -0.30328747630119324, 0.023653296753764153, 0.14964307844638824, -0.23665869235992432, 0.2220718115568161, -0.127649188041687, 0.156696617603302, -0.5824589133262634, 0.17742031812667847, 0.3083522915840149, -0.35020723938941956, -0.2952347695827484, 0.3219897747039795, -0.239834263920784, -0.22066789865493774, 0.30148106813430786, 0.09254331141710281, 0.2518879175186157, -0.08619800209999084, -0.3305041193962097, 0.1653061956167221, -0.19767583906650543, -0.05030924081802368, 0.21894881129264832, -0.13445152342319489, 0.5722993016242981, 0.06843242794275284, 0.020671185106039047, 0.34357354044914246, 0.16293884813785553, -0.4844616949558258, 0.00636171642690897, -0.3124409019947052, 0.32905474305152893, -0.42664146423339844, -0.2230866402387619, 0.3087373971939087, 0.30123233795166016, 0.1192622035741806, 0.28312599658966064, -0.11714572459459305, -0.028294295072555542, -0.1855260282754898, -0.3905510902404785, 0.10450927913188934, 0.15971989929676056, 0.07555986195802689, 0.4089352488517761, 0.35790738463401794, 0.015941206365823746, 0.08932854980230331, 0.19616879522800446, 0.07951805740594864, 0.153985857963562, -0.40032029151916504, 0.10857374966144562, 0.17908170819282532, -0.010841096751391888, 0.20228004455566406, -0.4843880832195282, -0.016403421759605408, -0.2856958210468292, -0.5996050834655762, 0.18830424547195435, 0.1562378704547882, 0.185891792178154, -0.17120523750782013, 0.008638525381684303, 0.24409222602844238, 0.04531530290842056, -0.38444697856903076, -0.27995139360427856, -0.23569191992282867, 0.10875120759010315, -0.22776912152767181, -0.06386047601699829, -0.013574589043855667, -0.2518272399902344, -0.08964838087558746, -0.18750283122062683, 0.15887348353862762, -0.037084899842739105, -0.10819849371910095, 0.01773933507502079, 0.0030180523172020912, 0.16014082729816437, 0.3013620376586914, 0.2294498234987259, -0.10597251355648041, 0.08347026258707047, -0.12620678544044495, 0.08693553507328033, 0.26469698548316956, 0.165034219622612, 0.2706114649772644, -0.25461655855178833, 0.017477218061685562, -0.18232254683971405, -0.023603826761245728, -0.2710793614387512, -0.3615795373916626, 0.18119758367538452, 0.1127733439207077, 0.23153530061244965, 0.5854442715644836, 0.2621700167655945, 0.14804761111736298, 0.009646798484027386, 0.06185195967555046, -0.0770331397652626, 0.3020949959754944, 0.3505798578262329, 0.20599760115146637, -0.02931441366672516, 0.11461173743009567, 0.20510762929916382, -0.04198123514652252, -0.6863721609115601, 0.022673461586236954, 0.09454619139432907, -0.08405952155590057, -0.08149932324886322, -0.14288674294948578, 0.11684563755989075, -0.31089845299720764, 0.444933146238327, 0.6242088079452515, -0.10983893275260925, -0.6202589273452759, -0.32917556166648865, -0.41363444924354553, -0.16785381734371185, -0.32449597120285034, -0.2696037292480469, 0.24853569269180298, 0.20090201497077942, 0.11571167409420013, 0.24790166318416595, 0.2681097090244293, 0.49922361969947815, 0.22850307822227478, 0.15446089208126068, -0.1260899156332016, -0.17963634431362152, -0.3239634037017822, 0.324795663356781, 0.07797222584486008, 0.11009364575147629, -0.04153602570295334, -0.0021335044875741005, 0.3744249641895294, 0.031466804444789886, 0.008314460515975952, -0.002809012308716774, -0.49455273151397705, 0.09927698224782944, -0.4079962372779846, 0.1910342276096344, 0.26556146144866943, -0.09982137382030487, 0.5517827272415161, 0.14899739623069763, 0.03904964029788971, 0.3062341511249542, -0.14849624037742615, -0.10249334573745728, 0.01863345503807068, 0.07259425520896912, -0.3156077265739441, -0.058582853525877, 0.07115093618631363, -0.12583056092262268, -0.381538987159729, -0.4552910029888153, -0.2298937439918518, 0.04475608468055725, -0.0658629983663559, 0.32695236802101135, -0.06662748754024506, 0.12711086869239807, -0.026749305427074432, 0.4202381670475006, -0.28396716713905334, -0.25174087285995483, 0.13448885083198547, 0.020760204643011093, 0.40040159225463867, 0.003327447921037674, -0.15684714913368225, 0.35210368037223816, -0.9093683362007141, 0.20187610387802124, 0.06452509015798569, -0.10078289359807968, -0.1541839987039566, 0.11740098148584366, 0.08369463682174683, -0.09869038313627243, 0.31036481261253357, -0.04224301874637604, -0.24801893532276154, 0.0631435289978981, -0.2498798966407776, 0.35699278116226196, 0.07417789846658707, -0.5510181784629822, 0.16631430387496948, 0.22599907219409943, 0.059501782059669495, 0.08750520646572113, 0.2067820131778717, -0.4945765435695648, -0.3856429159641266, -0.2259228676557541, -0.259779691696167, 0.2152986228466034, -0.09238582104444504, -0.11458612233400345, -0.3496169447898865, 0.33510681986808777, -0.430587500333786, -0.06456548720598221, -0.14355267584323883, 0.17670591175556183, -0.3117120563983917, 0.19721223413944244, -0.112457774579525, 0.031932856887578964, 0.14306041598320007, -0.24211172759532928, 0.02191154472529888, 0.27695906162261963, -0.4538050591945648, 0.3255937695503235, -0.05747991055250168, 0.5070013403892517, -0.25037097930908203, 0.08768226206302643, 0.024436606094241142, 0.03535851091146469, 0.18842780590057373, -0.2708897590637207, 0.26520705223083496, 0.18467113375663757, 0.22521385550498962, -0.042856648564338684, 0.08658977597951889, 0.02651842311024666, -0.2028137892484665, -0.2073802351951599, -0.13154974579811096, 0.07439455389976501, 0.061735570430755615, 0.18987363576889038, 0.07326965034008026, -0.21491773426532745, 0.12129995226860046, 0.09519226104021072, 0.2460012435913086, -0.0869327038526535, -0.15227076411247253, -0.009751875884830952, -0.3016950190067291, -0.3893565833568573, -0.16267786920070648, -0.14007198810577393, 0.1362593173980713, -0.14967584609985352, 0.698445200920105, 0.28595206141471863, 0.19229982793331146, -0.4514982998371124, -0.3472149968147278, 0.1944338083267212, 0.019702550023794174, -0.2071295827627182, -0.048490215092897415, -0.02701745368540287, 0.2652556896209717, -0.0679394081234932, 0.3548341393470764, 0.00733103696256876, 0.28700536489486694, -0.3128036856651306, -0.17483416199684143, 0.11826252192258835, 0.31137439608573914, -0.3777606785297394, 0.16654865443706512, 0.6026749014854431, 0.12352104485034943, 0.2895693778991699, -0.26400497555732727, -0.32582318782806396, -0.3831695318222046, 0.3172500729560852, -0.0008614622056484222, -0.29219019412994385, 0.187445268034935, -0.0029870718717575073, 0.134579598903656, 0.04513268917798996, 0.1012633740901947, -0.3962598145008087, -0.05054540932178497, 0.7283156514167786, 0.03414442390203476, 0.052368368953466415, -0.11271831393241882, 0.1745094358921051, 0.00203726626932621, 0.4796395003795624, 0.02594185620546341, 0.45254379510879517, 0.10230926424264908, 0.14392659068107605, -0.04668975993990898, 0.11864221841096878, -0.13963113725185394, -0.015134667046368122, 0.08304847776889801, -0.11364490538835526, 0.29621365666389465, -0.2858578562736511, -0.08497791737318039, -0.1445862203836441, 0.06827861070632935, -0.18989109992980957, -0.1620146781206131, -0.18971934914588928, 0.14604361355304718, -0.15580368041992188, 0.26219600439071655, 0.10002835839986801, 0.07594488561153412, -0.041191600263118744, -0.09682527929544449, -0.12158409506082535, -0.32081088423728943, 0.005862840451300144, 0.03910357505083084, -0.2081131488084793, 0.22263114154338837, -0.028779469430446625, 0.6100417971611023, 0.1749899834394455, -0.16606880724430084, 0.1286270171403885, 0.025322336703538895, 0.34500181674957275, -0.029204508289694786, 0.31804850697517395, -0.13060922920703888, -0.28054389357566833, -0.17231962084770203, 0.17452886700630188, -0.03462429717183113, -0.26396214962005615, -0.292312353849411, -0.09455715864896774, -0.25230488181114197, 0.2939882278442383, -0.1938946396112442, 0.1895560622215271, -0.2089308500289917, -0.28178873658180237, -0.04644821584224701, -0.28791487216949463, 0.0814998522400856, 0.014421552419662476, 0.022730110213160515, -0.06544776260852814, 0.16202105581760406, 0.050512783229351044, -0.18089580535888672, 0.1783464401960373, 0.19604167342185974, 0.20447003841400146, 0.19794751703739166, -0.2540675103664398, 0.4183909296989441, -0.1167665496468544, 0.07301939278841019, 0.06297970563173294, 0.32400479912757874, 0.029398495331406593, 0.09800301492214203, -0.14844632148742676, 0.33841031789779663, 0.03242860734462738, 0.08103498816490173, 0.03024718537926674, 0.033080264925956726, 0.2816173732280731, 0.010288352146744728, -0.23089680075645447, 0.061601363122463226, 0.08367506414651871, -0.012784808874130249, -0.05740662291646004, -0.04680982604622841, 0.22996942698955536, 0.09567482024431229, 0.20485107600688934, -0.30828040838241577, -0.7743224501609802, 0.21349777281284332, -0.06358468532562256, -0.15243151783943176, -0.2528374195098877, 0.0843275636434555, -0.4339222311973572, -0.056071434170007706, -0.226687952876091, -0.38584527373313904, -0.7075174450874329, 0.062175530940294266, -0.4987888038158417, -0.17930994927883148, 0.1260528564453125, 0.15984007716178894, -0.2579282522201538, -0.10335548222064972, -0.17798392474651337, -0.13627269864082336, -0.24734815955162048, 0.014112008735537529, -0.11166048049926758, -0.09779422730207443, -0.3323372006416321, 0.3287828862667084, -0.20026832818984985, -0.06147274374961853, 0.020255545154213905, 0.10874786227941513, -0.03154642507433891, -0.12734439969062805, 0.08538231253623962, 0.11971323192119598, -0.21777302026748657, 0.039350301027297974, -0.16962182521820068, -0.055571045726537704, 0.29584863781929016, 0.029050752520561218, 0.19706377387046814, 0.14224879443645477, 0.24074804782867432, 0.3766120672225952, 0.5858837962150574, 0.1439167708158493, -0.07916438579559326, 0.17549720406532288, -0.37079742550849915, -0.13857071101665497, 0.352548211812973, -0.5143429040908813, -0.2774292230606079, 0.18627893924713135, -0.005220914259552956, -0.3838677406311035, -0.06411757320165634, 0.4593810737133026, 0.0922841727733612, -0.2358517050743103, -0.22783921658992767, 0.48591336607933044, 0.022366860881447792, -0.35427671670913696, -0.01348557136952877, 0.44088831543922424, 0.13904622197151184, 0.17966385185718536, 0.37981510162353516, 0.2936115264892578, -0.5387045741081238, 0.2990696430206299, 0.23454049229621887, 0.1869606226682663, -0.20729072391986847, -0.32237857580184937, 0.13155515491962433, 0.10915885120630264, -0.11563939601182938, 0.04362472891807556, -0.18145816028118134, -0.22320342063903809, 0.19941727817058563, 0.3928236663341522, 0.13904227316379547, 0.041418179869651794, 0.3171752095222473, 0.4658777713775635, -0.21944014728069305, -0.238817498087883, 0.009292077273130417, -0.14791710674762726, 0.07153133302927017, -0.31015509366989136, 0.5721045136451721, 0.1159973293542862, -0.1571720838546753, -0.09994452446699142, 0.02835065871477127, 0.014474548399448395, -0.14266370236873627, -0.5429494380950928, -0.021284904330968857, -0.31296882033348083, -0.24823768436908722, 0.13602857291698456, -0.20416995882987976, -0.025978492572903633, -0.3871929943561554, -0.07629399001598358, -0.29528629779815674, -0.22988808155059814, 0.04152832180261612, 0.22262781858444214, -0.014944964088499546, -0.21911883354187012, -0.3092018961906433, 0.26229432225227356, 0.0724722295999527, -0.27483096718788147, 0.5984612107276917, -0.23697714507579803, 0.10873287916183472, -0.26342201232910156, -0.1894996166229248, 0.06399042904376984, 0.22346094250679016, -0.008860129863023758, -0.3861677646636963, 0.10505892336368561, 0.09688472002744675, -0.05290481448173523, -0.10778871178627014, -0.03866089880466461, -0.0025765644386410713, -0.26570796966552734, -0.4032886028289795, -0.31115061044692993, 0.17962731420993805, 0.09115523844957352, 0.0405462309718132, 0.28803786635398865, -0.5483978390693665, 0.009869333356618881, 0.140733540058136, 0.0011056400835514069, 0.22630318999290466, 0.14201022684574127, -0.12100064754486084, -0.01138321589678526, 0.17379571497440338, 0.15489095449447632, -0.5459758043289185, 0.09178856760263443, -0.0357867032289505, -0.11810161173343658, -0.01830507442355156, 0.056420646607875824, -0.16203372180461884, 0.0697181224822998, 0.024149712175130844, -0.13952849805355072, 0.12939174473285675, -0.22509530186653137, -0.3215356469154358, 0.07719727605581284, -0.5729852318763733, -0.46673858165740967, -0.04710346460342407, -0.2158641815185547, -0.14120711386203766, -0.149121955037117, -0.059576209634542465, -0.1074746772646904, -0.33292627334594727, 0.15458868443965912, -0.07976748049259186, -0.07444320619106293, -0.10851272940635681, 0.434364914894104, 0.03279935196042061, 0.2581731677055359, -0.07367648929357529, -0.13639934360980988, -0.026931390166282654, 0.22686681151390076, 0.1580113023519516, 0.2646593749523163, -0.10244566947221756, 0.23646259307861328, -0.33622369170188904, -0.4930356740951538, -0.19816854596138, -0.13335539400577545, 0.1289747953414917, -0.3167884349822998, 0.38378599286079407, 0.5104571580886841, 0.0490003302693367, 0.572318434715271, 0.10808367282152176, -0.1667718142271042, -0.47335395216941833, -0.29808735847473145, -0.1546841859817505, -0.04560055211186409, -0.16671967506408691, 0.15684391558170319, -0.35617581009864807, -0.37183868885040283, 0.15313228964805603, -0.0758962407708168, 0.1506943255662918, 0.2459447979927063, 0.1066218689084053, 0.09346366673707962, -0.2445719838142395, -0.35148876905441284, -0.5592332482337952, 0.39871060848236084, -0.055829375982284546, -0.05085053667426109, -0.19757214188575745, 0.03577301651239395, -0.011721177026629448, 0.5339704751968384, 0.5164806246757507, 0.04910501092672348, 0.17127542197704315, -0.35513630509376526, 0.009991777129471302, 0.2622738480567932, 0.03786328434944153, 0.1353408694267273, -0.023803018033504486, 0.2783108949661255, 0.18676221370697021, -0.14092688262462616, 0.29897376894950867, 0.3214340806007385, -0.12478576600551605, -0.08885027468204498, 0.29794248938560486, -0.19893468916416168, -0.2294151932001114, -0.23844274878501892, -0.29393628239631653, 0.18890267610549927, 0.08031050860881805, 0.6709893941879272, 0.10736642777919769, 0.1491396129131317, -0.1583930253982544, -0.15737688541412354, -0.03804334998130798, -0.25027602910995483, 0.1363597959280014, 0.053556106984615326, 0.14978300034999847, -0.4650009274482727, 0.18907596170902252, 0.04337136074900627, 0.17700313031673431, 0.26916778087615967, 0.3339340090751648, 0.1666174679994583, -0.10490601509809494, -0.3201241195201874, -0.5063132643699646, -0.5820340514183044, -0.03926161676645279, 0.39474403858184814, 0.4807916283607483, -0.4576127827167511, 0.11730524897575378, -0.22397443652153015, 0.2398981750011444, 0.06250657141208649, 0.13713715970516205, 0.07350306212902069, -0.3659186065196991, -0.13639163970947266, 0.3389242887496948, 0.1772460639476776, 0.2666071355342865, -0.4402880370616913, 0.023832786828279495, -0.2355191558599472, 0.2926309108734131, -0.34540852904319763, -0.2870712876319885, -0.049953632056713104, 0.160270825[04:03:18]0284195, 0.14960333704948425, -0.4084509611129761, -0.3757224380970001, -0.005333122797310352, 0.20693477988243103, 0.19412676990032196, 0.15402646362781525, -0.09030794352293015, 0.49549993872642517, -0.3955606520175934, 0.29589590430259705, 0.4532298445701599, 0.06624200195074081, -0.10430383682250977, 0.2718382179737091, -0.33200299739837646, -0.3183831572532654, -0.3293535113334656, 0.34884876012802124, 0.05744018405675888, 0.19942276179790497, -0.06341969221830368, -0.3142402172088623, 0.0009054727852344513, -0.08166588842868805, 0.7520222067832947, 0.1931276023387909, -0.37658849358558655, 0.24536322057247162, -0.3947701156139374, 0.056717291474342346, 0.20500537753105164, -0.23695535957813263, -0.6035119891166687, 0.06944169849157333, 0.2560947835445404, 0.40733328461647034, -0.11381958425045013, 0.011839242652058601, 0.06454581022262573, -0.2468871921300888, -0.24376842379570007, -0.3976286053657532, 0.06264571845531464, 0.5275187492370605, 0.15977467596530914, 0.2954343557357788, 0.3783207833766937, 0.2563488781452179, -0.02938930131494999, -0.14520156383514404, -0.35637620091438293, 0.3211607038974762, 0.07891859859228134, 0.3609373867511749, 0.11761166155338287, -0.04596623778343201, -0.40759003162384033, 0.10784841328859329, 0.07346343994140625, 0.12113718688488007, -0.09737817943096161, 0.19709518551826477, 0.22207126021385193, -0.056183673441410065, 0.41900667548179626, -0.16018766164779663, -0.19151832163333893, 0.24933072924613953, -0.010771221481263638, -0.0476592481136322, 0.030012911185622215, -0.06875088065862656, -0.10882687568664551, -0.4071263372898102, 0.1689595878124237, 0.01692383550107479, -0.1942441612482071, 0.1334405392408371, -0.07730593532323837, 0.37975531816482544, -0.14770051836967468, 0.03630535304546356, 0.22151803970336914, 0.1348019242286682, -0.41228190064430237, -0.009592941030859947, -0.13253150880336761, -0.14333078265190125, 0.12663908302783966, 0.06749331206083298, 0.34481510519981384, -0.01809237338602543, 0.1921568661928177, -0.11896679550409317, 0.42976728081703186, 0.023391565307974815, 0.6255058646202087, -0.10791528970003128, 0.19816213846206665, -0.07326994091272354, 0.1722257435321808, -0.008918631821870804, 0.20738360285758972, -0.06636680662631989, 0.6103935241699219, 0.04765670746564865, 0.03459011763334274, 0.47903209924697876, -0.2548537850379944, -0.205408975481987, -0.22307652235031128, -0.15688300132751465, 0.4940417408943176, 0.17433008551597595, 0.24729874730110168, -0.14253279566764832, 0.13255231082439423, 0.6186896562576294, 0.05488692224025726, -0.2224959135055542, -0.19881080090999603, 0.23354265093803406, -0.436097115278244, 0.24989140033721924, 0.061163123697042465, 0.2726971209049225, -0.02897685393691063, -0.14278192818164825, 0.1666129231452942, 0.08350670337677002, -0.004945207387208939, -0.10288112610578537, -0.21493412554264069, 0.3811533749103546, -0.25235411524772644, -0.17506727576255798, -0.11953071504831314, -0.06940705329179764, 0.2120160460472107, 0.10280363261699677, 0.08662467449903488, 0.32685407996177673, -0.04719482362270355, -0.0937296599149704, 0.29832589626312256, -0.16003739833831787, -0.3049694895744324, 0.046319104731082916, -0.05096408352255821, 0.6559005975723267, -0.709608793258667, -0.23770169913768768, 0.33873823285102844, 0.7014372944831848, 0.10218032449483871, -0.05124763026833534, 0.037726011127233505, 0.05137266591191292, 0.20034576952457428, -0.05252906307578087, -0.03791460394859314, 0.13919112086296082, -0.11918752640485764, 0.041547589004039764, -0.18379294872283936, -0.0625307559967041, -0.3266228437423706, -0.24817664921283722, -0.045671433210372925, 0.15488843619823456, 0.10365784913301468, 0.031655535101890564, 0.029781218618154526, 0.30181294679641724, 0.4672106206417084, -0.3344298005104065, -0.40641164779663086, 0.1660464107990265, 0.19911013543605804, 0.09038655459880829, -0.1934579461812973, 0.24044254422187805, 0.08546997606754303, 0.052062369883060455, -0.4600927531719208, -0.3068132698535919, -0.1762879192829132, -0.10446140170097351, 0.26980361342430115, -0.07014371454715729, -0.14002470672130585, 0.10538230091333389, 0.15622419118881226, -0.2695515751838684, -0.2833654582500458, 0.13986614346504211, -0.3071634769439697, -0.2737575173377991, -0.005549301393330097, 0.21623744070529938, -0.05994598567485809, -0.31244438886642456, -0.18757414817810059, 0.1449335813522339, 0.312858521938324, 0.1403532475233078, -0.13434438407421112, 0.05353650823235512, -0.0788891464471817, 0.3801283836364746, -0.41460120677948, -0.25016680359840393, 0.2250051647424698, -0.17025738954544067, 0.3863283693790436, -0.31772980093955994, 0.047560613602399826, -0.009013230912387371, 0.061175499111413956, 0.431693434715271, 0.05078994855284691, 0.3494015336036682, -0.340379923582077, -0.011084798723459244, 0.08881659805774689, 0.16412469744682312, 0.08244086802005768, -0.12600354850292206, 0.224580317735672, 0.3896084129810333, -0.7323351502418518, -0.29924657940864563, 0.25549519062042236, -0.2841807007789612, 0.20188291370868683, -0.014607395976781845, -0.06490876525640488, 0.10668519884347916, 0.015438046306371689, 0.14865443110466003, -0.4656183421611786, -0.04111889377236366, -0.48960497975349426, -0.1789441555738449, 0.26736634969711304, 0.35112446546554565, 0.3100612163543701, 0.2520800828933716, 0.015772731974720955, 0.09314434230327606, 0.23370514810085297, -0.07501661777496338, -0.04132808372378349, -0.09946150332689285, 0.11703880876302719, -0.05606299266219139, -0.011192678473889828, 0.20987901091575623, -0.16657616198062897, -0.10846233367919922, -0.08974955230951309, -0.13484063744544983, 0.06397482752799988, 0.057667076587677, -0.2756268084049225, -0.03381870687007904, -0.06506608426570892, 0.15905871987342834, 0.44486063718795776, 0.025089958682656288, 0.19768376648426056, -0.30216678977012634, -0.19825728237628937, 0.04479439556598663, 0.08090078085660934, -0.3053560256958008, -0.5811432600021362, -0.07872472703456879, -0.43980929255485535, -0.3275763988494873, -0.05810590833425522, 0.624430775642395, -0.19684408605098724, 0.5076770186424255, 0.014177556149661541, 0.193303182721138, 0.2283359169960022, 0.19054870307445526, 0.27345362305641174, 0.2972007095813751, 0.09682789444923401, -0.12182585150003433, -0.015459452755749226, -0.29386112093925476, -0.2299414724111557, 0.02048862725496292, 0.1102222129702568, 0.2413480579853058, 0.005722520407289267, -0.3748738765716553, -0.029894057661294937, 0.01909821107983589, -0.44398024678230286, -0.07385621964931488, 0.15419328212738037, -0.49539613723754883, -0.43168798089027405, -0.20117813348770142, -0.17491520941257477, 0.18372926115989685, -0.3744647800922394, -0.2816251218318939, -0.1636183261871338, -0.02240491285920143, 0.022303558886051178, 0.26033836603164673, -0.14656199514865875, -0.24104195833206177, -0.10492926090955734, 0.06401555985212326, -0.3542293608188629, -0.1963096261024475, 0.08225249499082565, -0.002426730003207922, -0.0012018154375255108, -0.1961255520582199, 0.24676011502742767, 0.0992390364408493, -0.36000704765319824, -0.10727958381175995, 0.22480113804340363, -0.13062521815299988, -0.017578989267349243, -0.18595655262470245, -0.0056744287721812725, -0.3303282856941223, -0.26482853293418884, 0.32677075266838074, -0.2776625454425812, 0.26758846640586853, -0.17366951704025269, 0.09589052945375443, 0.0567651130259037, 0.07992413640022278, -0.3495190441608429, -0.06799299269914627, 0.2531706988811493, -0.09126219898462296, 0.03300609067082405, -0.010300439782440662, 0.12467221170663834, 0.07716953754425049, 0.38173022866249084, 0.5842491984367371, -0.1489778757095337, 0.26609694957733154, 0.31304803490638733, 0.12213262915611267, 0.15228761732578278, 0.030485495924949646, -0.11218155920505524, 0.16315674781799316, 0.3789639174938202, 0.052358150482177734, -0.2061108946800232, -0.6711622476577759, 0.24241520464420319, 0.21732188761234283, -0.16694913804531097, -0.43580833077430725, 0.3230833113193512, -0.05902784690260887, -0.05860003083944321, 0.4425084888935089, 0.2210402637720108, -0.23283807933330536, -0.3344469368457794, 0.4523845613002777, 0.445747047662735, -0.22378535568714142, -0.42759719491004944, -0.26127541065216064, -0.11170931160449982, -0.1660594940185547, 0.03555761277675629, -0.07176309078931808, -0.43650269508361816, -0.19401302933692932, 0.06392368674278259, -0.24098554253578186, 0.14669451117515564, -0.09260240942239761, -0.3179517388343811, -0.20925326645374298, -0.18402741849422455, -0.15766681730747223, -0.14586225152015686, 0.007106192409992218, 0.366047739982605, -0.2581489384174347, -0.21406707167625427, 0.048346806317567825, 0.19810815155506134, 0.12334336340427399, 0.21229614317417145, -0.14692485332489014, 0.18543675541877747, 0.07788866013288498, -0.10155438631772995, -0.2665165662765503, -0.3380238115787506, 0.08232831954956055, 0.2675955295562744, -0.0925985798239708, -0.057994093745946884, 0.502001166343689, -0.2970220744609833, 0.226745143532753, -0.49539437890052795, -0.36215469241142273, -0.2851494550704956, -0.23751018941402435, 0.10056376457214355, -0.23845839500427246, -0.14464713633060455, -0.09897717833518982, 0.06845390051603317, -0.07734039425849915, 0.06439217180013657, -0.061317622661590576, 0.0020022413227707148, -0.4107309877872467, -0.3479078412055969, 0.0331491194665432, 0.342440664768219, 0.1492835283279419, 0.1361391693353653, -0.17733372747898102, -0.18063819408416748, 0.16007518768310547, 0.23801963031291962, 0.27430060505867004, -0.0008251769468188286, -0.07520593702793121, 0.05351128801703453, -0.5259031653404236, 0.07559621334075928, -0.07321736961603165, -0.19659224152565002, 0.3535939157009125, 0.025964200496673584, 0.21765640377998352, 0.26714739203453064, 0.4121452569961548, 0.12755855917930603, 0.2619374394416809, 0.11856861412525177, -0.6027534008026123, -0.3462643325328827, 0.38916102051734924, -0.15785762667655945, 0.12470445036888123, -0.5643418431282043, -0.0264828409999609, -0.1377740055322647, 0.11799212545156479, -0.27519896626472473, 0.03851477429270744, 0.04202206805348396, -0.13350772857666016, 0.23430612683296204, -0.04234660044312477, -0.440279096364975, -0.07522477954626083, 0.19150593876838684, -0.3357616662979126, -0.6792833209037781, 0.13455668091773987, -0.03237415850162506, 0.247248575091362, -0.13908647000789642, 0.005796127486974001, -0.04453401640057564, 0.2724740207195282, 0.12401992082595825, -0.07697850465774536, -0.07885757833719254, -0.015705687925219536, -0.3361564874649048, -0.4112606942653656, 0.44588494300842285, -0.3091486990451813, -0.2346591353416443, -0.23816505074501038, 0.23797041177749634, -0.035464879125356674, -0.44728800654411316, 0.055338166654109955, -0.12201452255249023, -0.013151668943464756, 0.3701621890068054, 0.2599610686302185, 0.1298338621854782, -0.07758110761642456, -0.07493020594120026, -0.3308239281177521, -0.40793436765670776, -0.010656145401299, 0.21437503397464752, -0.619426429271698, 0.2346302568912506, 0.13327676057815552, 0.10165494680404663, -0.15780207514762878, 0.13132770359516144, 0.15292903780937195, -0.2942091226577759, 0.10608208924531937, -0.13969646394252777, 0.30928611755371094, -0.6217488050460815, 0.6625334620475769, 0.01987411454319954, 0.09771949797868729, -0.11463195085525513, 0.4012567698955536, -0.004469025414437056, 0.7989456653594971, -0.3505590856075287, 0.46548572182655334, -0.13967378437519073, -0.08977038413286209, -0.08662275224924088, -0.04583750292658806, -0.16697914898395538, 0.22345151007175446, 0.05007362365722656, 0.25665751099586487, -0.05411572754383087, -0.08337517082691193, 0.12124332040548325, -0.09028986096382141, -0.11755211651325226, 0.262816846370697, 0.21221919357776642, 0.21376734972000122, 0.040631502866744995, 0.0790037140250206, 0.2978760898113251, 0.36566510796546936, -0.2676621377468109, 0.05127861350774765, -0.32006463408470154, -0.38304004073143005, 0.5488232374191284, -0.2560080885887146, 0.1630801558494568, 0.1754670888185501, 0.16267240047454834, -0.2719632089138031, -0.028530584648251534, 0.017591286450624466, -0.11469902843236923, -0.4040307104587555, -0.3334384858608246, -0.03185151889920235, -0.22847259044647217, 0.13526096940040588, -0.2539549469947815, 0.019599683582782745, 0.14776962995529175, 0.4695315957069397, 0.3016034960746765, -0.26598525047302246, 0.19883136451244354, -0.034692782908678055, -0.22808849811553955, 0.047874122858047485, -0.0390637144446373, 0.21051780879497528, -0.12663167715072632, 0.35223639011383057, 0.206088125705719, 0.22273556888103485, 0.19543620944023132, 0.06778375059366226, 0.4325169324874878, 0.15646563470363617, -0.5818257927894592, -0.3625432252883911, -0.04398160055279732, 0.19676347076892853, -0.28252366185188293, 0.04328775778412819, 0.6221411824226379, 0.12516412138938904, -0.4602741301059723, -0.34918516874313354, -0.07046697288751602, 0.00923493504524231, -0.08241304755210876, -0.8022873401641846, 0.18842405080795288, -0.41570693254470825, -0.0952116847038269, 0.23304709792137146, -0.061636824160814285, -0.11258963495492935, 0.08073745667934418, -0.2407657653093338, -0.17399369180202484, -0.11500313133001328, 0.048439767211675644, 0.04718228802084923, -0.1457301676273346, -0.1669178009033203, 0.15054161846637726, 0.03397849202156067, 0.48778653144836426, 0.09290801733732224, -0.5616750121116638, 0.3229183554649353, -0.36207589507102966, -0.4135172367095947, 0.1356344223022461, -0.29799267649650574, -0.2557068169116974, -0.1008787527680397, -0.4360877275466919, -0.40057873725891113, 0.25271889567375183, 0.23306860029697418, 0.0356578454375267, 0.060214683413505554, -0.05678050220012665, 0.193213552236557, 0.0925302729010582, 0.08050414174795151, -0.2533208727836609, 0.2982500195503235, 0.24986454844474792, 0.02617354318499565, 0.20823641121387482, 0.5444446206092834, -0.4478549361228943, -0.40962469577789307, 0.32141420245170593, 0.10681891441345215, -0.05509764701128006, -0.00536591000854969, -0.5460341572761536, -0.4878338873386383, 0.09137440472841263, 0.5422283411026001, 0.0070686861872673035, 0.6122578978538513, -0.08541790395975113, -0.10029567033052444, 0.2066168636083603, -0.2524319589138031, -0.12969782948493958, 0.07563800364732742, -0.0058291275054216385, -0.3083101809024811, 0.11174953728914261, 0.030724182724952698, 0.005228522699326277, 0.19864358007907867, -0.001231116708368063, 0.1741309016942978, 0.13820268213748932, -0.2507413327693939, -0.13646578788757324, -0.0013524889945983887, 0.3444216549396515, -0.22794172167778015, 0.31131401658058167, -0.3048384487628937, 0.07141120731830597, 0.12076090276241302, 0.10554433614015579, -0.47120124101638794, -0.22735685110092163, 0.17601223289966583, -0.08807788789272308, -0.008233901113271713, -0.04340193793177605, 0.0006280429661273956, 0.07486606389284134, 0.027069585397839546, 0.15953852236270905, 0.19057916104793549, 0.2541453540325165, -0.07049862295389175, -0.24108296632766724, 0.041544340550899506, -0.47172895073890686, 0.03153311833739281, 0.02681741863489151, 0.38750985264778137, -0.1045236587524414, -0.18501411378383636, 0.06917687505483627, 0.15063650906085968, -0.23220211267471313, 0.19531996548175812, 0.4416523575782776, 0.1950063407421112, 0.17669957876205444, 0.5297751426696777, 0.3865524232387543, 0.21197842061519623, -0.07568386942148209, -0.21571826934814453, -0.1510932445526123, 0.3900770843029022, -0.29803892970085144, 0.16383178532123566, -0.1451026350259781, -0.019272690638899803, -0.0926240086555481, -0.1767861545085907, 0.4521709978580475, 0.3154512047767639, 0.17060917615890503, 0.1503283828496933, -0.1315813660621643, 0.15474429726600647, 0.10894304513931274, 0.06580226123332977, 0.17442038655281067, 0.00522281788289547, 0.021353881806135178, 0.11580775678157806, -0.40537458658218384, -0.15158605575561523, 0.16797767579555511, -0.4453153908252716, 0.0881078839302063, 0.3602692782878876, -0.47265779972076416, 0.17150892317295074, -0.14061321318149567, 0.12511326372623444, 0.17778491973876953, -0.012690862640738487, -0.3718850016593933, 0.3545224666595459, -0.3978201448917389, 0.31903210282325745, -0.13828207552433014, 0.01256401278078556, -0.519318699836731, 0.6121496558189392, -0.06652992218732834, 0.005463758017867804, -0.05250593274831772, 0.37220335006713867, 0.4382096827030182, 0.12678244709968567, -0.018771523609757423, 0.30325108766555786, 0.2632127106189728, 0.0013738940469920635, 0.04690302908420563, -0.06656739860773087, -0.11008019000291824, 0.28373420238494873, -0.11783715337514877, 0.44650718569755554, 0.16985054314136505, -0.01484289113432169, -0.24821248650550842, -0.013928353786468506, 0.2532840669155121, -0.1503581553697586, 0.29344454407691956, -0.024113543331623077, -0.37663528323173523, -0.10629336535930634, -0.11170022934675217, 0.18953987956047058, 0.4314427375793457, 0.5489669442176819, -0.016677668318152428, 0.5436680912971497, 0.33193710446357727, 0.3674331605434418, 0.2815503478050232, -0.29756924510002136, 0.18167835474014282, 0.39577046036720276, -0.12501215934753418, 0.04182674363255501, 0.030884109437465668, -0.36246833205223083, -0.18899573385715485, 0.015316012315452099, 0.20052649080753326, 0.5344122648239136, 0.5614798069000244, -0.1503094732761383, 0.018105054274201393, -0.18547725677490234, -0.12156851589679718, -0.18240994215011597, 0.6350615620613098, -0.24366454780101776, -0.0038049863651394844, 0.1127140074968338, 0.3538149893283844, 0.4394817054271698, -0.03527501970529556, 0.07822022587060928, -0.12068115919828415, 0.3047838807106018, 0.0348910428583622, -0.07124581933021545, -0.5016176700592041, 0.17984241247177124, -0.20002833008766174, 0.27406901121139526, -0.024591684341430664, 0.12144837528467178, -0.21070078015327454, 0.0933908224105835, 0.35397568345069885, -0.2887996733188629, -0.20370720326900482, -0.5089613795280457, 0.12509959936141968, 0.019271399825811386, -0.4507002830505371, 0.5951627492904663, -0.3913004398345947, -0.01914539560675621, 0.04688743129372597, 0.03865305334329605, -0.06433987617492676, -0.06189458817243576, -0.41689327359199524, 0.16098804771900177, 0.07817528396844864, 0.39246442914009094, -0.04130303114652634, -0.03934379667043686, -0.21073907613754272, 0.5892271399497986, -0.10491810739040375, -0.20446205139160156, 0.4322333037853241, -0.4191787838935852, 0.019249223172664642, -0.013773196376860142, -0.32802003622055054, -0.05411068722605705, -0.40083393454551697, -0.3371194303035736, -0.04938511550426483, 0.09449201077222824, -0.15813016891479492, -0.0336483009159565, -0.48667335510253906, -0.16406597197055817, 0.14426109194755554, -0.059184782207012177, -0.15709158778190613, 0.1634412258863449, 0.20726391673088074, 0.5276558995246887, -0.21519909799098969, -0.33337104320526123, -0.5386123657226562, -0.08001553267240524, -0.25397738814353943, 0.2734164893627167, -0.09989585727453232, -0.10576079785823822, 0.008662018924951553, -0.30284255743026733, 0.1250842809677124, -0.1409108191728592, -0.20756161212921143, -0.1648295819759369, 0.24923011660575867, 0.4612914025783539, -0.634537398815155, -0.1554470658302307, 0.2090655267238617, 0.10834915935993195, -0.3970310091972351, 0.18586255609989166, 0.218425452709198, 0.3276868164539337, 0.004573897458612919, -0.06570275127887726, 0.464815229177475, 0.20016223192214966, 0.16286759078502655, -0.34308499097824097, 0.267570436000824, 0.2379329651594162, -0.2954253554344177, -0.41557106375694275, -0.012635527178645134, 0.16524048149585724, -0.5355381369590759, 0.1264265924692154, -0.14389091730117798, -0.1279882788658142, 0.29617825150489807, -0.35604536533355713, -0.3101904094219208, -0.2763315439224243, -0.2738853991031647, -0.14631491899490356, 0.09822074323892593, -0.10822530835866928, -0.08576280623674393, -0.20738503336906433, 0.39917898178100586, -0.09183545410633087, 0.06540080904960632, 0.0228344164788723, -0.34343820810317993, -0.03311280906200409, -0.1659896820783615, -0.27713143825531006, 0.020725078880786896, 0.07703544944524765, -0.07243739813566208, 0.07080643624067307, 0.7887364029884338, -0.05806939676403999, 0.24840311706066132, -0.2675383687019348, -0.011126281693577766, -0.03485697880387306, 0.4417492747306824, 0.006364290602505207, 0.10935544222593307, 0.03904564678668976, 0.29417526721954346, 0.19262105226516724, 0.27584779262542725, 0.20074248313903809, 0.08246445655822754, -0.0893925130367279, -0.07499350607395172, 0.34991341829299927, 0.005018514581024647, 0.0092470096424222, -0.07643313705921173, 0.17306296527385712, 0.38961824774742126, -0.2061564326286316, 0.07453318685293198, -0.016390472650527954, 0.16062237322330475, -0.03506036475300789, 0.10092762857675552, -0.03121456503868103, 0.1948145031929016, -0.0048786960542202, 0.13545432686805725, 0.0590408556163311, -0.06489788740873337, -0.29997870326042175, -0.0918567031621933, -0.0210744459182024, -0.026923110708594322, -0.16349796950817108, -0.3288500905036926, 0.1879449337720871, -0.3571648597717285, 0.06906835734844208, -0.43376898765563965, 0.23512955009937286, 0.18127161264419556, 0.002822335809469223, -0.24493977427482605, -0.24461528658866882, -0.17536373436450958, -0.2668966054916382, 0.46799203753471375, 0.26531296968460083, 0.2289828360080719, -0.07043366134166718, -0.2390579730272293, 0.34275221824645996, -0.04582664743065834, -0.5818540453910828, -0.043754350394010544, -0.13289517164230347, -0.4183304011821747, 0.08458323031663895, 0.10279334336519241, -0.012840067967772484, -0.1681647151708603, -0.09133639931678772, -0.3443116545677185, -0.08989834040403366, -0.5123436450958252, -0.08331800252199173, 0.2782290279865265, 0.30066120624542236, -0.3299359977245331, -0.04547451436519623, 0.05985385924577713, 0.1913100779056549, 0.18453438580036163, 0.38765302300453186, 0.5515962839126587, -0.5355423092842102, -0.18245407938957214, -0.24297215044498444, 0.22168709337711334, 0.13737037777900696, 0.44571566581726074, -0.03362153470516205, 0.01579980179667473, -0.5063525438308716, -0.05895524471998215, -0.03133279085159302, 0.030149472877383232, 0.32139089703559875, -0.028228478506207466, 0.13534578680992126, -0.2741130590438843, -0.1443510800600052, -0.19767993688583374, 0.04865887016057968, 0.10296399146318436, 0.2162613421678543, -0.11682268232107162, 0.024615295231342316, -0.24505610764026642, 0.05604007840156555, -0.24677175283432007, 0.06230068579316139, 0.035538431257009506, -0.3346743583679199, -0.04800788685679436, -0.2868471145629883, 0.02187711000442505, 0.01028498075902462, -0.011512277647852898, 0.25967106223106384, 0.11713939905166626, 0.2276211977005005, 0.14739543199539185, 0.6970019936561584, 0.07768486440181732, -0.21395492553710938, -0.5127426385879517, 0.39747127890586853, -0.1014152243733406, 0.009836706332862377, -0.13898858428001404, 0.3432086110115051, -0.21349933743476868, -0.11830306053161621, -0.01703530177474022, 0.6182603240013123, -0.051813509315252304, 0.19068914651870728, 0.4417784810066223, 0.11260148137807846, -0.3894611597061157, 0.06608045101165771, -0.2515330910682678, -0.2492813915014267, 0.006201292388141155, -0.17261959612369537, -0.17663010954856873, -0.008295649662613869, 0.2443319410085678, -0.1529257446527481, 0.09296126663684845, -0.08964700996875763, -0.5494345426559448, -0.13549496233463287, -0.45134514570236206, 0.16494783759117126, -0.03635471314191818, -0.06863738596439362, -0.18745499849319458, 0.22576244175434113, -0.10009891539812088, -0.17520026862621307, 0.013441605493426323, 0.06522412598133087, 0.11961650848388672, -0.007878627628087997, -0.3486010730266571, 0.2964794635772705, 0.28474652767181396, -0.04945899546146393, -0.005850490182638168, -0.34386008977890015, -0.23823553323745728, -0.15457603335380554, 0.30027997493743896, 0.3250250816345215, 0.06477362662553787, -0.22883078455924988, 0.14239035546779633, -0.1697104573249817, 0.007167535368353128, 0.07238317281007767, -0.14452895522117615, 0.4469156563282013, -0.08605289459228516, -0.3321313261985779, 0.04231223464012146, 0.03997784107923508, -0.04858935624361038, 0.16813836991786957, 0.45446398854255676, 0.05528322234749794, 0.2943294048309326, -0.18991747498512268, 0.3624584674835205, -0.2199152410030365, 0.32487839460372925, -0.5964881777763367, -0.39821311831474304, -0.07990235090255737, -0.20432579517364502, -0.019437050446867943, -0.1544070839881897, -0.043231286108493805, -0.1217254102230072, 0.3755152225494385, -0.01797502487897873, -0.06825153529644012, -0.026892028748989105, -0.10024324059486389, -0.09937237203121185, -0.1681835949420929, -0.14893774688243866, -0.16375969350337982, -0.20485526323318481, -0.08904203027486801, 0.28245973587036133, -0.1566430777311325, -0.10804803669452667, 0.04572606459259987, -0.2194475680589676, 0.26277193427085876, -0.03912784159183502, 0.29674240946769714, 0.3309990465641022, -0.12359482795000076, -0.03476667031645775, -0.07363063842058182, -0.17898859083652496, 0.3447287082672119, -0.13115757703781128, 0.08687035739421844, 0.22232602536678314, 0.3378424644470215, -0.09621594846248627, 0.017631689086556435, -0.022852687165141106, -0.21387049555778503, -0.016063980758190155, 0.12555894255638123, -0.0987170934677124, 0.1930965930223465, -0.16326700150966644, 0.0023996802046895027, -0.0341150239109993, 0.5893941521644592, 0.08000724762678146, 0.052609674632549286, -0.16660109162330627, 0.038018129765987396, 0.14706368744373322, 0.2127184271812439, -0.059394970536231995, -0.04976639896631241, 0.5829349756240845, -0.30722516775131226, 0.02018311433494091, -0.1523411124944687, 0.10397405177354813, 0.15023019909858704, 0.19511836767196655, -0.23627665638923645, -0.04159622639417648, -0.09921228140592575, -0.014527457766234875, 0.6717625260353088, 0.13722750544548035, -0.023988619446754456, 0.1060677245259285, 0.3234189450740814, 0.4050976634025574, -0.1362861692905426, -0.2550441324710846, 0.5130767822265625, 0.41855376958847046, 0.20983265340328217, -0.02821803279221058, 0.024995386600494385, -0.10254748910665512, 0.3734491765499115, 0.18926335871219635, 0.22672529518604279, -0.4394526481628418, 0.3193276524543762, 0.40548595786094666, 0.05638321116566658, 0.32228031754493713, -0.0760379284620285, 0.11639757454395294, -0.057121019810438156, 0.16289809346199036, 0.03665376454591751, 0.015214209444820881, 0.06594491004943848, 0.36166781187057495, 0.041155897080898285, 0.3288721442222595, 0.12775088846683502, 0.24673643708229065, -0.07690301537513733, -0.03886289522051811, 0.4333811104297638, -0.21956533193588257, 0.5451732277870178, 0.2584543824195862, -0.12023119628429413, -0.04008439928293228, 0.24448326230049133, -0.022214844822883606, -0.05769970268011093, -0.1465863585472107, 0.35338446497917175, 0.2550244927406311, -0.3342045247554779, 0.044591933488845825, -0.5208319425582886, 0.06819280982017517, -0.0715041384100914, 0.35187581181526184, 0.3005897104740143, 0.24962970614433289, -0.09857980161905289, -0.41293948888778687, 0.058356400579214096, 0.3757261633872986, 0.04075067117810249, -0.3814047873020172, -0.11419123411178589, 0.13530752062797546, 0.14392848312854767, 0.24524997174739838, -0.3711049556732178, -0.10399837791919708, 0.10699485242366791, -0.2983234226703644, -0.5072367787361145, -0.35423004627227783, 0.034880056977272034, 0.5026630163192749, -0.08547744154930115, 0.5617827773094177, 0.01747482270002365, 0.10643871128559113, 0.2441801279783249, -0.41112565994262695, -0.05403154343366623, -0.00397898256778717, -0.017106225714087486, 0.03794602304697037, 0.14889350533485413, 0.35319894552230835, -0.021213088184595108, -0.17620770633220673, -0.16924411058425903, 0.42781081795692444, -0.36159586906433105, -0.10555122792720795, 0.014097683131694794, -0.36334681510925293, 0.00451703742146492, 0.3090406060218811, -0.16641762852668762, 0.20067176222801208, -0.11620268225669861, -0.20098641514778137, 0.30159667134284973, 0.02503514662384987, 0.2087271511554718, -0.13896705210208893, 0.3932027518749237, -0.2307521253824234, 0.2859140932559967, -0.04987434670329094, -0.2939414381980896, -0.25626710057258606, -0.06652169674634933, 0.0037489384412765503, -0.32048487663269043, -0.2533356845378876, -0.18739153444766998, -0.0969548225402832, -0.1195937991142273, -0.3291480243206024, -0.8386882543563843, 0.0607207827270031, -0.04466363042593002, 0.1535666435956955, 0.324324369430542, 0.6117973923683167, -0.5493592619895935, -0.029060227796435356, -0.11887363344430923, -0.3162856101989746, -0.05950460210442543, 0.1758747547864914, -0.26385974884033203, -0.15449051558971405, -0.23957596719264984, -0.06227082759141922, 0.04688639938831329, -0.2394203096628189, -0.1855853796005249, -0.0687825083732605, 0.08410708606243134, -0.36360499262809753, -0.019152823835611343, 0.38035815954208374, -0.41157883405685425, 0.20892485976219177, -0.10028418153524399, 0.3816061019897461, 0.27282774448394775, -0.10491951555013657, 0.1852511316537857, 0.194187730550766, -0.025882143527269363, 0.14652182161808014, -0.23925544321537018, -0.19892574846744537, -0.08760879933834076, 0.06986033916473389, 0.14675791561603546, 0.2596369981765747, -0.12014814466238022, -0.5798794627189636, 0.19208155572414398, 0.11525823920965195, 0.11655942350625992, 0.1734657883644104, 0.2746399939060211, -0.05618685483932495, 0.251782089471817, 0.2739724814891815, 0.059701401740312576, 0.1651490479707718, -0.023119140416383743, 0.30411195755004883, -0.47027862071990967, 0.08955810964107513, -0.6316811442375183, -0.021506618708372116, -0.5790191888809204, -0.08944722265005112, 0.17036105692386627, 0.26965850591659546, 0.09797612577676773, -0.16904020309448242, -0.14029118418693542, 0.017528677359223366, 0.04896378889679909, 0.2444133460521698, -0.04032309725880623, -0.6714460849761963, -0.17376087605953217, -0.0014075199142098427, -0.488998681306839, -0.13484525680541992, -0.2925269603729248, 0.08322116732597351, -0.1796354353427887, -0.06502261012792587, -0.05971135199069977, -0.3745098412036896, -0.16676324605941772, 0.019483964890241623, -0.04796295613050461, -0.09959311783313751, 0.21361902356147766, -0.09881387650966644, -0.21465037763118744, -0.32144802808761597, 0.13957975804805756, 0.2877090871334076, -0.1693355292081833, 8.615292608737946e-05, -0.18899880349636078, 0.04463411867618561, -0.09087873995304108, 0.42700719833374023, -0.09028305858373642, 0.4195947051048279, 0.1550154685974121, -0.3315845727920532, 0.2506504952907562, 0.14764976501464844, -0.4304776191711426, 0.10114438831806183, 0.14176248013973236, -0.1677713245153427, -0.06742686033248901, -0.16801464557647705, -0.008548149839043617, -0.13005909323692322, 0.18560943007469177, 0.14422164857387543, -0.17578233778476715, -0.08196354657411575, -0.31192445755004883, -0.1158667504787445, -0.056391723453998566, 0.585544764995575, 0.1731400489807129, -0.00115105789154768, 0.26283103227615356, -0.105418860912323, -0.23619644343852997, 0.22084367275238037, -0.13050220906734467, 0.3698161542415619, -0.21234093606472015, 0.2676120400428772, -0.23723569512367249, -0.09942346811294556, 0.41247743368148804, -0.010998918674886227, 0.12097059190273285, -0.05977337807416916, -0.15712271630764008, 0.09729588031768799, -0.09069227427244186, 0.471007376909256, -0.25799641013145447, 0.27943184971809387, 0.3065713346004486, 0.04257119819521904, 0.10927069932222366, -0.042006965726614, 0.047985292971134186, -0.3384052515029907, -0.13817369937896729, -0.15002943575382233, -0.08476447314023972, -0.7581685185432434, 0.4196011424064636, 0.29428577423095703, 0.030429702252149582, -0.07084620743989944, 0.1425859034061432, -0.19393087923526764, 0.18156792223453522, 0.20308241248130798, -0.1201145276427269, 0.11254330724477768, 0.16346994042396545, -0.0941513404250145, -0.25263622403144836, 0.5014766454696655, 0.3631647527217865, 0.5058159828186035, 0.4176076054573059, 0.096949003636837, 0.0791742280125618, 0.22136926651000977, 0.34992390871047974, -0.48288020491600037, 0.21603618562221527, -0.4148430824279785, 0.23848477005958557, 0.1700005680322647, 0.5181679129600525, 0.19213011860847473, -0.5012410879135132, 0.18591488897800446, 0.17075739800930023, 0.35483795404434204, 0.07220913469791412, -0.11062071472406387, 0.09385830909013748, 0.1343289017677307, 0.18913030624389648, -0.10929184406995773, 0.6974979639053345, -0.03184833377599716, -0.04563898220658302, -0.2533910572528839, -0.3807494640350342, 0.18437378108501434, -0.20033559203147888, 0.1018906980752945, -0.1928449273109436, -0.08276019990444183, 0.16541419923305511, 0.0808245837688446, 0.19911369681358337, -0.1644507646560669, -0.3224650025367737, -0.329642117023468, 0.04737366363406181, 0.2170235961675644, 0.19466397166252136, -0.23013466596603394, 0.4198651611804962, -0.022699210792779922, -0.183136984705925, 0.031034179031848907, 0.2443692833185196, -0.15779832005500793, -0.13697397708892822, 0.020882075652480125, -0.2760004699230194, 0.06830962002277374, -0.16854827105998993, 0.2576044499874115, -0.4854315519332886, 0.18602634966373444, -0.06351719051599503, -0.018681764602661133, 0.20790472626686096, -0.15683086216449738, 0.5759782791137695, -0.5539723038673401, -0.25045186281204224, 0.167698934674263, -0.2663697302341461, -0.12586000561714172, 0.22515013813972473, 0.05433660000562668, 0.5713780522346497, 0.031099185347557068, 0.1479751467704773, 0.06352870911359787, -0.22744686901569366, 0.007300416007637978, -0.2053651213645935, -0.11413712799549103, 0.27391159534454346, 0.2116125375032425, 0.5301288366317749, -0.3539138436317444, -0.30404388904571533, 0.21649256348609924, -0.29658928513526917, -0.05651773512363434, -0.030923891812562943, 0.30431637167930603, -0.2929500341415405, 0.06303168833255768, 0.07910425215959549, 0.1993863582611084, 0.46843135356903076, -0.18453116714954376, -0.42426377534866333, 0.14310091733932495, -0.0025217102374881506, 0.2155946046113968, -0.1476924568414688, 0.25671127438545227, 0.28406137228012085, -0.4508851170539856, 0.3257851302623749, 0.11346110701560974, -0.28029030561447144, 0.12063952535390854, 0.010135163553059101, 0.21302610635757446, 0.5115125775337219, 0.1357985883951187, -0.013914402574300766, 0.16071662306785583, 0.11413207650184631, -0.19745582342147827, -0.03990375995635986, -0.08096791058778763, 0.23055338859558105, 0.061997007578611374, 0.26650470495224, -0.10153983533382416, -0.022678740322589874, -0.41831302642822266, 0.1478731334209442, 0.25704026222229004, -0.130820170044899, -0.3560331463813782, -0.2969486713409424, -0.6867450475692749, 0.11684045195579529, -0.0669359564781189, -0.22342801094055176, 0.04735356569290161, 0.6438831090927124, 0.06381812691688538, -0.06649698317050934, 0.12929342687129974, 0.2673463523387909, 0.40589383244514465, 0.04078303277492523, -0.14718882739543915, 0.3407458961009979, -0.23023883998394012, 0.27695587277412415, -0.37301838397979736, 0.01446277555078268, -0.2324177771806717, -0.3635009825229645, 0.07168843597173691, 0.1778969019651413, -0.16512495279312134, -0.03451048582792282, -0.4264972507953644, -0.041846863925457, 0.16966013610363007, -0.7549986243247986, 0.12656664848327637, 0.3559589087963104, -0.12569968402385712, -0.12885639071464539, -0.04017086699604988, 0.1020679622888565, -0.324747771024704, -0.1500454545021057, 0.02980746328830719, -0.0003539975732564926, -0.33795711398124695, -0.3431670069694519, 0.2481355369091034, -0.10023816674947739, 0.15998585522174835, -0.01784851774573326, 0.11826149374246597, 0.4461314380168915, 0.054465197026729584, -0.2987884283065796, 0.1779642403125763, 0.16476018726825714, -0.24431970715522766, -0.13102002441883087, -0.11290553957223892, -0.10124672204256058, -0.1294558048248291, 0.1358116716146469, -0.11172560602426529, -0.44356879591941833, -0.12313828617334366, -0.10960777848958969, 0.07063917815685272, 0.12687993049621582, -0.5496239066123962, 0.28438955545425415, 0.2909368574619293, 0.20356418192386627, 0.011169460602104664, -0.0006625372916460037, -0.33758270740509033, -0.18095724284648895, -0.13711313903331757, -0.27682244777679443, 0.17707563936710358, -0.18323349952697754, -0.6315507292747498, -0.2453051656484604, 0.2598150074481964, 0.002140158787369728, 0.07884839177131653, 0.05587894842028618, 0.3618578016757965, -0.5370166301727295, 0.11708533763885498, 0.2891392111778259, -0.1352270543575287, -0.11509169638156891, -0.08769264072179794, 0.03121664747595787, 0.40602201223373413, -0.12699410319328308, 0.3304629921913147, 0.2043887823820114, 0.1389753371477127, -0.07940339297056198, 0.29504454135894775, 0.29121872782707214, 0.06608252972364426, 0.2574593424797058, 0.13237762451171875, -0.129018172621727, 0.20009960234165192, -0.3761989176273346, 0.16801288723945618, 0.0068142227828502655, 0.5390497446060181, -0.13274751603603363, -0.2791355550289154, 0.1003098264336586, -0.06765507906675339, -0.13280248641967773, 0.10890459269285202, -0.039983611553907394, -0.07566763460636139, -0.368804395198822, -0.22914981842041016, 0.3883906602859497, -0.19569844007492065, -0.07022424042224884, -0.17116010189056396, 0.03695514425635338, 0.19380256533622742, -0.029504865407943726, 0.12062138319015503, -0.2650590240955353, -0.2164493352174759, 0.1316036432981491, -0.3286001980304718, 0.20362824201583862, 0.30198514461517334, 0.0011863606050610542, -0.2690638601779938, 0.23395730555057526, -0.1402129977941513, 0.14025874435901642, -0.05841369181871414, -0.29438766837120056, -0.15774698555469513, 0.4232636094093323, -0.023120392113924026, -0.12640808522701263, 0.11345915496349335, 0.24870708584785461, -0.31952792406082153, 0.015407035127282143, 0.06468074023723602, 0.291881799697876, 0.16749215126037598, 0.3854084610939026, 0.026463989168405533, -0.6082428693771362, -0.09685052186250687, 0.6248672604560852, -0.07998855412006378, 0.13274401426315308, 0.14471369981765747, 0.009447688236832619, -0.13332237303256989, -0.4345783591270447, 0.38391244411468506, 0.10859882831573486, 0.11540669202804565, 0.3851245939731598, 0.10125875473022461, 0.6526855230331421, 0.3638778626918793, -0.23882032930850983, 0.09418655931949615, 0.010092604905366898, 0.08140971511602402, 0.4305211305618286, -0.012018006294965744, -0.24404709041118622, -0.3399401307106018, 0.19033336639404297, 0.039100661873817444, -0.10818464308977127, -0.3188149631023407, 0.061850614845752716, -0.1460694670677185, 0.09048759937286377, 0.05910440534353256, 0.3853529393672943, -0.3066987991333008, -0.08904948085546494, -0.20048201084136963, 0.13540108501911163, -0.3360523283481598, -0.08244147151708603, -0.019906114786863327, 0.010357620194554329, -0.3191532790660858, -0.044120609760284424, -0.16707928478717804, -0.10028059035539627, -0.18282607197761536, 0.19518038630485535, -0.4222147464752197, 0.256045937538147, -0.2637290060520172, 0.17596054077148438, -0.13580219447612762, -0.3631698787212372, 0.01943916454911232, 0.35776638984680176, -0.12268393486738205, 0.018575657159090042, 0.3221844434738159, 0.10779427736997604, -0.1141795665025711, 0.23406299948692322, -0.22175250947475433, -0.3152371048927307, -0.17734789848327637, -0.06648525595664978, -0.7068200707435608, -0.08820588141679764, 0.19306273758411407, -0.2439340502023697, -0.07552611827850342, -0.3779177665710449, 0.18540900945663452, 0.2340855896472931, 0.19358813762664795, -0.05994626134634018, -0.2665308713912964, 0.5326111316680908, -0.5573934316635132, 0.20131342113018036, -0.14127086102962494, 0.07234100252389908, 0.21343910694122314, -0.5874510407447815, -0.12530705332756042, 0.32636427879333496, 0.47948405146598816, -0.3789653480052948, 0.22571751475334167, 0.07306180149316788, 0.10149084776639938, 0.48182231187820435, -0.33387866616249084, -0.06303651630878448, 0.2863572835922241, 0.21463270485401154, -0.018695268779993057, -0.06214404106140137, -0.46826595067977905, 0.33007174730300903, 0.17055664956569672, 0.1230950579047203, 0.22227957844734192, -0.07542870938777924, -0.06607655435800552, -0.23089227080345154, -0.026390772312879562, -0.5002794861793518, -0.10783139616250992, -0.3612103760242462, -0.285203754901886, -0.2453031986951828, -0.010054735466837883, -0.021370764821767807, 0.25612226128578186, -0.14152954518795013, -0.1844809502363205, 0.08830014616250992, -0.10643375664949417, 0.016320476308465004, -0.08747636526823044, -0.2599881589412689, 0.051969919353723526, -0.1904647946357727, -0.03598577529191971, 0.08244013786315918, 0.009853309951722622, 0.257398396730423, -0.008332199417054653, -0.1251349151134491, -0.5104292035102844, -0.006587297655642033, 0.05101542919874191, 0.2310415506362915, -0.2865259647369385, -0.31479379534721375, -0.343932181596756, -0.3957860469818115, -0.5769727230072021, -0.05955474451184273, -0.07015438377857208, 0.03651769459247589, 0.28207239508628845, 0.06649153679609299, 0.09626053273677826, -0.66211998462677, 0.08188395947217941, -0.13449832797050476, -0.2634730041027069, -0.28089362382888794, 0.06979631632566452, -0.5911073088645935, -0.1299414187669754, 0.06343498826026917, 0.2177083045244217, -0.17176693677902222, 0.09467128664255142, 0.018653348088264465, -0.2731304466724396, 0.041539404541254044, 0.4047676622867584, -0.24819763004779816, -0.27260398864746094, -0.022753344848752022, 0.1160326600074768, -0.31304410099983215, 0.2696714401245117, -0.3046918511390686, 0.34546250104904175, -0.4479956030845642, 0.015769701451063156, -0.015572335571050644, -0.04663859307765961, -0.2566402554512024, -0.14508038759231567, -0.02952880784869194, -0.1655639111995697, -0.015087828040122986, -0.7064628601074219, 0.039925891906023026, 0.15202242136001587, -0.03427816182374954, 0.08743631839752197, -0.22175589203834534, -0.3812499940395355, 0.0307913925498724, -0.17431645095348358, -0.1713683009147644, -0.0518014021217823, -0.12750093638896942, 0.09755246341228485, 0.18759892880916595, -0.20776160061359406, 0.009411315433681011, -0.044830404222011566, 0.02942725643515587, -0.22368459403514862, 0.5853859186172485, 0.014734934084117413, -0.657567024230957, 0.2053418606519699, -0.16737937927246094, -0.16420532763004303, -0.16411679983139038, -0.14452163875102997, 0.05629316717386246, -0.022808238863945007, 0.055026739835739136, 0.1997731626033783, 0.14371594786643982, -0.1775117963552475, 0.3420300781726837, 0.42842215299606323, -0.4051274359226227, -0.32623299956321716, -0.11401752382516861, 0.0442858450114727, 0.31488361954689026, 0.17355754971504211, 0.10763748735189438, 0.2260793298482895, -0.040867604315280914, 0.3182031512260437, -0.2703711986541748, 0.011289981193840504, -0.1974918246269226, -0.1884935051202774, -0.04507853835821152, -0.4495532810688019, -0.3123295307159424, 0.1919129341840744, 0.28153613209724426, -0.39154767990112305, 0.3044877052307129, -0.5277446508407593, 0.19742125272750854, -0.21753808856010437, -0.24294547736644745, -0.05252697691321373, 0.025405192747712135, 0.004719423595815897, -0.012734448537230492, -0.15349528193473816, 0.2621051073074341, -0.22021931409835815, 0.18960343301296234, -0.37470874190330505, -0.041400108486413956, -0.3040498197078705, -0.25706741213798523, -0.06854655593633652, -0.364302396774292, -0.09597625583410263, 0.356889933347702, 0.13584929704666138, -0.29242950677871704, 0.04702659696340561, 0.039101891219615936, -0.34234619140625, -0.09873133152723312, 0.05599695071578026, -0.04444513097405434, -0.37418103218078613, 0.1609620898962021, -0.386184960603714, -0.32732710242271423, -0.20959800481796265, 0.09742599725723267, 0.34984636306762695, 0.03391025960445404, -0.07151774317026138, -0.07849645614624023, -0.422472208738327, -0.31166478991508484, 0.40307149291038513, -0.12488818913698196, 0.0647326409816742, -0.4930305480957031, -0.36705145239830017, -0.2127387821674347, -0.002393631264567375, 0.36632171273231506, 0.1134619265794754]]
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32

(server) E:\Research\extension\chrome-extension>python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 85, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    context = self.retrieval(query)
              ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 49, in retrieval
    return self.use_langchain(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 59, in use_langchain
    result = retriever.invoke(query)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 194, in invoke
    return self.get_relevant_documents(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\_api\deprecation.py", line 148, in warning_emitting_wrapper
    return wrapped(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 323, in get_relevant_documents
    raise e
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 316, in get_relevant_documents
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\vectorstores.py", line 696, in _get_relevant_documents
    docs = self.vectorstore.similarity_search(query, **self.search_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 384, in similarity_search
    docs_and_scores = self.similarity_search_with_score(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 474, in similarity_search_with_score
    results = self.__query_collection(
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py", line 36, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 191, in __query_collection
    return self._collection.query(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\api\models\Collection.py", line 300, in query
    validate_embeddings(
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\chromadb\api\types.py", line 488, in validate_embeddings
    raise ValueError(
ValueError: Expected each embedding in the embeddings to be a list, got ['ndarray']
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32

(server) E:\Research\extension\chrome-extension>[04:05:17]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 85, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, context)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 78, in generate_answer
    self.llm = llm(model_name=self.config["llm_model"], mode="hf")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\llm.py", line 17, in __init__
    self.model_info = self.set_embedded_model(model_id=model_name)
                      ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'llm' object has no attribute 'set_embedded_model'
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md\n# 3. 找到新關鍵字(ChatGPT)\n- Multi-Source Information Management\n- RALM，重要，需要了解具體定義及其與RAG的區別', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md', '標題1': '3. 找到新關鍵字(ChatGPT)'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md\n# 2. 實驗\n- 實驗列表\n- [ ] LangChain RAG方法整理、參數整理\n- [ ] Llama-index RAG方法整理、參數整理\n- [ ] 可用LLM整理、參數整理\n- [ ] 可用Embedded整理、參數整理\n- [ ] 資料集整理、分類、生成\n- 結果\n- 最近遇到的tgi莫名斷線問題解決了，~~是truncate=512異常切斷造成編碼錯誤~~，是debug函式的問題，把debug輸出關掉就不會報錯了\n- `-e LOG_LEVEL="info,text_generation_router=debug" \\`\n- 猜測當token大於一定長度的時候會出現這個問題\n- 將Lab中的huggingfaceendpoint改成chat，以使用TGI提供的chat template功能\n- 實驗langchain的chat和openai的chat設定\n```\nllm = HuggingFaceEndpoint(', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md', '標題1': '2. 實驗'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-03.md\n# 1. 系統\n- 設定頁面\n- 根據[這個issue](https://github.com/gradio-app/gradio/issues/7541)，必須把compoment作為input傳到函數中才能取得最新的值，否則value屬性本來就只能拿到初始值\n- gr.Error必須被raise出去才會成功丟警告出來\n- 完成\n- 模型端\n- Taiwan-LLM有2.1版，之前好像都用2.0.1版\n- 官方推薦使用 [[LLaMA-Factory]] 微調\n- ~~TGI好像會自動把system覆蓋掉~~\n- 修正，是程式問題，修正後正常\n- 使用openAI函數溝通tgi成功，從tgi的debug訊息來看應該是tgi那邊會自動套用prompt(?)', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-03.md', '標題1': '1. 系統'}), Document(page_content="來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-28.md\n- [ ] 待實驗\n- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/\n- [ ] GEMMA\n- [ ] [[HyDE]]\n- 系統\n- [ ] 設計整個架構和所需要的API需求及文件\n- [ ] 浮動視窗，類似字典\n- [x] 解決讀取文字會動到剪貼簿的問題\n- 用 `pyperclip.copy('string')` 和 `pyperclip.paste()`  將原本剪貼簿中的資訊備份下來", metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-28.md', '標題1': '0. 今日計畫'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-13.md\n# 1. 實驗\n- 測試 [[llama-index]] 的RAG\n- 根據[教學](https://docs.llamaindex.ai/en/stable/module_guides/models/llms/)，發現 [[phi-3-mini-4k-instruct]] ，也許可以關於text2sql之類的非中文任務可以交給它(llama-index提供的[測試結果](https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/benchmarks/phi-3-mini-4k-instruct.ipynb))\n- 超猛的 [[LlamaHub]]\n- 繼續做LangChain的實驗\n- 出現神奇的問題，明明檢索的是4/11，未完成閱讀的資料，Q3_K_L卻根據', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-13.md', '標題1': '1. 實驗'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
        ==參考文獻==
        [Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md\n# 3. 找到新關鍵字(ChatGPT)\n- Multi-Source Information Management\n- RALM，重要，需要了解具體定義及其與RAG的區別', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md', '標題1': '3. 找到新關鍵字(ChatGPT)'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md\n# 2. 實驗\n- 實驗列表\n- [ ] LangChain RAG方法整理、參數整理\n- [ ] Llama-index RAG方法整理、參數整理\n- [ ] 可用LLM整理、參數整理\n- [ ] 可用Embedded整理、參數整理\n- [ ] 資料集整理、分類、生成\n- 結果\n- 最近遇到的tgi莫名斷線問題解決了，~~是truncate=512異常切斷造成編碼錯誤~~，是debug函式的問題，把debug輸出關掉就不會報錯了\n- `-e LOG_LEVEL="info,text_generation_router=debug" \\`\n- 猜測當token大於一定長度的時候會出現這個問題\n- 將Lab中的huggingfaceendpoint改成chat，以使用TGI提供的chat template功能\n- 實驗langchain的chat和openai的chat設定\n```\nllm = HuggingFaceEndpoint(', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md', '標題1': '2. 實驗'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-03.md\n# 1. 系統\n- 設定頁面\n- 根據[這個issue](https://github.com/gradio-app/gradio/issues/7541)，必須把compoment作為input傳到函數中才能取得最新的值，否則value屬性本來就只能拿到初始值\n- gr.Error必須被raise出去才會成功丟警告出來\n- 完成\n- 模型端\n- Taiwan-LLM有2.1版，之前好像都用2.0.1版\n- 官方推薦使用 [[LLaMA-Factory]] 微調\n- ~~TGI好像會自動把system覆蓋掉~~\n- 修正，是程式問題，修正後正常\n- 使用openAI函數溝通tgi成功，從tgi的debug訊息來看應該是tgi那邊會自動套用prompt(?)', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-03.md', '標題1': '1. 系統'}), Document(page_content="來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-28.md\n- [ ] 待實驗\n- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/\n- [ ] GEMMA\n- [ ] [[HyDE]]\n- 系統\n- [ ] 設計整個架構和所需要的API需求及文件\n- [ ] 浮動視窗，類似字典\n- [x] 解決讀取文字會動到剪貼簿的問題\n- 用 `pyperclip.copy('string')` 和 `pyperclip.paste()`  將原本剪貼簿中的資訊備份下來", metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-28.md', '標題1': '0. 今日計畫'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-13.md\n# 1. 實驗\n- 測試 [[llama-index]] 的RAG\n- 根據[教學](https://docs.llamaindex.ai/en/stable/module_guides/models/llms/)，發現 [[phi-3-mini-4k-instruct]] ，也許可以關於text2sql之類的非中文任務可以交給它(llama-index提供的[測試結果](https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/benchmarks/phi-3-mini-4k-instruct.ipynb))\n- 超猛的 [[LlamaHub]]\n- 繼續做LangChain的實驗\n- 出現神奇的問題，明明檢索的是4/11，未完成閱讀的資料，Q3_K_L卻根據', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-13.md', '標題1': '1. 實驗'})]

        ==問題==
        根據上文，請問如何設定RAG
        請用20個字簡潔回答問題。
        

(server) E:\Research\extension\chrome-extension>[04:13:08]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 85, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, context)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 79, in generate_answer
    llm.chat(input=prompt, system_message="")
TypeError: llm.chat() missing 1 required positional argument: 'self'
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md\n# 3. 找到新關鍵字(ChatGPT)\n- Multi-Source Information Management\n- RALM，重要，需要了解具體定義及其與RAG的區別', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md', '標題1': '3. 找到新關鍵字(ChatGPT)'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md\n# 999. 靈感\n- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  \n[^1]: https://ithelp.ithome.com.tw/articles/10340284\n[^2]: https://github.com/huggingface/text-generation-inference/issues/1201', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md', '標題1': '999. 靈感'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md\n# 2. 實驗\n- 實驗列表\n- [ ] LangChain RAG方法整理、參數整理\n- [ ] Llama-index RAG方法整理、參數整理\n- [ ] 可用LLM整理、參數整理\n- [ ] 可用Embedded整理、參數整理\n- [ ] 資料集整理、分類、生成\n- 結果\n- 最近遇到的tgi莫名斷線問題解決了，~~是truncate=512異常切斷造成編碼錯誤~~，是debug函式的問題，把debug輸出關掉就不會報錯了\n- `-e LOG_LEVEL="info,text_generation_router=debug" \\`\n- 猜測當token大於一定長度的時候會出現這個問題\n- 將Lab中的huggingfaceendpoint改成chat，以使用TGI提供的chat template功能\n- 實驗langchain的chat和openai的chat設定\n```\nllm = HuggingFaceEndpoint(', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md', '標題1': '2. 實驗'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-03.md\n# 1. 系統\n- 設定頁面\n- 根據[這個issue](https://github.com/gradio-app/gradio/issues/7541)，必須把compoment作為input傳到函數中才能取得最新的值，否則value屬性本來就只能拿到初始值\n- gr.Error必須被raise出去才會成功丟警告出來\n- 完成\n- 模型端\n- Taiwan-LLM有2.1版，之前好像都用2.0.1版\n- 官方推薦使用 [[LLaMA-Factory]] 微調\n- ~~TGI好像會自動把system覆蓋掉~~\n- 修正，是程式問題，修正後正常\n- 使用openAI函數溝通tgi成功，從tgi的debug訊息來看應該是tgi那邊會自動套用prompt(?)', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-03.md', '標題1': '1. 系統'}), Document(page_content="來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-28.md\n- [ ] 待實驗\n- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/\n- [ ] GEMMA\n- [ ] [[HyDE]]\n- 系統\n- [ ] 設計整個架構和所需要的API需求及文件\n- [ ] 浮動視窗，類似字典\n- [x] 解決讀取文字會動到剪貼簿的問題\n- 用 `pyperclip.copy('string')` 和 `pyperclip.paste()`  將原本剪貼簿中的資訊備份下來", metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-28.md', '標題1': '0. 今日計畫'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
        ==參考文獻==
        [Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md\n# 3. 找到新關鍵字(ChatGPT)\n- Multi-Source Information Management\n- RALM，重要，需要了解具體定義及其與RAG的區別', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md', '標題1': '3. 找到新關鍵字(ChatGPT)'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md\n# 999. 靈感\n- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  \n[^1]: https://ithelp.ithome.com.tw/articles/10340284\n[^2]: https://github.com/huggingface/text-generation-inference/issues/1201', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md', '標題1': '999. 靈感'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md\n# 2. 實驗\n- 實驗列表\n- [ ] LangChain RAG方法整理、參數整理\n- [ ] Llama-index RAG方法整理、參數整理\n- [ ] 可用LLM整理、參數整理\n- [ ] 可用Embedded整理、參數整理\n- [ ] 資料集整理、分類、生成\n- 結果\n- 最近遇到的tgi莫名斷線問題解決了，~~是truncate=512異常切斷造成編碼錯誤~~，是debug函式的問題，把debug輸出關掉就不會報錯了\n- `-e LOG_LEVEL="info,text_generation_router=debug" \\`\n- 猜測當token大於一定長度的時候會出現這個問題\n- 將Lab中的huggingfaceendpoint改成chat，以使用TGI提供的chat template功能\n- 實驗langchain的chat和openai的chat設定\n```\nllm = HuggingFaceEndpoint(', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md', '標題1': '2. 實驗'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-03.md\n# 1. 系統\n- 設定頁面\n- 根據[這個issue](https://github.com/gradio-app/gradio/issues/7541)，必須把compoment作為input傳到函數中才能取得最新的值，否則value屬性本來就只能拿到初始值\n- gr.Error必須被raise出去才會成功丟警告出來\n- 完成\n- 模型端\n- Taiwan-LLM有2.1版，之前好像都用2.0.1版\n- 官方推薦使用 [[LLaMA-Factory]] 微調\n- ~~TGI好像會自動把system覆蓋掉~~\n- 修正，是程式問題，修正後正常\n- 使用openAI函數溝通tgi成功，從tgi的debug訊息來看應該是tgi那邊會自動套用prompt(?)', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-03.md', '標題1': '1. 系統'}), Document(page_content="來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-28.md\n- [ ] 待實驗\n- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/\n- [ ] GEMMA\n- [ ] [[HyDE]]\n- 系統\n- [ ] 設計整個架構和所需要的API需求及文件\n- [ ] 浮動視窗，類似字典\n- [x] 解決讀取文字會動到剪貼簿的問題\n- 用 `pyperclip.copy('string')` 和 `pyperclip.paste()`  將原本剪貼簿中的資訊備份下來", metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-28.md', '標題1': '0. 今日計畫'})]

        ==問題==
        根據上文，請問如何設定RAG
        請用20個字簡潔回答問題。
        

(server) E:\Research\extension\chrome-extension>[04:13:55]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, retrieval_result)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 77, in generate_answer
    prompt = prompt.format(context=format_docs(retrieval_result), question=query)
                                   ^^^^^^^^^^^
NameError: name 'format_docs' is not defined
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32

(server) E:\Research\extension\chrome-extension>[04:14:22]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, retrieval_result)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 77, in generate_answer
    prompt = prompt.format(context=self.format_docs(retrieval_result), question=query)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: rag.format_docs() takes 1 positional argument but 2 were given
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32

(server) E:\Research\extension\chrome-extension>[04:15:05]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 89, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, retrieval_result)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 78, in generate_answer
    prompt = prompt.format(context=format_docs(retrieval_result), question=query)
                                   ^^^^^^^^^^^
NameError: name 'format_docs' is not defined
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32

(server) E:\Research\extension\chrome-extension>[04:16:23]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, retrieval_result)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 82, in generate_answer
    self.llm.chat(input=prompt, system_message="")
  File "E:\Research\extension\chrome-extension\modules\llm.py", line 39, in chat
    model_name = get_model_name()
                 ^^^^^^^^^^^^^^
NameError: name 'get_model_name' is not defined. Did you mean: 'model_name'?
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
        ==參考文獻==
        來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 999. 靈感
- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  
[^1]: https://ithelp.ithome.com.tw/articles/10340284
[^2]: https://github.com/huggingface/text-generation-inference/issues/1201

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 2. 實驗
- 實驗列表
- [ ] LangChain RAG方法整理、參數整理
- [ ] Llama-index RAG方法整理、參數整理
- [ ] 可用LLM整理、參數整理
- [ ] 可用Embedded整理、參數整理
- [ ] 資料集整理、分類、生成
- 結果
- 最近遇到的tgi莫名斷線問題解決了，~~是truncate=512異常切斷造成編碼錯誤~~，是debug函式的問題，把debug輸出關掉就不會報錯了
- `-e LOG_LEVEL="info,text_generation_router=debug" \`
- 猜測當token大於一定長度的時候會出現這個問題
- 將Lab中的huggingfaceendpoint改成chat，以使用TGI提供的chat template功能
- 實驗langchain的chat和openai的chat設定
```
llm = HuggingFaceEndpoint(

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-03.md
# 1. 系統
- 設定頁面
- 根據[這個issue](https://github.com/gradio-app/gradio/issues/7541)，必須把compoment作為input傳到函數中才能取得最新的值，否則value屬性本來就只能拿到初始值
- gr.Error必須被raise出去才會成功丟警告出來
- 完成
- 模型端
- Taiwan-LLM有2.1版，之前好像都用2.0.1版
- 官方推薦使用 [[LLaMA-Factory]] 微調
- ~~TGI好像會自動把system覆蓋掉~~
- 修正，是程式問題，修正後正常
- 使用openAI函數溝通tgi成功，從tgi的debug訊息來看應該是tgi那邊會自動套用prompt(?)

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-28.md
- [ ] 待實驗
- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/
- [ ] GEMMA
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典
- [x] 解決讀取文字會動到剪貼簿的問題
- 用 `pyperclip.copy('string')` 和 `pyperclip.paste()`  將原本剪貼簿中的資訊備份下來

        ==問題==
        根據上文，請問如何設定RAG
        請用20個字簡潔回答問題。
        

(server) E:\Research\extension\chrome-extension>[04:20:16]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, retrieval_result)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 82, in generate_answer
    self.llm.chat(input=prompt, system_message="")
  File "E:\Research\extension\chrome-extension\modules\llm.py", line 43, in chat
    llm = HuggingFaceEndpoint(
          ^^^^^^^^^^^^^^^^^^^
NameError: name 'HuggingFaceEndpoint' is not defined
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
        ==參考文獻==
        來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 2. 實驗
- 實驗列表
- [ ] LangChain RAG方法整理、參數整理
- [ ] Llama-index RAG方法整理、參數整理
- [ ] 可用LLM整理、參數整理
- [ ] 可用Embedded整理、參數整理
- [ ] 資料集整理、分類、生成
- 結果
- 最近遇到的tgi莫名斷線問題解決了，~~是truncate=512異常切斷造成編碼錯誤~~，是debug函式的問題，把debug輸出關掉就不會報錯了
- `-e LOG_LEVEL="info,text_generation_router=debug" \`
- 猜測當token大於一定長度的時候會出現這個問題
- 將Lab中的huggingfaceendpoint改成chat，以使用TGI提供的chat template功能
- 實驗langchain的chat和openai的chat設定
```
llm = HuggingFaceEndpoint(

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-03.md
# 1. 系統
- 設定頁面
- 根據[這個issue](https://github.com/gradio-app/gradio/issues/7541)，必須把compoment作為input傳到函數中才能取得最新的值，否則value屬性本來就只能拿到初始值
- gr.Error必須被raise出去才會成功丟警告出來
- 完成
- 模型端
- Taiwan-LLM有2.1版，之前好像都用2.0.1版
- 官方推薦使用 [[LLaMA-Factory]] 微調
- ~~TGI好像會自動把system覆蓋掉~~
- 修正，是程式問題，修正後正常
- 使用openAI函數溝通tgi成功，從tgi的debug訊息來看應該是tgi那邊會自動套用prompt(?)

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-28.md
- [ ] 待實驗
- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/
- [ ] GEMMA
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典
- [x] 解決讀取文字會動到剪貼簿的問題
- 用 `pyperclip.copy('string')` 和 `pyperclip.paste()`  將原本剪貼簿中的資訊備份下來

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-13.md
# 1. 實驗
- 測試 [[llama-index]] 的RAG
- 根據[教學](https://docs.llamaindex.ai/en/stable/module_guides/models/llms/)，發現 [[phi-3-mini-4k-instruct]] ，也許可以關於text2sql之類的非中文任務可以交給它(llama-index提供的[測試結果](https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/benchmarks/phi-3-mini-4k-instruct.ipynb))
- 超猛的 [[LlamaHub]]
- 繼續做LangChain的實驗
- 出現神奇的問題，明明檢索的是4/11，未完成閱讀的資料，Q3_K_L卻根據

        ==問題==
        根據上文，請問如何設定RAG
        請用20個字簡潔回答問題。
        
model_id: MediaTek-Research/Breeze-7B-Instruct-v0_1
model_dtype:  torch.float16

(server) E:\Research\extension\chrome-extension>[04:21:06]python -m modules.rag
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\_api\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from langchain-huggingface package and should be used instead. To use it run `pip install -U from langchain-huggingface` and import as `from from langchain_huggingface import llms import HuggingFaceEndpoint`.
  warn_deprecated(
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, retrieval_result)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 82, in generate_answer
    self.llm.chat(input=prompt, system_message="")
  File "E:\Research\extension\chrome-extension\modules\llm.py", line 44, in chat
    llm = HuggingFaceEndpoint(
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\_api\deprecation.py", line 183, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pydantic\v1\main.py", line 341, in __init__
    raise validation_error
pydantic.v1.error_wrappers.ValidationError: 1 validation error for HuggingFaceEndpoint
__root__
  Could not authenticate with huggingface_hub. Please check your API token. (type=value_error)
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
        ==參考文獻==
        來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 2. 實驗
- 實驗列表
- [ ] LangChain RAG方法整理、參數整理
- [ ] Llama-index RAG方法整理、參數整理
- [ ] 可用LLM整理、參數整理
- [ ] 可用Embedded整理、參數整理
- [ ] 資料集整理、分類、生成
- 結果
- 最近遇到的tgi莫名斷線問題解決了，~~是truncate=512異常切斷造成編碼錯誤~~，是debug函式的問題，把debug輸出關掉就不會報錯了
- `-e LOG_LEVEL="info,text_generation_router=debug" \`
- 猜測當token大於一定長度的時候會出現這個問題
- 將Lab中的huggingfaceendpoint改成chat，以使用TGI提供的chat template功能
- 實驗langchain的chat和openai的chat設定
```
llm = HuggingFaceEndpoint(

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-03.md
# 1. 系統
- 設定頁面
- 根據[這個issue](https://github.com/gradio-app/gradio/issues/7541)，必須把compoment作為input傳到函數中才能取得最新的值，否則value屬性本來就只能拿到初始值
- gr.Error必須被raise出去才會成功丟警告出來
- 完成
- 模型端
- Taiwan-LLM有2.1版，之前好像都用2.0.1版
- 官方推薦使用 [[LLaMA-Factory]] 微調
- ~~TGI好像會自動把system覆蓋掉~~
- 修正，是程式問題，修正後正常
- 使用openAI函數溝通tgi成功，從tgi的debug訊息來看應該是tgi那邊會自動套用prompt(?)

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-28.md
- [ ] 待實驗
- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/
- [ ] GEMMA
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典
- [x] 解決讀取文字會動到剪貼簿的問題
- 用 `pyperclip.copy('string')` 和 `pyperclip.paste()`  將原本剪貼簿中的資訊備份下來

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-13.md
# 1. 實驗
- 測試 [[llama-index]] 的RAG
- 根據[教學](https://docs.llamaindex.ai/en/stable/module_guides/models/llms/)，發現 [[phi-3-mini-4k-instruct]] ，也許可以關於text2sql之類的非中文任務可以交給它(llama-index提供的[測試結果](https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/benchmarks/phi-3-mini-4k-instruct.ipynb))
- 超猛的 [[LlamaHub]]
- 繼續做LangChain的實驗
- 出現神奇的問題，明明檢索的是4/11，未完成閱讀的資料，Q3_K_L卻根據

        ==問題==
        根據上文，請問如何設定RAG
        請用20個字簡潔回答問題。
        
model_id: MediaTek-Research/Breeze-7B-Instruct-v0_1
model_dtype:  torch.float16

(server) E:\Research\extension\chrome-extension>[04:25:30]set HF_TOKEN=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

(server) E:\Research\extension\chrome-extension>[04:25:32]python -m modules.rag
Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 793, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 537, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connection.py", line 466, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 1378, in getresponse
    response.begin()
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 847, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\util\retry.py", line 470, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 793, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 537, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connection.py", line 466, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 1378, in getresponse
    response.begin()
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 20, in query
    self.embedded()
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 44, in embedded
    self.embedded_obj = embedded(model_name=self.embedded_model_name)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 34, in __init__
    self.model_info = self.set_embedded_model(model_id=model_name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 79, in set_embedded_model
    response = requests.get(
               ^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
嵌入模型載入中...

(server) E:\Research\extension\chrome-extension>[04:26:11]python -m modules.rag
Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 793, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 537, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connection.py", line 466, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 1378, in getresponse
    response.begin()
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 847, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\util\retry.py", line 470, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 793, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 537, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connection.py", line 466, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 1378, in getresponse
    response.begin()
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    retrieval_result = self.retrieval(query)
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 49, in retrieval
    return self.use_langchain(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 59, in use_langchain
    result = retriever.invoke(query)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 194, in invoke
    return self.get_relevant_documents(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\_api\deprecation.py", line 148, in warning_emitting_wrapper
    return wrapped(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 323, in get_relevant_documents
    raise e
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 316, in get_relevant_documents
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\vectorstores.py", line 696, in _get_relevant_documents
    docs = self.vectorstore.similarity_search(query, **self.search_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 384, in similarity_search
    docs_and_scores = self.similarity_search_with_score(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 473, in similarity_search_with_score
    query_embedding = self._embedding_function.embed_query(query)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 67, in embed_query
    return self.embedded([query])[0].tolist()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 48, in embedded
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
嵌入模型載入中...
嵌入模型載入完成
{'max_length': None, 'dim': None}
資料庫已存在

(server) E:\Research\extension\chrome-extension>[04:40:19]python -m modules.rag
Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 無法連線，因為目標電腦拒絕連線。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 793, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 496, in _make_request
    conn.request(
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connection.py", line 400, in request
    self.endheaders()
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 1281, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 1041, in _send_output
    self.send(msg)
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 979, in send
    self.connect()
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connection.py", line 238, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000023D42E5EF50>: Failed to establish a new connection: [WinError 10061] 無法連線，因為目標電腦拒絕連線。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 847, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\util\retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='10.147.19.2', port=8000): Max retries exceeded with url: /?model_id=infgrad%2Fpuff-base-v1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000023D42E5EF50>: Failed to establish a new connection: [WinError 10061] 無法連線，因為目標電腦拒絕連線。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 20, in query
    self.embedded()
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 44, in embedded
    self.embedded_obj = embedded(model_name=self.embedded_model_name)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 34, in __init__
    self.model_info = self.set_embedded_model(model_id=model_name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 79, in set_embedded_model
    response = requests.get(
               ^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\adapters.py", line 519, in send
嵌入模型載入中...
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='10.147.19.2', port=8000): Max retries exceeded with url: /?model_id=infgrad%2Fpuff-base-v1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000023D42E5EF50>: Failed to establish a new connection: [WinError 10061] 無法連線，因為目標電腦拒絕連線。'))

(server) E:\Research\extension\chrome-extension>[04:40:36]python -m modules.rag
Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 793, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 537, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connection.py", line 466, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 1378, in getresponse
    response.begin()
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 847, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\util\retry.py", line 470, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 793, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 537, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connection.py", line 466, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 1378, in getresponse
    response.begin()
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 23, in query
    retrieval_result = self.retrieval(query)
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 49, in retrieval
    return self.use_langchain(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 59, in use_langchain
    result = retriever.invoke(query)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 194, in invoke
    return self.get_relevant_documents(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\_api\deprecation.py", line 148, in warning_emitting_wrapper
    return wrapped(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 323, in get_relevant_documents
    raise e
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\retrievers.py", line 316, in get_relevant_documents
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\vectorstores.py", line 696, in _get_relevant_documents
    docs = self.vectorstore.similarity_search(query, **self.search_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 384, in similarity_search
    docs_and_scores = self.similarity_search_with_score(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_chroma\vectorstores.py", line 473, in similarity_search_with_score
    query_embedding = self._embedding_function.embed_query(query)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 67, in embed_query
    return self.embedded([query])[0].tolist()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 48, in embedded
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
嵌入模型載入中...
嵌入模型載入完成
{'max_length': None, 'dim': None}
資料庫已存在

(server) E:\Research\extension\chrome-extension>[04:42:00]python -m modules.rag
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\_api\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from langchain-huggingface package and should be used instead. To use it run `pip install -U from langchain-huggingface` and import as `from from langchain_huggingface import llms import HuggingFaceEndpoint`.
  warn_deprecated(
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, retrieval_result)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 82, in generate_answer
    self.llm.chat(input=prompt, system_message="")
  File "E:\Research\extension\chrome-extension\modules\llm.py", line 44, in chat
    llm = HuggingFaceEndpoint(
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\_api\deprecation.py", line 183, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pydantic\v1\main.py", line 341, in __init__
    raise validation_error
pydantic.v1.error_wrappers.ValidationError: 1 validation error for HuggingFaceEndpoint
__root__
  Could not authenticate with huggingface_hub. Please check your API token. (type=value_error)
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
        ==參考文獻==
        來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 999. 靈感
- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  
[^1]: https://ithelp.ithome.com.tw/articles/10340284
[^2]: https://github.com/huggingface/text-generation-inference/issues/1201

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-03.md
# 1. 系統
- 設定頁面
- 根據[這個issue](https://github.com/gradio-app/gradio/issues/7541)，必須把compoment作為input傳到函數中才能取得最新的值，否則value屬性本來就只能拿到初始值
- gr.Error必須被raise出去才會成功丟警告出來
- 完成
- 模型端
- Taiwan-LLM有2.1版，之前好像都用2.0.1版
- 官方推薦使用 [[LLaMA-Factory]] 微調
- ~~TGI好像會自動把system覆蓋掉~~
- 修正，是程式問題，修正後正常
- 使用openAI函數溝通tgi成功，從tgi的debug訊息來看應該是tgi那邊會自動套用prompt(?)

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-28.md
- [ ] 待實驗
- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/
- [ ] GEMMA
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典
- [x] 解決讀取文字會動到剪貼簿的問題
- 用 `pyperclip.copy('string')` 和 `pyperclip.paste()`  將原本剪貼簿中的資訊備份下來

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-13.md
# 1. 實驗
- 測試 [[llama-index]] 的RAG
- 根據[教學](https://docs.llamaindex.ai/en/stable/module_guides/models/llms/)，發現 [[phi-3-mini-4k-instruct]] ，也許可以關於text2sql之類的非中文任務可以交給它(llama-index提供的[測試結果](https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/benchmarks/phi-3-mini-4k-instruct.ipynb))
- 超猛的 [[LlamaHub]]
- 繼續做LangChain的實驗
- 出現神奇的問題，明明檢索的是4/11，未完成閱讀的資料，Q3_K_L卻根據

        ==問題==
        根據上文，請問如何設定RAG
        請用20個字簡潔回答問題。
        
model_id: MediaTek-Research/Breeze-7B-Instruct-v0_1
model_dtype:  torch.float16

(server) E:\Research\extension\chrome-extension>[04:43:18]set HF_TOKEN=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

(server) E:\Research\extension\chrome-extension>[04:43:50]set HF_TOKEN=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

(server) E:\Research\extension\chrome-extension>[04:43:52]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, retrieval_result)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 82, in generate_answer
    self.llm.chat(input=prompt, system_message="")
  File "E:\Research\extension\chrome-extension\modules\llm.py", line 27, in chat
    if "gpt" in model_name:
                ^^^^^^^^^^
UnboundLocalError: cannot access local variable 'model_name' where it is not associated with a value
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
        ==參考文獻==
        來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 999. 靈感
- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  
[^1]: https://ithelp.ithome.com.tw/articles/10340284
[^2]: https://github.com/huggingface/text-generation-inference/issues/1201

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 2. 實驗
- 實驗列表
- [ ] LangChain RAG方法整理、參數整理
- [ ] Llama-index RAG方法整理、參數整理
- [ ] 可用LLM整理、參數整理
- [ ] 可用Embedded整理、參數整理
- [ ] 資料集整理、分類、生成
- 結果
- 最近遇到的tgi莫名斷線問題解決了，~~是truncate=512異常切斷造成編碼錯誤~~，是debug函式的問題，把debug輸出關掉就不會報錯了
- `-e LOG_LEVEL="info,text_generation_router=debug" \`
- 猜測當token大於一定長度的時候會出現這個問題
- 將Lab中的huggingfaceendpoint改成chat，以使用TGI提供的chat template功能
- 實驗langchain的chat和openai的chat設定
```
llm = HuggingFaceEndpoint(

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-03.md
# 1. 系統
- 設定頁面
- 根據[這個issue](https://github.com/gradio-app/gradio/issues/7541)，必須把compoment作為input傳到函數中才能取得最新的值，否則value屬性本來就只能拿到初始值
- gr.Error必須被raise出去才會成功丟警告出來
- 完成
- 模型端
- Taiwan-LLM有2.1版，之前好像都用2.0.1版
- 官方推薦使用 [[LLaMA-Factory]] 微調
- ~~TGI好像會自動把system覆蓋掉~~
- 修正，是程式問題，修正後正常
- 使用openAI函數溝通tgi成功，從tgi的debug訊息來看應該是tgi那邊會自動套用prompt(?)

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-28.md
- [ ] 待實驗
- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/
- [ ] GEMMA
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典
- [x] 解決讀取文字會動到剪貼簿的問題
- 用 `pyperclip.copy('string')` 和 `pyperclip.paste()`  將原本剪貼簿中的資訊備份下來

        ==問題==
        根據上文，請問如何設定RAG
        請用20個字簡潔回答問題。
        

(server) E:\Research\extension\chrome-extension>[04:44:52]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, retrieval_result)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 82, in generate_answer
    self.llm.chat(input=prompt, system_message="")
  File "E:\Research\extension\chrome-extension\modules\llm.py", line 31, in chat
    from langchain_openai import ChatOpenAI
ModuleNotFoundError: No module named 'langchain_openai'
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
        ==參考文獻==
        來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 999. 靈感
- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  
[^1]: https://ithelp.ithome.com.tw/articles/10340284
[^2]: https://github.com/huggingface/text-generation-inference/issues/1201

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 2. 實驗
- 實驗列表
- [ ] LangChain RAG方法整理、參數整理
- [ ] Llama-index RAG方法整理、參數整理
- [ ] 可用LLM整理、參數整理
- [ ] 可用Embedded整理、參數整理
- [ ] 資料集整理、分類、生成
- 結果
- 最近遇到的tgi莫名斷線問題解決了，~~是truncate=512異常切斷造成編碼錯誤~~，是debug函式的問題，把debug輸出關掉就不會報錯了
- `-e LOG_LEVEL="info,text_generation_router=debug" \`
- 猜測當token大於一定長度的時候會出現這個問題
- 將Lab中的huggingfaceendpoint改成chat，以使用TGI提供的chat template功能
- 實驗langchain的chat和openai的chat設定
```
llm = HuggingFaceEndpoint(

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-03.md
# 1. 系統
- 設定頁面
- 根據[這個issue](https://github.com/gradio-app/gradio/issues/7541)，必須把compoment作為input傳到函數中才能取得最新的值，否則value屬性本來就只能拿到初始值
- gr.Error必須被raise出去才會成功丟警告出來
- 完成
- 模型端
- Taiwan-LLM有2.1版，之前好像都用2.0.1版
- 官方推薦使用 [[LLaMA-Factory]] 微調
- ~~TGI好像會自動把system覆蓋掉~~
- 修正，是程式問題，修正後正常
- 使用openAI函數溝通tgi成功，從tgi的debug訊息來看應該是tgi那邊會自動套用prompt(?)

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-28.md
- [ ] 待實驗
- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/
- [ ] GEMMA
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典
- [x] 解決讀取文字會動到剪貼簿的問題
- 用 `pyperclip.copy('string')` 和 `pyperclip.paste()`  將原本剪貼簿中的資訊備份下來

        ==問題==
        根據上文，請問如何設定RAG
        請用20個字簡潔回答問題。
        

(server) E:\Research\extension\chrome-extension>[04:45:47]pip install langchain-openai
Collecting langchain-openai
  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)
Requirement already satisfied: langchain-core<0.3,>=0.1.46 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-openai) (0.2.0)
Requirement already satisfied: openai<2.0.0,>=1.24.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-openai) (1.25.1)
Collecting tiktoken<1,>=0.7 (from langchain-openai)
  Downloading tiktoken-0.7.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)
Requirement already satisfied: PyYAML>=5.3 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (6.0.1)
Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (1.33)
Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (0.1.60)
Requirement already satisfied: packaging<24.0,>=23.2 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (23.2)
Requirement already satisfied: pydantic<3,>=1 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (2.6.4)
Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-core<0.3,>=0.1.46->langchain-openai) (8.3.0)
Requirement already satisfied: anyio<5,>=3.5.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.3.0)
Requirement already satisfied: distro<2,>=1.7.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.9.0)
Requirement already satisfied: httpx<1,>=0.23.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.27.0)
Requirement already satisfied: sniffio in d:\programdata\anaconda3\envs\server\lib\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.3.1)
Requirement already satisfied: tqdm>4 in d:\programdata\anaconda3\envs\server\lib\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.66.2)
Requirement already satisfied: typing-extensions<5,>=4.7 in d:\programdata\anaconda3\envs\server\lib\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.10.0)
Requirement already satisfied: regex>=2022.1.18 in d:\programdata\anaconda3\envs\server\lib\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)
Requirement already satisfied: requests>=2.26.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)
Requirement already satisfied: idna>=2.8 in d:\programdata\anaconda3\envs\server\lib\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai) (3.6)
Requirement already satisfied: certifi in d:\programdata\anaconda3\envs\server\lib\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (2024.2.2)
Requirement already satisfied: httpcore==1.* in d:\programdata\anaconda3\envs\server\lib\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.0.5)
Requirement already satisfied: h11<0.15,>=0.13 in d:\programdata\anaconda3\envs\server\lib\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (0.14.0)
Requirement already satisfied: jsonpointer>=1.9 in d:\programdata\anaconda3\envs\server\lib\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain-openai) (2.4)
Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.46->langchain-openai) (3.10.0)
Requirement already satisfied: annotated-types>=0.4.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai) (0.6.0)
Requirement already satisfied: pydantic-core==2.16.3 in d:\programdata\anaconda3\envs\server\lib\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai) (2.16.3)
Requirement already satisfied: charset-normalizer<4,>=2 in d:\programdata\anaconda3\envs\server\lib\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)
Requirement already satisfied: urllib3<3,>=1.21.1 in d:\programdata\anaconda3\envs\server\lib\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.1)
Requirement already satisfied: colorama in d:\programdata\anaconda3\envs\server\lib\site-packages (from tqdm>4->openai<2.0.0,>=1.24.0->langchain-openai) (0.4.6)
Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)
Downloading tiktoken-0.7.0-cp311-cp311-win_amd64.whl (799 kB)
   ---------------------------------------- 799.0/799.0 kB 1.6 MB/s eta 0:00:00
Installing collected packages: tiktoken, langchain-openai
Successfully installed langchain-openai-0.1.7 tiktoken-0.7.0

(server) E:\Research\extension\chrome-extension>[04:46:02]python -m modules.rag
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, retrieval_result)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 82, in generate_answer
    self.llm.chat(input=prompt, system_message="")
  File "E:\Research\extension\chrome-extension\modules\llm.py", line 32, in chat
    chat = ChatOpenAI(openai_api_base=self.base_url, model_name=self.model_name, seed=1)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pydantic\v1\main.py", line 341, in __init__
    raise validation_error
pydantic.v1.error_wrappers.ValidationError: 1 validation error for ChatOpenAI
__root__
  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
        ==參考文獻==
        來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 999. 靈感
- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  
[^1]: https://ithelp.ithome.com.tw/articles/10340284
[^2]: https://github.com/huggingface/text-generation-inference/issues/1201

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 2. 實驗
- 實驗列表
- [ ] LangChain RAG方法整理、參數整理
- [ ] Llama-index RAG方法整理、參數整理
- [ ] 可用LLM整理、參數整理
- [ ] 可用Embedded整理、參數整理
- [ ] 資料集整理、分類、生成
- 結果
- 最近遇到的tgi莫名斷線問題解決了，~~是truncate=512異常切斷造成編碼錯誤~~，是debug函式的問題，把debug輸出關掉就不會報錯了
- `-e LOG_LEVEL="info,text_generation_router=debug" \`
- 猜測當token大於一定長度的時候會出現這個問題
- 將Lab中的huggingfaceendpoint改成chat，以使用TGI提供的chat template功能
- 實驗langchain的chat和openai的chat設定
```
llm = HuggingFaceEndpoint(

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-03.md
# 1. 系統
- 設定頁面
- 根據[這個issue](https://github.com/gradio-app/gradio/issues/7541)，必須把compoment作為input傳到函數中才能取得最新的值，否則value屬性本來就只能拿到初始值
- gr.Error必須被raise出去才會成功丟警告出來
- 完成
- 模型端
- Taiwan-LLM有2.1版，之前好像都用2.0.1版
- 官方推薦使用 [[LLaMA-Factory]] 微調
- ~~TGI好像會自動把system覆蓋掉~~
- 修正，是程式問題，修正後正常
- 使用openAI函數溝通tgi成功，從tgi的debug訊息來看應該是tgi那邊會自動套用prompt(?)

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-28.md
- [ ] 待實驗
- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/
- [ ] GEMMA
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典
- [x] 解決讀取文字會動到剪貼簿的問題
- 用 `pyperclip.copy('string')` 和 `pyperclip.paste()`  將原本剪貼簿中的資訊備份下來

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-13.md
# 1. 實驗
- 測試 [[llama-index]] 的RAG
- 根據[教學](https://docs.llamaindex.ai/en/stable/module_guides/models/llms/)，發現 [[phi-3-mini-4k-instruct]] ，也許可以關於text2sql之類的非中文任務可以交給它(llama-index提供的[測試結果](https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/benchmarks/phi-3-mini-4k-instruct.ipynb))
- 超猛的 [[LlamaHub]]
- 繼續做LangChain的實驗
- 出現神奇的問題，明明檢索的是4/11，未完成閱讀的資料，Q3_K_L卻根據

        ==問題==
        根據上文，請問如何設定RAG
        請用20個字簡潔回答問題。
        

(server) E:\Research\extension\chrome-extension>[04:47:19]set OPENAI_API_KEY= 

(server) E:\Research\extension\chrome-extension>[04:47:20]python -m modules.rag
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, retrieval_result)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 82, in generate_answer
    self.llm.chat(input=prompt, system_message="")
  File "E:\Research\extension\chrome-extension\modules\llm.py", line 34, in chat
    response = chat.invoke(message_list)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 170, in invoke
    self.generate_prompt(
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 599, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 456, in generate
    raise e
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 446, in generate
    self._generate_with_cache(
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 671, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_openai\chat_models\base.py", line 522, in _generate
    response = self.client.create(messages=message_dicts, **params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_utils\_utils.py", line 277, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\resources\chat\completions.py", line 579, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 1240, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 921, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 1020, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
        ==參考文獻==
        來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 2. 實驗
- 實驗列表
- [ ] LangChain RAG方法整理、參數整理
- [ ] Llama-index RAG方法整理、參數整理
- [ ] 可用LLM整理、參數整理
- [ ] 可用Embedded整理、參數整理
- [ ] 資料集整理、分類、生成
- 結果
- 最近遇到的tgi莫名斷線問題解決了，~~是truncate=512異常切斷造成編碼錯誤~~，是debug函式的問題，把debug輸出關掉就不會報錯了
- `-e LOG_LEVEL="info,text_generation_router=debug" \`
- 猜測當token大於一定長度的時候會出現這個問題
- 將Lab中的huggingfaceendpoint改成chat，以使用TGI提供的chat template功能
- 實驗langchain的chat和openai的chat設定
```
llm = HuggingFaceEndpoint(

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-03.md
# 1. 系統
- 設定頁面
- 根據[這個issue](https://github.com/gradio-app/gradio/issues/7541)，必須把compoment作為input傳到函數中才能取得最新的值，否則value屬性本來就只能拿到初始值
- gr.Error必須被raise出去才會成功丟警告出來
- 完成
- 模型端
- Taiwan-LLM有2.1版，之前好像都用2.0.1版
- 官方推薦使用 [[LLaMA-Factory]] 微調
- ~~TGI好像會自動把system覆蓋掉~~
- 修正，是程式問題，修正後正常
- 使用openAI函數溝通tgi成功，從tgi的debug訊息來看應該是tgi那邊會自動套用prompt(?)

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-28.md
- [ ] 待實驗
- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/
- [ ] GEMMA
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典
- [x] 解決讀取文字會動到剪貼簿的問題
- 用 `pyperclip.copy('string')` 和 `pyperclip.paste()`  將原本剪貼簿中的資訊備份下來

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-13.md
# 1. 實驗
- 測試 [[llama-index]] 的RAG
- 根據[教學](https://docs.llamaindex.ai/en/stable/module_guides/models/llms/)，發現 [[phi-3-mini-4k-instruct]] ，也許可以關於text2sql之類的非中文任務可以交給它(llama-index提供的[測試結果](https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/benchmarks/phi-3-mini-4k-instruct.ipynb))
- 超猛的 [[LlamaHub]]
- 繼續做LangChain的實驗
- 出現神奇的問題，明明檢索的是4/11，未完成閱讀的資料，Q3_K_L卻根據

        ==問題==
        根據上文，請問如何設定RAG
        請用20個字簡潔回答問題。
        

(server) E:\Research\extension\chrome-extension>[04:48:32]python -m modules.rag
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("請問如何設定RAG")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, retrieval_result)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 83, in generate_answer
    if self.config["use_llm"]:
       ~~~~~~~~~~~^^^^^^^^^^^
KeyError: 'use_llm'
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.13044822
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
        ==參考文獻==
        來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 999. 靈感
- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  
[^1]: https://ithelp.ithome.com.tw/articles/10340284
[^2]: https://github.com/huggingface/text-generation-inference/issues/1201

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 2. 實驗
- 實驗列表
- [ ] LangChain RAG方法整理、參數整理
- [ ] Llama-index RAG方法整理、參數整理
- [ ] 可用LLM整理、參數整理
- [ ] 可用Embedded整理、參數整理
- [ ] 資料集整理、分類、生成
- 結果
- 最近遇到的tgi莫名斷線問題解決了，~~是truncate=512異常切斷造成編碼錯誤~~，是debug函式的問題，把debug輸出關掉就不會報錯了
- `-e LOG_LEVEL="info,text_generation_router=debug" \`
- 猜測當token大於一定長度的時候會出現這個問題
- 將Lab中的huggingfaceendpoint改成chat，以使用TGI提供的chat template功能
- 實驗langchain的chat和openai的chat設定
```
llm = HuggingFaceEndpoint(

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-03.md
# 1. 系統
- 設定頁面
- 根據[這個issue](https://github.com/gradio-app/gradio/issues/7541)，必須把compoment作為input傳到函數中才能取得最新的值，否則value屬性本來就只能拿到初始值
- gr.Error必須被raise出去才會成功丟警告出來
- 完成
- 模型端
- Taiwan-LLM有2.1版，之前好像都用2.0.1版
- 官方推薦使用 [[LLaMA-Factory]] 微調
- ~~TGI好像會自動把system覆蓋掉~~
- 修正，是程式問題，修正後正常
- 使用openAI函數溝通tgi成功，從tgi的debug訊息來看應該是tgi那邊會自動套用prompt(?)

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-28.md
- [ ] 待實驗
- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/
- [ ] GEMMA
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典
- [x] 解決讀取文字會動到剪貼簿的問題
- 用 `pyperclip.copy('string')` 和 `pyperclip.paste()`  將原本剪貼簿中的資訊備份下來

        ==問題==
        根據上文，請問如何設定RAG
        請用20個字簡潔回答問題。
        
content='請提供您希望了解的RAG設定方法或參數，例如LangChain RAG方法整理、參數整理，或Llama-index RAG方法整理、參數整理。' response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 924, 'total_tokens': 963}, 'model_name': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'system_fingerprint': '2.0.2-sha-9546534', 'finish_reason': 'eos_token', 'logprobs': None} id='run-78bc82ea-a6d9-416e-aaa7-112fc74ba469-0'

(server) E:\Research\extension\chrome-extension>[04:49:24]python -m modules.rag
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 88, in <module>
    result = rag_obj.query("RALM和甚麼概念類似?")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, retrieval_result)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 83, in generate_answer
    if self.config["use_llm"]:
       ~~~~~~~~~~~^^^^^^^^^^^
KeyError: 'use_llm'
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.273954
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
        ==參考文獻==
        來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
- [ ] [NEUMAI](https://docs.neum.ai/get-started/introduction)  
- [ ] 待實驗
- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/
- [ ] GEMMA
- [ ] [[HyDE]]
- [ ] LLM的上下文與few-shot
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-01-13.md
- Vicuna-13B：这是一个开源的语言模型，是LLaMA的后代，使用了从ShareGPT收集的用户共享对话进行微调。
- GPT-3：这是另一个语言模型，可以通过提供相关的问题-SPARQL对和测试问题来生成正确的SPARQL查询。

请注意，这些语言模型是用于在学术知识图谱问答中生成SPARQL查询的。 Pages: ["few-shot llm prompting", "the scholarly kgqa model", "question analysis"]
```

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-01-13.md
問題：請介紹這篇論文
回答：
這篇論文介紹了一個學術知識圖譜問答（KGQA）系統，該系統利用大型語言模型（LLM）以few-shot方式回答文獻資料庫中的自然語言問題。該模型通過一個基於BERT的句子編碼器識別與測試問題相關的前n個相似訓練問題，並檢索它們對應的SPARQL查詢語句。使用這些相似問題-SPARQL對作為示例，與測試問題一起創建一個提示語句，然後將提示語句傳遞給LLM進行SPARQL生成。最後，運行SPARQL查詢以對應的學術知識圖譜進行查詢，並返回答案。這個系統在SciQA測試集上達到了99.0\%的F1分數，是Scholarly-QALD-23挑戰賽SciQA排行榜的亞軍。
```
```
(myLLM) domaj@Domaj-server:~/Research/myLLM$ python step2.query.py
Distance: [[0.49441427 0.5016975  0.50322545 0.5052259  0.51162815]]

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-18.md
# 999. 靈感
- 定義類似含義的術語，由ChatGPT生成類似的描述，用於評估嵌入模型在領域中的效果。  
[^1]: https://docs.python.org/3/library/urllib.parse.html#urllib.parse.quote
[^2]: https://www.gradio.app/docs/gradio/chatbot#initialization

        ==問題==
        根據上文，RALM和甚麼概念類似?
        請用20個字簡潔回答問題。
        
content='根據上文，RALM類似重要的概念。' response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 951, 'total_tokens': 964}, 'model_name': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'system_fingerprint': '2.0.2-sha-9546534', 'finish_reason': 'eos_token', 'logprobs': None} id='run-43b843c2-e7f7-4ed7-99f8-ef9dd20a9518-0'

(server) E:\Research\extension\chrome-extension>[04:50:45]python -m modules.rag
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 86, in <module>
    result = rag_obj.query("RALM和甚麼概念類似?")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 30, in query
    "context": context,
               ^^^^^^^
NameError: name 'context' is not defined
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.273954
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
        ==參考文獻==
        來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
- [ ] [NEUMAI](https://docs.neum.ai/get-started/introduction)  
- [ ] 待實驗
- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/
- [ ] GEMMA
- [ ] [[HyDE]]
- [ ] LLM的上下文與few-shot
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典

        ==問題==
        根據上文，RALM和甚麼概念類似?
        請用20個字簡潔回答問題。
        
content='根據上文，RALM類似Multi-Source Information Management概念。' response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 336, 'total_tokens': 352}, 'model_name': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'system_fingerprint': '2.0.2-sha-9546534', 'finish_reason': 'eos_token', 'logprobs': None} id='run-53399f06-1bcd-4624-849d-b9017a0e70cd-0'

(server) E:\Research\extension\chrome-extension>[04:51:45]python -m modules.rag
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 86, in <module>
    result = rag_obj.query("RALM類似什麼概念？")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 30, in query
    "context": context,
               ^^^^^^^
NameError: name 'context' is not defined
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.28215396
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
        ==參考文獻==
        來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
- [ ] [NEUMAI](https://docs.neum.ai/get-started/introduction)  
- [ ] 待實驗
- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/
- [ ] GEMMA
- [ ] [[HyDE]]
- [ ] LLM的上下文與few-shot
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典

        ==問題==
        根據上文，RALM類似什麼概念？
        請用20個字簡潔回答問題。
        
content='根據上文，RALM類似Multi-Source Information Management概念。' response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 335, 'total_tokens': 351}, 'model_name': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'system_fingerprint': '2.0.2-sha-9546534', 'finish_reason': 'eos_token', 'logprobs': None} id='run-0fbef2ba-1fb1-4f68-a91f-639a5609999f-0'

(server) E:\Research\extension\chrome-extension>[04:53:28]python -m modules.rag
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 87, in <module>
    result = rag_obj.query("在2024/4/17，我做了什麼實驗？")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 30, in query
    "context": context,
               ^^^^^^^
NameError: name 'context' is not defined
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2960534
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
        ==參考文獻==
        來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-24.md
# 1. [[Whisper-Finetune]]
![[Whisper-Finetune#0924實驗]]

        ==問題==
        根據上文，在2024/4/17，我做了什麼實驗？
        請用20個字簡潔回答問題。
        
content='資訊不足' response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 207, 'total_tokens': 210}, 'model_name': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'system_fingerprint': '2.0.2-sha-9546534', 'finish_reason': 'eos_token', 'logprobs': None} id='run-be35777d-f829-4246-b652-c84f93ec0a63-0'

(server) E:\Research\extension\chrome-extension>[05:03:16]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 82, in <module>
    result = rag_obj.query("在2024/4/17，我做了什麼實驗？")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, conotext)
                                              ^^^^^^^^
NameError: name 'conotext' is not defined. Did you mean: 'context'?
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2960534
float32

(server) E:\Research\extension\chrome-extension>[05:03:53]python -m modules.rag
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 82, in <module>
    result = rag_obj.query("在2024/4/17，我做了什麼實驗？")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, context)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 77, in generate_answer
    return llm_result.content
           ^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'content'
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2960534
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-24.md
# 1. [[Whisper-Finetune]]
![[Whisper-Finetune#0924實驗]]

==問題==
根據上文，在2024/4/17，我做了什麼實驗？
請用20個字簡潔回答問題。

content='資訊不足' response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 201, 'total_tokens': 204}, 'model_name': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'system_fingerprint': '2.0.2-sha-9546534', 'finish_reason': 'eos_token', 'logprobs': None} id='run-67b813d3-9a4c-4efd-9dc8-5bff485d77ae-0'

(server) E:\Research\extension\chrome-extension>[05:04:16]python -m modules.rag
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 82, in <module>
    result = rag_obj.query("在2024/4/17，我做了什麼實驗？")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 35, in query
    "retrieval_method": self.retrieval_method,
                        ^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'rag' object has no attribute 'retrieval_method'
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2960534
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-24.md
# 1. [[Whisper-Finetune]]
![[Whisper-Finetune#0924實驗]]

==問題==
根據上文，在2024/4/17，我做了什麼實驗？
請用20個字簡潔回答問題。


(server) E:\Research\extension\chrome-extension>[05:06:47]python -m modules.rag
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 82, in <module>
    result = rag_obj.query("在2024/4/17，我做了什麼實驗？")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 36, in query
    "LLM_model": self.llm_model_name,
                 ^^^^^^^^^^^^^^^^^^^
AttributeError: 'rag' object has no attribute 'llm_model_name'
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2960534
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-24.md
# 1. [[Whisper-Finetune]]
![[Whisper-Finetune#0924實驗]]

==問題==
根據上文，在2024/4/17，我做了什麼實驗？
請用20個字簡潔回答問題。


(server) E:\Research\extension\chrome-extension>[05:09:02]python -m modules.rag
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2960534
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-24.md
# 1. [[Whisper-Finetune]]
![[Whisper-Finetune#0924實驗]]

==問題==
根據上文，在2024/4/17，我做了什麼實驗？
請用20個字簡潔回答問題。

{'answer_text': '資訊不足', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-27.md\n# 2. 跑實驗\n\n來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-24.md\n# 1. [[Whisper-Finetune]]\n![[Whisper-Finetune#0924實驗]]', 'rag_parameter': {'query': '在2024/4/17，我做了什麼實驗？', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}

(server) E:\Research\extension\chrome-extension>[05:11:27]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 83, in <module>
    result = rag_obj.query("在2024/4/17，我做了什麼實驗？")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 24, in query
    context = self.format_docs(retrieval_result)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 64, in format_docs
    return "\n\n".join([document.page_content for document in documents])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not iterable
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在

(server) E:\Research\extension\chrome-extension>[05:11:55]python -m modules.rag
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2960534
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-24.md
# 1. [[Whisper-Finetune]]
![[Whisper-Finetune#0924實驗]]

==問題==
根據上文，在2024/4/17，我做了什麼實驗？
請用20個字簡潔回答問題。

{'answer_text': '資訊不足', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-27.md\n# 2. 跑實驗\n\n來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-24.md\n# 1. [[Whisper-Finetune]]\n![[Whisper-Finetune#0924實驗]]', 'rag_parameter': {'query': '在2024/4/17，我做了什麼實驗？', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}

(server) E:\Research\extension\chrome-extension>[05:15:37]python -m modules.rag

Filter:   0%|          | 0/51 [00:00<?, ? examples/s]
Filter: 100%|██████████| 51/51 [00:00<00:00, 3396.41 examples/s]

Filter:   0%|          | 0/38 [00:00<?, ? examples/s]
Filter: 100%|██████████| 38/38 [00:00<00:00, 2925.65 examples/s]

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  3%|▎         | 1/36 [00:06<03:52,  6.65s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  6%|▌         | 2/36 [00:10<02:51,  5.03s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  8%|▊         | 3/36 [00:14<02:30,  4.57s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 11%|█         | 4/36 [00:18<02:18,  4.34s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 14%|█▍        | 5/36 [00:22<02:07,  4.13s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 17%|█▋        | 6/36 [00:25<01:57,  3.90s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 19%|█▉        | 7/36 [00:30<01:57,  4.06s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。

{'answer_text': '請參考「Obsidian Git」設定，在 Obsidian 中開啟「Vault」並確認「obsidian-git」已安裝，然後設定 SSH 金鑰。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-07-24.md\n# 新增宿舍的筆記同步\n1. 參考[[Git指令]]，新增ssh key\n2. 使用ssh -T測試OK\n3. 用[[git clone]]將整份筆記下載\n4. 在Obsidian中開啟vault\n5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)\n6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題\n7. 使用以下指令重製ssh-key密碼為空\n```\nssh-keygen -p -f github_key\n```\n8. 重製為空後即可正常使用\n註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。', 'rag_parameter': {'query': '如何設定Obsidian同步?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.057200395
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-03.md
>In computing, an ontology is then a concrete, formal representation—a convention—on what terms mean within the scope in which they are used (e.g., a given domain). Like all conventions, the usefulness of an ontology depends on how broadly and consistently it is adopted and how detailed it is. Knowledge graphs that use a shared ontology will be more interoperable. Given that ontologies are formal representations, they can further be used to

==問題==
根據上文，Ontology是什麼?
請用20個字簡潔回答問題。

{'answer_text': '根據上文，Ontology是計算機中對特定領域的術語進行具體、正式代表的方式，用以表示這些術語的意思。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-03.md\n>In computing, an ontology is then a concrete, formal representation—a convention—on what terms mean within the scope in which they are used (e.g., a given domain). Like all conventions, the usefulness of an ontology depends on how broadly and consistently it is adopted and how detailed it is. Knowledge graphs that use a shared ontology will be more interoperable. Given that ontologies are formal representations, they can further be used to', 'rag_parameter': {'query': 'Ontology是什麼?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2588572
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-07.md
# 2. 測試[[LLaMA2]]
中文支援不佳，嘗試使用中文微調專案[[Chinese-LLaMA-Alpaca-2]]
及webui專案[[text-generation-webui]]
設定參考[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh)
- 須解決簡體中文的問題

==問題==
根據上文，llama支援中文嗎?
請用20個字簡潔回答問題。

{'answer_text': '不，LLaMA的中文支持不佳。您可以嘗試使用中文微調專案Chinese-LLaMA-Alpaca-2和webui專案text-generation-webui。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-07.md\n# 2. 測試[[LLaMA2]]\n中文支援不佳，嘗試使用中文微調專案[[Chinese-LLaMA-Alpaca-2]]\n及webui專案[[text-generation-webui]]\n設定參考[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh)\n- 須解決簡體中文的問題', 'rag_parameter': {'query': 'llama支援中文嗎?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1619676
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

==問題==
根據上文，在mysql中如何將多張表合併?
請用20個字簡潔回答問題。


 22%|██▏       | 8/36 [00:35<02:04,  4.46s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 25%|██▌       | 9/36 [00:39<01:53,  4.22s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 28%|██▊       | 10/36 [00:43<01:46,  4.11s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 31%|███       | 11/36 [00:46<01:37,  3.90s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 33%|███▎      | 12/36 [00:50<01:32,  3.84s/it]{'answer_text': '在MySQL中，將多張表合併可使用JOIN句法，例如LEFT JOIN、RIGHT JOIN、FULL JOIN等，結合不同表的資料。', 'context': "來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md\n# [[MySQL]]匯出檔案\n參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join\n``` mysql\nmysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG\nHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;", 'rag_parameter': {'query': '在mysql中如何將多張表合併?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.32915065
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

==問題==
根據上文，如何將mysql的表匯出?
請用20個字簡潔回答問題。

{'answer_text': '請使用SELECT INTO OUTFILE指令匯出MySQL表，並指定輸出檔名與路徑。', 'context': "來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md\n# [[MySQL]]匯出檔案\n參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join\n``` mysql\nmysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG\nHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;", 'rag_parameter': {'query': '如何將mysql的表匯出?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1116085
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-06.md
# 4. 在引用上實在很不方便，找了一些別的插件
http://ob-plugin.eryajf.net/#/ob-plugin/01.Obsidian%E6%8F%92%E4%BB%B6%E5%91%A8%E5%88%8A%E7%AC%AC%E4%B8%80%E6%9C%9F

==問題==
根據上文，什麼時候安裝了obsidian的引用外掛?
請用20個字簡潔回答問題。

{'answer_text': '資訊不足', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-06.md\n# 4. 在引用上實在很不方便，找了一些別的插件\nhttp://ob-plugin.eryajf.net/#/ob-plugin/01.Obsidian%E6%8F%92%E4%BB%B6%E5%91%A8%E5%88%8A%E7%AC%AC%E4%B8%80%E6%9C%9F', 'rag_parameter': {'query': '什麼時候安裝了obsidian的引用外掛?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.11549372
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 4. 如何選擇port?
參考[^2] ，選擇沒人佔用的27709  
[^1]: https://stackoverflow.com/questions/42631509/piping-node-js-to-python
[^2]: https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=27709

==問題==
根據上文，怎麼選擇端口的?
請用20個字簡潔回答問題。

{'answer_text': '請參考IANA的服務與埠號碼分配（https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=27709），並選擇沒人佔用的埠號27709。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md\n# 4. 如何選擇port?\n參考[^2] ，選擇沒人佔用的27709  \n[^1]: https://stackoverflow.com/questions/42631509/piping-node-js-to-python\n[^2]: https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=27709', 'rag_parameter': {'query': '怎麼選擇端口的?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.35214102
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-21.md
# 4. 開會
- 冒號問題，如果資訊比較不重要可以刪除
- 或者用減號、全形冒號等
```
▸標籤管理實作
▸PDF抽取方法實驗及整理
▸s2orc-doc2json、 grobid
▸文獻閱讀: Too many tags spoil the metadata: investigating the knowledge management of scientific research with semantic web technologies(2019)
▸其他: 冒號問題
```

==問題==
根據上文，如何解決論文標題中的冒號問題?
請用20個字簡潔回答問題。

D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 36%|███▌      | 13/36 [00:53<01:26,  3.77s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 39%|███▉      | 14/36 [00:57<01:22,  3.75s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 42%|████▏     | 15/36 [01:03<01:31,  4.36s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 44%|████▍     | 16/36 [01:07<01:23,  4.19s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
{'answer_text': '在論文標題中解決冒號問題，可以在标签名称或作者名称加入减号或全形冒号。例如："应用减号取代标签名称中的冒号：作者-论文题目"。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-21.md\n# 4. 開會\n- 冒號問題，如果資訊比較不重要可以刪除\n- 或者用減號、全形冒號等\n```\n▸標籤管理實作\n▸PDF抽取方法實驗及整理\n▸s2orc-doc2json、 grobid\n▸文獻閱讀: Too many tags spoil the metadata: investigating the knowledge management of scientific research with semantic web technologies(2019)\n▸其他: 冒號問題\n```', 'rag_parameter': {'query': '如何解決論文標題中的冒號問題?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.1906288
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

==問題==
根據上文，哪些因素可能會影響語音識別的準確度?
請用20個字簡潔回答問題。

{'answer_text': '聲道、取樣率、語速、bit率等因素可能影響語音識別的準確度。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md\n# 3. 除了降噪外其他可能影響語音識別的因素\n#靈感/語音識別\n1. 聲道\n2. 取樣率\n3. 語速\n4. bit率', 'rag_parameter': {'query': '哪些因素可能會影響語音識別的準確度?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16114116
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 999. 靈感
- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  
[^1]: https://ithelp.ithome.com.tw/articles/10340284
[^2]: https://github.com/huggingface/text-generation-inference/issues/1201

==問題==
根據上文，如何微調whisper?
請用20個字簡潔回答問題。

{'answer_text': '請參考[^1]、[^2]，針對whisper進行指令微調整和基座模型RAG微調可能有效。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md\n# 999. 靈感\n- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  \n[^1]: https://ithelp.ithome.com.tw/articles/10340284\n[^2]: https://github.com/huggingface/text-generation-inference/issues/1201', 'rag_parameter': {'query': '如何微調whisper?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.106168725
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-03.md
# 2. 重新點一次view裡面的顯示prefix才能正常顯示

==問題==
根據上文，如何解決protégé中的顯示問題?
請用20個字簡潔回答問題。

{'answer_text': '資訊不足', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-10-03.md\n# 2. 重新點一次view裡面的顯示prefix才能正常顯示', 'rag_parameter': {'query': '如何解決protégé中的顯示問題?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2692792
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-16.md
`mklink "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\make.exe" "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\mingw32-make.exe"`
- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`
- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性
- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要
- [ ] 整理文獻
- [ ] 閱讀清單

==問題==
根據上文，為甚麼系統要使用多執行緒?
請用20個字簡潔回答問題。

{'answer_text': '系統可能使用多執行緒以同時處理多項任務、提升效能和反應時間。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-16.md\n`mklink "E:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin\\make.exe" "E:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin\\mingw32-make.exe"`\n- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`\n- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性\n- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要\n- [ ] 整理文獻\n- [ ] 閱讀清單', 'rag_parameter': {'query': '為甚麼系統要使用多執行緒?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.008740316
float32
format後的prompt: 
 47%|████▋     | 17/36 [01:10<01:15,  3.97s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 50%|█████     | 18/36 [01:14<01:09,  3.86s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 53%|█████▎    | 19/36 [01:17<01:05,  3.84s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 56%|█████▌    | 20/36 [01:22<01:05,  4.09s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 58%|█████▊    | 21/36 [01:26<01:01,  4.07s/it]Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-25.md
# 3. 根據chrome extensione官方說明，30秒會自動將service worker關閉，因此採用25秒一次的心跳來解決這個問題[^1]
- 之後如果確認後端不會主動傳訊息給SW，則可以考慮改為http ( 只要修改send函數應該就行了 )

==問題==
根據上文，service worker幾秒後會自動關閉?
請用20個字簡潔回答問題。

{'answer_text': '25秒後服務工作者會自動關閉。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-25.md\n# 3. 根據chrome extensione官方說明，30秒會自動將service worker關閉，因此採用25秒一次的心跳來解決這個問題[^1]\n- 之後如果確認後端不會主動傳訊息給SW，則可以考慮改為http ( 只要修改send函數應該就行了 )', 'rag_parameter': {'query': 'service worker幾秒後會自動關閉?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.19715488
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-28.md
# 9. 關於chrome-extension中不允許在html中直接呼叫javascript函數
- 因為chrome-extension不允許CSP
- 但好像可以用[這個](https://stackoverflow.com/questions/72186787/chrome-extensions-and-csp)允許特定網站的CSP?

==問題==
根據上文，為什麼chrome-extension不能在html中直接呼叫javascript函數
請用20個字簡潔回答問題。

{'answer_text': '因Chrome-extension不允許CSP，限制在html中直接呼叫javascript函數。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-28.md\n# 9. 關於chrome-extension中不允許在html中直接呼叫javascript函數\n- 因為chrome-extension不允許CSP\n- 但好像可以用[這個](https://stackoverflow.com/questions/72186787/chrome-extensions-and-csp)允許特定網站的CSP?', 'rag_parameter': {'query': '為什麼chrome-extension不能在html中直接呼叫javascript函數', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.109264515
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-13.md
# 4. 閱讀論文
- 在這篇[^4] 論文中提到，實驗中為了在最小化幻覺和嚴格生成之間取得平衡，將GPT的溫度設為0，llama的溫度設為0.1，但論文中未提及更詳細的理由

==問題==
根據上文，ChatGPT的溫度設為多少最恰當?
請用20個字簡潔回答問題。

{'answer_text': '根據上文，ChatGPT的溫度設為0最適當。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-13.md\n# 4. 閱讀論文\n- 在這篇[^4] 論文中提到，實驗中為了在最小化幻覺和嚴格生成之間取得平衡，將GPT的溫度設為0，llama的溫度設為0.1，但論文中未提及更詳細的理由', 'rag_parameter': {'query': 'ChatGPT的溫度設為多少最恰當?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.20829745
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-22.md
# 999. 其他
- How can we evaluate the ability of each LLM to generate Cypher?
- tag嵌套的必要性
- markdown的結構化 #靈感
- 例如tab代表有
- 可能要重新考慮nDCG來比對[[Embeddeding|嵌入]]結果
- 可能要檢查 [[Mean Average Precision|MAP]] 的算法是否有誤
- 以前不熟悉的關鍵字會慢慢熟悉，要怎麼應對這種情況? #靈感
[^1]: https://github.com/microsoft/terminal/issues/14018
[^2]: https://stackoverflow.com/questions/32127524/how-to-install-and-use-make-in-windows

==問題==
根據上文，嵌入有可能遇到什麼問題?
請用20個字簡潔回答問題。

{'answer_text': '嵌入可能遇到的問題包括需要重新考慮nDCG、檢查MAP算法以及應對熟悉度變化。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-22.md\n# 999. 其他\n- How can we evaluate the ability of each LLM to generate Cypher?\n- tag嵌套的必要性\n- markdown的結構化 #靈感\n- 例如tab代表有\n- 可能要重新考慮nDCG來比對[[Embeddeding|嵌入]]結果\n- 可能要檢查 [[Mean Average Precision|MAP]] 的算法是否有誤\n- 以前不熟悉的關鍵字會慢慢熟悉，要怎麼應對這種情況? #靈感\n[^1]: https://github.com/microsoft/terminal/issues/14018\n[^2]: https://stackoverflow.com/questions/32127524/how-to-install-and-use-make-in-windows', 'rag_parameter': {'query': '嵌入有可能遇到什麼問題?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.090603866
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-16.md
# 1. [[Whisper]]
嘗試解決幻覺問題
https://github.com/openai/whisper/discussions/679
加上參數--condition_on_previous_text False  
##  評估方式?
根據不同面向，例如冗字、專有名詞，其他錯誤等  
又加了一堆論文哈哈

==問題==
根據上文，有哪些方法可以解決語音辨識的幻聽問題
請用20個字簡潔回答問題。

D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 61%|██████    | 22/36 [01:30<00:55,  4.00s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 64%|██████▍   | 23/36 [01:34<00:51,  3.92s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 67%|██████▋   | 24/36 [01:39<00:50,  4.21s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 69%|██████▉   | 25/36 [01:42<00:44,  4.07s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
{'answer_text': '消息不足', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-16.md\n# 1. [[Whisper]]\n嘗試解決幻覺問題\nhttps://github.com/openai/whisper/discussions/679\n加上參數--condition_on_previous_text False  \n##  評估方式?\n根據不同面向，例如冗字、專有名詞，其他錯誤等  \n又加了一堆論文哈哈', 'rag_parameter': {'query': '有哪些方法可以解決語音辨識的幻聽問題', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16820273
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

==問題==
根據上文，語音辨識可以有哪些評估的方向
請用20個字簡潔回答問題。

{'answer_text': '聲音聲道、取樣率、語速、位元率。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md\n# 3. 除了降噪外其他可能影響語音識別的因素\n#靈感/語音識別\n1. 聲道\n2. 取樣率\n3. 語速\n4. bit率', 'rag_parameter': {'query': '語音辨識可以有哪些評估的方向', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.071613215
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 3. 關於瀏覽器插件的溝通方式選擇
pipe or websocket
選擇websocket，因為javascript無法操作作業系統層級的pipe
查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe
理論上也確實如此，否則瀏覽器插件的權限很容易太大

==問題==
根據上文，為什麼瀏覽器插件不使用pipe?
請用20個字簡潔回答問題。

{'answer_text': '瀏覽器插件不使用pipe是因為javascript無法操作作業系統層級的pipe，且提高權限可能導致安全問題。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md\n# 3. 關於瀏覽器插件的溝通方式選擇\npipe or websocket\n選擇websocket，因為javascript無法操作作業系統層級的pipe\n查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe\n理論上也確實如此，否則瀏覽器插件的權限很容易太大', 'rag_parameter': {'query': '為什麼瀏覽器插件不使用pipe?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2258542
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

==問題==
根據上文，哪些因素可能會影響語音識別？
請用20個字簡潔回答問題。

{'answer_text': '聲道、取樣率、語速、bit率等因素可能影響語音識別。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md\n# 3. 除了降噪外其他可能影響語音識別的因素\n#靈感/語音識別\n1. 聲道\n2. 取樣率\n3. 語速\n4. bit率', 'rag_parameter': {'query': '哪些因素可能會影響語音識別？', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.26710048
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-30.md
# 3. 將宿舍電腦的 StableDiffusion 虛擬環境中的 [[pytorch]] 更新到pytorch2[^1]
1. 切換到虛擬環境
`.\envs\scripts\activate.bat`
2. 檢查pip路徑
`pip --version`
3. 參考[官網](https://pytorch.org/get-started/locally/)訊息，CUDA11.8
`pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`
4. 結果
```
Installing collected packages: mpmath, sympy, torch, torchvision, torchaudio
Attempting uninstall: torch
Found existing installation: torch 1.13.1+cu117

==問題==
根據上文，我參考了哪個教學將pytorch更新到pytorch2?
請用20個字簡潔回答問題。

{'answer_text': '您參考了官網 (https://pytorch.org/get-started/locally/) 教學將 pytorch 更新到 pytorch2。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-30.md\n# 3. 將宿舍電腦的 StableDiffusion 虛擬環境中的 [[pytorch]] 更新到pytorch2[^1]\n1. 切換到虛擬環境\n`.\\envs\\scripts\\activate.bat`\n2. 檢查pip路徑\n`pip --version`\n3. 參考[官網](https://pytorch.org/get-started/locally/)訊息，CUDA11.8\n`pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`\n4. 結果\n```\nInstalling collected packages: mpmath, sympy, torch, torchvision, torchaudio\nAttempting uninstall: torch\nFound existing installation: torch 1.13.1+cu117', 'rag_parameter': {'query': '我參考了哪個教學將pytorch更新到pytorch2?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.3263341
float32
format後的prompt: 
 72%|███████▏  | 26/36 [01:46<00:39,  3.98s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 75%|███████▌  | 27/36 [01:50<00:35,  3.91s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 78%|███████▊  | 28/36 [01:53<00:30,  3.78s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 81%|████████  | 29/36 [01:57<00:26,  3.74s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-11-15.md
# 1. 考慮和 [[EndNote]] 連動的可能性
- [[websocket]] 攔截
- [[RIS]] 等引用文件
- 文獻清單
- 其實 [[Bibtex]] 應該更適合作為相容性最好的引用格式而非[[RIS]]

==問題==
根據上文，bibtex和ris差在哪？
請用20個字簡潔回答問題。

{'answer_text': '二種引用格式：BibTeX 兼容性較 RIS 高，BibTeX 更適合。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-11-15.md\n# 1. 考慮和 [[EndNote]] 連動的可能性\n- [[websocket]] 攔截\n- [[RIS]] 等引用文件\n- 文獻清單\n- 其實 [[Bibtex]] 應該更適合作為相容性最好的引用格式而非[[RIS]]', 'rag_parameter': {'query': 'bibtex和ris差在哪？', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.4384315
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-11-23.md
# 2. 研究過程中，除了這個研究的貢獻外，在相關研究中也可以得到很多資訊
可以在筆記中包含，提到這篇研究的研究、該研究中的說明、評價、引用編號等
#靈感

==問題==
根據上文，可以從論文的相關研究中得到什麼？
請用20個字簡潔回答問題。

{'answer_text': '從論文的相關研究中，你可以獲得更多資訊、研究、說明、評價和引用編號。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-11-23.md\n# 2. 研究過程中，除了這個研究的貢獻外，在相關研究中也可以得到很多資訊\n可以在筆記中包含，提到這篇研究的研究、該研究中的說明、評價、引用編號等\n#靈感', 'rag_parameter': {'query': '可以從論文的相關研究中得到什麼？', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.44338506
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-04.md
# 5. 土豆挑戰

==問題==
根據上文，土豆挑戰是什麼？
請用20個字簡潔回答問題。

{'answer_text': '土豆挑戰是與豆品種類、大豆種植、和食品加工等領域有關的挑戰。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-04.md\n# 5. 土豆挑戰', 'rag_parameter': {'query': '土豆挑戰是什麼？', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1314348
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-08.md
# 1. 撰寫chrome extension
- 關於popus.js和background.js的溝通
- 遇到錯誤 `Unchecked runtime.lastError: The message port closed before a response was received.`
- 經過正確的使用sendmessage的callback的第三個參數sendResponse完成完整的溝通。
- 準確的說是service-worker，因為在版本三中並沒有background page的存在，而是改為service worker。
- 同上，有很多用法在第二版可以用，但在第三版不能用。

==問題==
根據上文，如何解決The message port closed before a response was received
請用20個字簡潔回答問題。

{'answer_text': '解決方法：正確使用sendMessage的callback的第三個參數sendResponse完成完整的溝通。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-08.md\n# 1. 撰寫chrome extension\n- 關於popus.js和background.js的溝通\n- 遇到錯誤 `Unchecked runtime.lastError: The message port closed before a response was received.`\n- 經過正確的使用sendmessage的callback的第三個參數sendResponse完成完整的溝通。\n- 準確的說是service-worker，因為在版本三中並沒有background page的存在，而是改為service worker。\n- 同上，有很多用法在第二版可以用，但在第三版不能用。', 'rag_parameter': {'query': '如何解決The message port closed before a response was received', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.062017523
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-22.md
- 註: daemon關閉時會強制關閉，若有讀寫檔、暫存檔等需要額外處理，例如在主thread中捕捉相關的事件。  
- ChatGPT用模擬ctrl+c的方式實現自訂義複製快捷鍵，我喜歡
- 本來無法模擬ctrl+c，後來發現是因為模擬前沒有放開實體按鍵，使用time.sleep或keyboard.release都能解決這個問題，也不需要管理員權限  
- 讀取當前焦點視窗
- 暫時先考慮windows，不考慮mac和linux，因此使用pywin32  
- [[cypher]] 的參數化查詢無法用於標籤或關係上，因此需要使用python的格式化輸入來處理
`query = f"MATCH (n:{tagName})"`

==問題==
根據上文，哪些python套件能監聽快捷鍵？
請用20個字簡潔回答問題。


 83%|████████▎ | 30/36 [02:01<00:22,  3.78s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 86%|████████▌ | 31/36 [02:05<00:19,  3.94s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 89%|████████▉ | 32/36 [02:09<00:15,  3.79s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 92%|█████████▏| 33/36 [02:12<00:11,  3.69s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 94%|█████████▍| 34/36 [02:15<00:07,  3.62s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 97%|█████████▋| 35/36 [02:19<00:03,  3.58s/it]{'answer_text': '請使用pywin32、pyautogui或keyboard等python套件來監聽快捷鍵。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-22.md\n- 註: daemon關閉時會強制關閉，若有讀寫檔、暫存檔等需要額外處理，例如在主thread中捕捉相關的事件。  \n- ChatGPT用模擬ctrl+c的方式實現自訂義複製快捷鍵，我喜歡\n- 本來無法模擬ctrl+c，後來發現是因為模擬前沒有放開實體按鍵，使用time.sleep或keyboard.release都能解決這個問題，也不需要管理員權限  \n- 讀取當前焦點視窗\n- 暫時先考慮windows，不考慮mac和linux，因此使用pywin32  \n- [[cypher]] 的參數化查詢無法用於標籤或關係上，因此需要使用python的格式化輸入來處理\n`query = f"MATCH (n:{tagName})"`', 'rag_parameter': {'query': '哪些python套件能監聽快捷鍵？', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2724631
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-16.md
`mklink "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\make.exe" "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\mingw32-make.exe"`
- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`
- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性
- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要
- [ ] 整理文獻
- [ ] 閱讀清單

==問題==
根據上文，除了pyqt外，當時還考慮哪些類似的套件？
請用20個字簡潔回答問題。

{'answer_text': '除了pyqt，當時還考慮了qt、pyqt5、wxpython等類似套件。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-16.md\n`mklink "E:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin\\make.exe" "E:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin\\mingw32-make.exe"`\n- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`\n- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性\n- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要\n- [ ] 整理文獻\n- [ ] 閱讀清單', 'rag_parameter': {'query': '除了pyqt外，當時還考慮哪些類似的套件？', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.14854458
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-16.md
# 999. 其他
- 根據FastAPI的文檔，建議使用Union來取代Optional功能，但範例中有點錯誤
- 建議避免使用 `name: Optional[str]`，因為實際上name並不是可選的而是必選的
- 就算使用 `def say_hi(name: str | None)` 也不代表不需要參數，必須要設定初始值，如 `def say_hi(name: str | None = None)`  
[^1]: https://stackoverflow.com/questions/63872924/how-can-i-send-an-http-request-from-my-fastapi-app-to-another-site-api
[^2]: https://scrapfly.io/blog/httpx-vs-requests-vs-aiohttp/

==問題==
根據上文，系統中的FastAPI監聽哪個端口？
請用20個字簡潔回答問題。

{'answer_text': '資訊不足', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-16.md\n# 999. 其他\n- 根據FastAPI的文檔，建議使用Union來取代Optional功能，但範例中有點錯誤\n- 建議避免使用 `name: Optional[str]`，因為實際上name並不是可選的而是必選的\n- 就算使用 `def say_hi(name: str | None)` 也不代表不需要參數，必須要設定初始值，如 `def say_hi(name: str | None = None)`  \n[^1]: https://stackoverflow.com/questions/63872924/how-can-i-send-an-http-request-from-my-fastapi-app-to-another-site-api\n[^2]: https://scrapfly.io/blog/httpx-vs-requests-vs-aiohttp/', 'rag_parameter': {'query': '系統中的FastAPI監聽哪個端口？', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.28215396
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

==問題==
根據上文，RALM類似什麼概念？
請用20個字簡潔回答問題。

{'answer_text': '根據上文，RALM類似Multi-Source Information Management概念。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md\n# 3. 找到新關鍵字(ChatGPT)\n- Multi-Source Information Management\n- RALM，重要，需要了解具體定義及其與RAG的區別', 'rag_parameter': {'query': 'RALM類似什麼概念？', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.04661884
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-11.md
# 1. 修改論文
- Multi-Source Data Analysis與Multi-source infomation management system
- 多源資料分析主要注重統合、轉換、除錯並分析資料
- 多源資訊管理主要目的在蒐集與管理資訊

==問題==
根據上文，多源資料分析和管理差在哪？
請用20個字簡潔回答問題。

D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

100%|██████████| 36/36 [02:23<00:00,  3.63s/it]
100%|██████████| 36/36 [02:23<00:00,  3.98s/it]
{'answer_text': '多源資料分析與管理的差異在於分析統合、轉換、除錯資料，而管理則著重於蒐集與管理資訊。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-11.md\n# 1. 修改論文\n- Multi-Source Data Analysis與Multi-source infomation management system\n- 多源資料分析主要注重統合、轉換、除錯並分析資料\n- 多源資訊管理主要目的在蒐集與管理資訊', 'rag_parameter': {'query': '多源資料分析和管理差在哪？', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.06321003
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-18.md
[^10]: https://community.neo4j.com/t/import-individuals-and-relate-to-classes-in-neo4j/24567/2

==問題==
根據上文，在2024/4/17，我看完NEUMAI了嗎？
請用20個字簡潔回答問題。

{'answer_text': '資訊不足', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-18.md\n[^10]: https://community.neo4j.com/t/import-individuals-and-relate-to-classes-in-neo4j/24567/2', 'rag_parameter': {'query': '在2024/4/17，我看完NEUMAI了嗎？', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2960534
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

==問題==
根據上文，在2024/4/17，我做了什麼實驗？
請用20個字簡潔回答問題。

{'answer_text': '資訊不足', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-27.md\n# 2. 跑實驗', 'rag_parameter': {'query': '在2024/4/17，我做了什麼實驗？', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.0678077
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-22.md
- 以後不再測試未經指令微調的模型
- 備份之前的結果後，刪除gemma-2b及TAIDE-LX-7B共計930筆紀錄

==問題==
根據上文，在2024/4/17，我實驗過gemma了嗎?
請用20個字簡潔回答問題。

{'answer_text': '資訊不足', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-22.md\n- 以後不再測試未經指令微調的模型\n- 備份之前的結果後，刪除gemma-2b及TAIDE-LX-7B共計930筆紀錄', 'rag_parameter': {'query': '在2024/4/17，我實驗過gemma了嗎?', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.10619263
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-07.md
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典

==問題==
根據上文，在2024/4/17，我設計完整個架構和所需要的API需求及文件了嗎？
請用20個字簡潔回答問題。

{'answer_text': '資訊不足', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-07.md\n- [ ] [[HyDE]]\n- 系統\n- [ ] 設計整個架構和所需要的API需求及文件\n- [ ] 浮動視窗，類似字典', 'rag_parameter': {'query': '在2024/4/17，我設計完整個架構和所需要的API需求及文件了嗎？', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.12266735
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-17.md
# 2. 試用 [[Chat RTX]]
- 38G，好大
- 下載好久，安裝好久，安裝一個多小時吧，包含下載模型的時間
- 吃爆VRAM、反應不快，基本只收英文
- 因為很卡所以沒有繼續測試下去  
[^3]: https://www.volcengine.com/theme/3863827-W-7-1
[^4]: https://www.pythonforbeginners.com/basics/convert-ini-to-yaml-in-python
[^5]: https://docs.privategpt.dev/recipes/choice-of-llm/list-of-ll-ms

==問題==
根據上文，我對ChatRTX的評價是正面還是負面
請用20個字簡潔回答問題。

{'answer_text': '負面', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-17.md\n# 2. 試用 [[Chat RTX]]\n- 38G，好大\n- 下載好久，安裝好久，安裝一個多小時吧，包含下載模型的時間\n- 吃爆VRAM、反應不快，基本只收英文\n- 因為很卡所以沒有繼續測試下去  \n[^3]: https://www.volcengine.com/theme/3863827-W-7-1\n[^4]: https://www.pythonforbeginners.com/basics/convert-ini-to-yaml-in-python\n[^5]: https://docs.privategpt.dev/recipes/choice-of-llm/list-of-ll-ms', 'rag_parameter': {'query': '我對ChatRTX的評價是正面還是負面', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.056782953
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-21.md
# 2. 跑實驗
- google/gemma-2b-it
- 約20分鐘
- google/gemma-2b
- 約20分鐘
- meta-llama/Llama-2-7b-chat-hf
- 約一小時

==問題==
根據上文，在2024/4/21，我總共花了幾分鐘跑實驗
請用20個字簡潔回答問題。

{'answer_text': '在2024/4/21，你總共花了約3小時跑實驗。', 'context': '來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-21.md\n# 2. 跑實驗\n- google/gemma-2b-it\n- 約20分鐘\n- google/gemma-2b\n- 約20分鐘\n- meta-llama/Llama-2-7b-chat-hf\n- 約一小時', 'rag_parameter': {'query': '在2024/4/21，我總共花了幾分鐘跑實驗', 'embedded_model': 'infgrad/puff-base-v1', 'embedded_db_path': './data/db/chromadb', 'retrieval_method': ['chroma_similarity'], 'LLM_model': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'prompt_template': '不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{context}\n\n==問題==\n根據上文，{question}\n請用20個字簡潔回答問題。\n'}}
None

(server) E:\Research\extension\chrome-extension>[05:24:39]python -m modules.rag
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 110, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 90, in eval
    df = pd.read_excel("./data/rag_eval.xlsx", index_col=0, dtype="str")
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\io\excel\_base.py", line 495, in read_excel
    io = ExcelFile(
         ^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\io\excel\_base.py", line 1550, in __init__
    ext = inspect_excel_format(
          ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\io\excel\_base.py", line 1402, in inspect_excel_format
    with get_handle(
         ^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\io\common.py", line 882, in get_handle
    handle = open(handle, ioargs.mode)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './data/rag_eval.xlsx'

(server) E:\Research\extension\chrome-extension>[05:25:38]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  0%|          | 0/36 [00:05<?, ?it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 110, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 98, in eval
    update_or_append_result(df, {
TypeError: update_or_append_result() missing 1 required positional argument: 'result'
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。


(server) E:\Research\extension\chrome-extension>[05:27:04]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  0%|          | 0/36 [00:06<?, ?it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 111, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 98, in eval
    update_or_append_result(df, {
TypeError: update_or_append_result() missing 1 required positional argument: 'result'
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。


(server) E:\Research\extension\chrome-extension>[05:28:18]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  0%|          | 0/36 [00:06<?, ?it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 112, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 98, in eval
    update_or_append_result(df, {
  File "E:\Research\extension\chrome-extension\modules\utils.py", line 23, in update_or_append_result
    mask &= (df[key]==value)
             ^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\ops\common.py", line 76, in new_method
    return method(self, other)
           ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\arraylike.py", line 40, in __eq__
    return self._cmp_method(other, operator.eq)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\series.py", line 6110, in _cmp_method
    res_values = ops.comparison_op(lvalues, rvalues, op)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\ops\array_ops.py", line 321, in comparison_op
    raise ValueError(
ValueError: ('Lengths must match to compare', (0,), (1,))
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。


(server) E:\Research\extension\chrome-extension>[05:30:49]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

  3%|▎         | 1/36 [00:05<03:19,  5.70s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

  6%|▌         | 2/36 [00:08<02:19,  4.09s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

  8%|▊         | 3/36 [00:11<02:00,  3.64s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The beActive code page: 437
Active code page: 437

(base) E:\Research\extension\chrome-extension>chcp 65001
Active code page: 65001

(base) E:\Research\extension\chrome-extension>[05:32:35]conda activate server

(server) E:\Research\extension\chrome-extension>[05:32:47]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  0%|          | 0/36 [00:04<?, ?it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 113, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 96, in eval
    result = self.query(query)
             ^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, context, model_name=self.config["llm_model"])
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 76, in generate_answer
    llm_result = self.llm.chat(input=prompt, system_message="")
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\llm.py", line 44, in chat
    chat = ChatOpenAI(openai_api_base=self.base_url, model_name=self.model_name, seed=1)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pydantic\v1\main.py", line 341, in __init__
    raise validation_error
pydantic.v1.error_wrappers.ValidationError: 1 validation error for ChatOpenAI
__root__
  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。


(server) E:\Research\extension\chrome-extension>[05:34:03]eActive code page: 437
Active code page: 437

(base) E:\Research\extension\chrome-extension>chcp 65001
Active code page: 65001

(base) E:\Research\extension\chrome-extension>[05:34:27]set OPEN_API_KEY= 

(base) E:\Research\extension\chrome-extension>[05:34:32]python -m modules.rag
Active code page: 437
Active code page: 437

(base) E:\Research\extension\chrome-extension>chcp 65001
Active code page: 65001

(base) E:\Research\extension\chrome-extension>[05:35:12]conda activate server

(server) E:\Research\extension\chrome-extension>[05:35:23]set OPEN_API_KEY= 

(server) E:\Research\extension\chrome-extension>[05:35:31]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  0%|          | 0/36 [00:04<?, ?it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 113, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 96, in eval
    result = self.query(query)
             ^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, context, model_name=self.config["llm_model"])
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 76, in generate_answer
    llm_result = self.llm.chat(input=prompt, system_message="")
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\llm.py", line 44, in chat
    chat = ChatOpenAI(openai_api_base=self.base_url, model_name=self.model_name, seed=1)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pydantic\v1\main.py", line 341, in __init__
    raise validation_error
pydantic.v1.error_wrappers.ValidationError: 1 validation error for ChatOpenAI
__root__
  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。


(server) E:\Research\extension\chrome-extension>[05:35:57]set OPENAI_API_KEY= 

(server) E:\Research\extension\chrome-extension>[05:35:59]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

  3%|▎         | 1/36 [00:05<03:19,  5.70s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

  6%|▌         | 2/36 [00:08<02:18,  4.08s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

  8%|▊         | 3/36 [00:11<02:00,  3.64s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 11%|█         | 4/36 [00:14<01:48,  3.41s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 14%|█▍        | 5/36 [00:20<02:12,  4.28s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 17%|█▋        | 6/36 [00:23<01:50,  3.68s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 19%|█▉        | 7/36 [00:26<01:44,  3.62s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 22%|██▏       | 8/36 [00:29<01:38,  3.51s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 25%|██▌       | 9/36 [00:32<01:28,  3.28s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 28%|██▊       | 10/36 [00:35<01:22,  3.18s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 31%|███       | 11/36 [00:38<01:14,  2.97s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 33%|███▎      | 12/36 [00:40<01:10,  2.92s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 36%|███▌      | 13/36 [00:43<01:05,  2.83s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 39%|███▉      | 14/36 [00:48<01:14,  3.40s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 42%|████▏     | 15/36 [00:50<01:07,  3.19s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 44%|████▍     | 16/36 [00:53<01:01,  3.08s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 47%|████▋     | 17/36 [00:56<00:55,  2.91s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 50%|█████     | 18/36 [00:59<00:51,  2.84s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 53%|█████▎    | 19/36 [01:03<00:56,  3.32s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 56%|█████▌    | 20/36 [01:06<00:50,  3.14s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 58%|█████▊    | 21/36 [01:09<00:46,  3.11s/it]嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.057200395
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-03.md
>In computing, an ontology is then a concrete, formal representation—a convention—on what terms mean within the scope in which they are used (e.g., a given domain). Like all conventions, the usefulness of an ontology depends on how broadly and consistently it is adopted and how detailed it is. Knowledge graphs that use a shared ontology will be more interoperable. Given that ontologies are formal representations, they can further be used to

==問題==
根據上文，Ontology是什麼?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2588572
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-07.md
# 2. 測試[[LLaMA2]]
中文支援不佳，嘗試使用中文微調專案[[Chinese-LLaMA-Alpaca-2]]
及webui專案[[text-generation-webui]]
設定參考[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh)
- 須解決簡體中文的問題

==問題==
根據上文，llama支援中文嗎?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1619676
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

==問題==
根據上文，在mysql中如何將多張表合併?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.32915065
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

==問題==
根據上文，如何將mysql的表匯出?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1116085
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-06.md
# 4. 在引用上實在很不方便，找了一些別的插件
http://ob-plugin.eryajf.net/#/ob-plugin/01.Obsidian%E6%8F%92%E4%BB%B6%E5%91%A8%E5%88%8A%E7%AC%AC%E4%B8%80%E6%9C%9F

==問題==
根據上文，什麼時候安裝了obsidian的引用外掛?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.11549372
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 4. 如何選擇port?
參考[^2] ，選擇沒人佔用的27709  
[^1]: https://stackoverflow.com/questions/42631509/piping-node-js-to-python
[^2]: https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=27709

==問題==
根據上文，怎麼選擇端口的?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.35214102
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-21.md
# 4. 開會
- 冒號問題，如果資訊比較不重要可以刪除
- 或者用減號、全形冒號等
```
▸標籤管理實作
▸PDF抽取方法實驗及整理
▸s2orc-doc2json、 grobid
▸文獻閱讀: Too many tags spoil the metadata: investigating the knowledge management of scientific research with semantic web technologies(2019)
▸其他: 冒號問題
```

==問題==
根據上文，如何解決論文標題中的冒號問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.1906288
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

==問題==
根據上文，哪些因素可能會影響語音識別的準確度?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16114116
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 999. 靈感
- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  
[^1]: https://ithelp.ithome.com.tw/articles/10340284
[^2]: https://github.com/huggingface/text-generation-inference/issues/1201

==問題==
根據上文，如何微調whisper?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.106168725
float32
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 61%|██████    | 22/36 [01:11<00:41,  2.94s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 64%|██████▍   | 23/36 [01:14<00:37,  2.91s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 67%|██████▋   | 24/36 [01:20<00:46,  3.90s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 69%|██████▉   | 25/36 [01:23<00:39,  3.57s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 72%|███████▏  | 26/36 [01:26<00:33,  3.35s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 75%|███████▌  | 27/36 [01:30<00:31,  3.47s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 78%|███████▊  | 28/36 [01:33<00:27,  3.46s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 81%|████████  | 29/36 [01:37<00:24,  3.51s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 83%|████████▎ | 30/36 [01:41<00:21,  3.62s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 86%|████████▌ | 31/36 [01:44<00:17,  3.57s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 89%|████████▉ | 32/36 [01:48<00:14,  3.57s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 92%|█████████▏| 33/36 [01:51<00:10,  3.53s/it]Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-03.md
# 2. 重新點一次view裡面的顯示prefix才能正常顯示

==問題==
根據上文，如何解決protégé中的顯示問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2692792
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-16.md
`mklink "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\make.exe" "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\mingw32-make.exe"`
- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`
- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性
- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要
- [ ] 整理文獻
- [ ] 閱讀清單

==問題==
根據上文，為甚麼系統要使用多執行緒?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.008740316
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-25.md
# 3. 根據chrome extensione官方說明，30秒會自動將service worker關閉，因此採用25秒一次的心跳來解決這個問題[^1]
- 之後如果確認後端不會主動傳訊息給SW，則可以考慮改為http ( 只要修改send函數應該就行了 )

==問題==
根據上文，service worker幾秒後會自動關閉?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.19715488
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-28.md
# 9. 關於chrome-extension中不允許在html中直接呼叫javascript函數
- 因為chrome-extension不允許CSP
- 但好像可以用[這個](https://stackoverflow.com/questions/72186787/chrome-extensions-and-csp)允許特定網站的CSP?

==問題==
根據上文，為什麼chrome-extension不能在html中直接呼叫javascript函數
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.109264515
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-13.md
# 4. 閱讀論文
- 在這篇[^4] 論文中提到，實驗中為了在最小化幻覺和嚴格生成之間取得平衡，將GPT的溫度設為0，llama的溫度設為0.1，但論文中未提及更詳細的理由

==問題==
根據上文，ChatGPT的溫度設為多少最恰當?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.20829745
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-22.md
# 999. 其他
- How can we evaluate the ability of each LLM to generate Cypher?
- tag嵌套的必要性
- markdown的結構化 #靈感
- 例如tab代表有
- 可能要重新考慮nDCG來比對[[Embeddeding|嵌入]]結果
- 可能要檢查 [[Mean Average Precision|MAP]] 的算法是否有誤
- 以前不熟悉的關鍵字會慢慢熟悉，要怎麼應對這種情況? #靈感
[^1]: https://github.com/microsoft/terminal/issues/14018
[^2]: https://stackoverflow.com/questions/32127524/how-to-install-and-use-make-in-windows

==問題==
根據上文，嵌入有可能遇到什麼問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.090603866
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-16.md
# 1. [[Whisper]]
嘗試解決幻覺問題
https://github.com/openai/whisper/discussions/679
加上參數--condition_on_previous_text False  
##  評估方式?
根據不同面向，例如冗字、專有名詞，其他錯誤等  
又加了一堆論文哈哈

==問題==
根據上文，有哪些方法可以解決語音辨識的幻聽問題
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16820273
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

==問題==
根據上文，語音辨識可以有哪些評估的方向
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.071613215
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 3. 關於瀏覽器插件的溝通方式選擇
pipe or websocket
選擇websocket，因為javascript無法操作作業系統層級的pipe
查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe
理論上也確實如此，否則瀏覽器插件的權限很容易太大

==問題==
根據上文，為什麼瀏覽器插件不使用pipe?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2258542
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

==問題==
根據上文，哪些因素可能會影響語音識別？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.26710048
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-30.md
# 3. 將宿舍電腦的 StableDiffusion 虛擬環境中的 [[pytorch]] 更新到pytorch2[^1]
1. 切換到虛擬環境
`.\envs\scripts\activate.bat`
2. 檢查pip路徑
`pip --version`
3. 參考[官網](https://pytorch.org/get-started/locally/)訊息，CUDA11.8
`pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`
4. 結果
```
Installing collected packages: mpmath, sympy, torch, torchvision, torchaudio
Attempting uninstall: torch
Found existing installation: torch 1.13.1+cu117

==問題==
根據上文，我參考了哪個教學將pytorch更新到pytorch2?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.3263341
float32
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 94%|█████████▍| 34/36 [01:55<00:07,  3.50s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

 97%|█████████▋| 35/36 [01:58<00:03,  3.48s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
E:\Research\extension\chrome-extension\modules\utils.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  return pd.concat([df, new_row_df], ignore_index=True)

100%|██████████| 36/36 [02:04<00:00,  4.30s/it]
100%|██████████| 36/36 [02:04<00:00,  3.46s/it]
Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-28.md
# 999. 靈感  
[^1]: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=key1YF/record?r1=16&h1=0
[^2]: https://aws.amazon.com/tw/compare/the-difference-between-grpc-and-rest/

==問題==
根據上文，bibtex和ris差在哪？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.4384315
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-11-23.md
# 2. 研究過程中，除了這個研究的貢獻外，在相關研究中也可以得到很多資訊
可以在筆記中包含，提到這篇研究的研究、該研究中的說明、評價、引用編號等
#靈感

==問題==
根據上文，可以從論文的相關研究中得到什麼？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.44338506
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-04.md
# 5. 土豆挑戰

==問題==
根據上文，土豆挑戰是什麼？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1314348
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-08.md
# 1. 撰寫chrome extension
- 關於popus.js和background.js的溝通
- 遇到錯誤 `Unchecked runtime.lastError: The message port closed before a response was received.`
- 經過正確的使用sendmessage的callback的第三個參數sendResponse完成完整的溝通。
- 準確的說是service-worker，因為在版本三中並沒有background page的存在，而是改為service worker。
- 同上，有很多用法在第二版可以用，但在第三版不能用。

==問題==
根據上文，如何解決The message port closed before a response was received
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.062017523
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-22.md
- 註: daemon關閉時會強制關閉，若有讀寫檔、暫存檔等需要額外處理，例如在主thread中捕捉相關的事件。  
- ChatGPT用模擬ctrl+c的方式實現自訂義複製快捷鍵，我喜歡
- 本來無法模擬ctrl+c，後來發現是因為模擬前沒有放開實體按鍵，使用time.sleep或keyboard.release都能解決這個問題，也不需要管理員權限  
- 讀取當前焦點視窗
- 暫時先考慮windows，不考慮mac和linux，因此使用pywin32  
- [[cypher]] 的參數化查詢無法用於標籤或關係上，因此需要使用python的格式化輸入來處理
`query = f"MATCH (n:{tagName})"`

==問題==
根據上文，哪些python套件能監聽快捷鍵？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2724631
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-16.md
`mklink "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\make.exe" "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\mingw32-make.exe"`
- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`
- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性
- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要
- [ ] 整理文獻
- [ ] 閱讀清單

==問題==
根據上文，除了pyqt外，當時還考慮哪些類似的套件？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.14854458
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-16.md
# 1. 系統
- neo4j
- 根據[官方教學](https://neo4j.com/docs/operations-manual/current/configuration/connectors/) 修改neo4j的監聽ip讓台北電腦測試neo4j chain

==問題==
根據上文，系統中的FastAPI監聽哪個端口？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.28215396
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

==問題==
根據上文，RALM類似什麼概念？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.04661884
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-11.md
# 1. 修改論文
- Multi-Source Data Analysis與Multi-source infomation management system
- 多源資料分析主要注重統合、轉換、除錯並分析資料
- 多源資訊管理主要目的在蒐集與管理資訊

==問題==
根據上文，多源資料分析和管理差在哪？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.06321003
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-18.md
[^10]: https://community.neo4j.com/t/import-individuals-and-relate-to-classes-in-neo4j/24567/2

==問題==
根據上文，在2024/4/17，我看完NEUMAI了嗎？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2960534
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

==問題==
根據上文，在2024/4/17，我做了什麼實驗？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.0678077
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-21.md
# 2. 跑實驗
- google/gemma-2b-it
- 約20分鐘
- google/gemma-2b
- 約20分鐘
- meta-llama/Llama-2-7b-chat-hf
- 約一小時

==問題==
根據上文，在2024/4/17，我實驗過gemma了嗎?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.10619263
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-07.md
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典

==問題==
根據上文，在2024/4/17，我設計完整個架構和所需要的API需求及文件了嗎？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.12266735
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-17.md
# 2. 試用 [[Chat RTX]]
- 38G，好大
- 下載好久，安裝好久，安裝一個多小時吧，包含下載模型的時間
- 吃爆VRAM、反應不快，基本只收英文
- 因為很卡所以沒有繼續測試下去  
[^3]: https://www.volcengine.com/theme/3863827-W-7-1
[^4]: https://www.pythonforbeginners.com/basics/convert-ini-to-yaml-in-python
[^5]: https://docs.privategpt.dev/recipes/choice-of-llm/list-of-ll-ms

==問題==
根據上文，我對ChatRTX的評價是正面還是負面
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.056782953
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-21.md
# 2. 跑實驗
- google/gemma-2b-it
- 約20分鐘
- google/gemma-2b
- 約20分鐘
- meta-llama/Llama-2-7b-chat-hf
- 約一小時

==問題==
根據上文，在2024/4/21，我總共花了幾分鐘跑實驗
請用20個字簡潔回答問題。

None

(server) E:\Research\extension\chrome-extension>[05:39:21]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  0%|          | 0/36 [00:06<?, ?it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 113, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 98, in eval
    update_or_append_result(df, {
  File "E:\Research\extension\chrome-extension\modules\utils.py", line 23, in update_or_append_result
    mask &= (df[key]==value)
             ^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\ops\common.py", line 76, in new_method
    return method(self, other)
           ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\arraylike.py", line 40, in __eq__
    return self._cmp_method(other, operator.eq)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\series.py", line 6110, in _cmp_method
    res_values = ops.comparison_op(lvalues, rvalues, op)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\ops\array_ops.py", line 321, in comparison_op
    raise ValueError(
ValueError: ('Lengths must match to compare', (0,), (1,))
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。


(server) E:\Research\extension\chrome-extension>[05:42:13]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  0%|          | 0/36 [00:06<?, ?it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 113, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 98, in eval
    update_or_append_result(df, {
  File "E:\Research\extension\chrome-extension\modules\utils.py", line 24, in update_or_append_result
    mask &= (df[key]==value)
             ^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\ops\common.py", line 76, in new_method
    return method(self, other)
           ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\arraylike.py", line 40, in __eq__
    return self._cmp_method(other, operator.eq)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\series.py", line 6110, in _cmp_method
    res_values = ops.comparison_op(lvalues, rvalues, op)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\ops\array_ops.py", line 321, in comparison_op
    raise ValueError(
ValueError: ('Lengths must match to compare', (0,), (1,))
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。

Series([], Name: LLM, dtype: object)
Series([], Name: 量化, dtype: object)
Series([], Name: prompt_template, dtype: object)
Series([], Name: 嵌入模型, dtype: object)
Series([], Name: query, dtype: object)
Series([], Name: top_k, dtype: object)
Series([], Name: 檢索方法, dtype: object)

(server) E:\Research\extension\chrome-extension>[05:42:57]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  3%|▎         | 1/36 [00:05<03:29,  5.99s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  6%|▌         | 2/36 [00:09<02:29,  4.40s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  8%|▊         | 3/36 [00:13<02:26,  4.43s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 11%|█         | 4/36 [00:16<02:05,  3.93s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 14%|█▍        | 5/36 [00:19<01:49,  3.54s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 17%|█▋        | 6/36 [00:22<01:35,  3.19s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 19%|█▉        | 7/36 [00:25<01:35,  3.30s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 22%|██▏       | 8/36 [00:29<01:32,  3.29s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 25%|██▌       | 9/36 [00:31<01:24,  3.13s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 28%|██▊       | 10/36 [00:34<01:19,  3.06s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 31%|███       | 11/36 [00:37<01:12,  2.89s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 33%|███▎      | 12/36 [00:40<01:10,  2.94s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 36%|███▌      | 13/36 [00:44<01:16,  3.32s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 39%|███▉      | 14/36 [00:47<01:09,  3.15s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 42%|████▏     | 15/36 [00:49<01:03,  3.02s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 44%|████▍     | 16/36 [00:52<00:59,  2.97s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 47%|████▋     | 17/36 [00:55<00:53,  2.83s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 50%|█████     | 18/36 [00:58<00:53,  2.98s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 53%|█████▎    | 19/36 [01:01<00:50,  2.97s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 56%|█████▌    | 20/36 [01:04<00:46,  2.90s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 58%|█████▊    | 21/36 [01:07<00:44,  2.95s/it]嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.057200395
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-03.md
>In computing, an ontology is then a concrete, formal representation—a convention—on what terms mean within the scope in which they are used (e.g., a given domain). Like all conventions, the usefulness of an ontology depends on how broadly and consistently it is adopted and how detailed it is. Knowledge graphs that use a shared ontology will be more interoperable. Given that ontologies are formal representations, they can further be used to

==問題==
根據上文，Ontology是什麼?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2588572
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-07.md
# 2. 測試[[LLaMA2]]
中文支援不佳，嘗試使用中文微調專案[[Chinese-LLaMA-Alpaca-2]]
及webui專案[[text-generation-webui]]
設定參考[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh)
- 須解決簡體中文的問題

==問題==
根據上文，llama支援中文嗎?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1619676
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

==問題==
根據上文，在mysql中如何將多張表合併?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.32915065
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

==問題==
根據上文，如何將mysql的表匯出?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1116085
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-06.md
# 4. 在引用上實在很不方便，找了一些別的插件
http://ob-plugin.eryajf.net/#/ob-plugin/01.Obsidian%E6%8F%92%E4%BB%B6%E5%91%A8%E5%88%8A%E7%AC%AC%E4%B8%80%E6%9C%9F

==問題==
根據上文，什麼時候安裝了obsidian的引用外掛?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.11549372
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 4. 如何選擇port?
參考[^2] ，選擇沒人佔用的27709  
[^1]: https://stackoverflow.com/questions/42631509/piping-node-js-to-python
[^2]: https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=27709

==問題==
根據上文，怎麼選擇端口的?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.35214102
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-21.md
# 4. 開會
- 冒號問題，如果資訊比較不重要可以刪除
- 或者用減號、全形冒號等
```
▸標籤管理實作
▸PDF抽取方法實驗及整理
▸s2orc-doc2json、 grobid
▸文獻閱讀: Too many tags spoil the metadata: investigating the knowledge management of scientific research with semantic web technologies(2019)
▸其他: 冒號問題
```

==問題==
根據上文，如何解決論文標題中的冒號問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.1906288
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

==問題==
根據上文，哪些因素可能會影響語音識別的準確度?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16114116
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 999. 靈感
- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  
[^1]: https://ithelp.ithome.com.tw/articles/10340284
[^2]: https://github.com/huggingface/text-generation-inference/issues/1201

==問題==
根據上文，如何微調whisper?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.106168725
float32
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 61%|██████    | 22/36 [01:10<00:41,  2.93s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 64%|██████▍   | 23/36 [01:13<00:37,  2.89s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 67%|██████▋   | 24/36 [01:15<00:34,  2.88s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 69%|██████▉   | 25/36 [01:18<00:31,  2.85s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 72%|███████▏  | 26/36 [01:21<00:28,  2.85s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 75%|███████▌  | 27/36 [01:24<00:25,  2.84s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 78%|███████▊  | 28/36 [01:26<00:21,  2.75s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 81%|████████  | 29/36 [01:30<00:21,  3.04s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 83%|████████▎ | 30/36 [01:33<00:18,  3.01s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 86%|████████▌ | 31/36 [01:36<00:14,  2.86s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 89%|████████▉ | 32/36 [01:38<00:11,  2.78s/it]Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-03.md
# 2. 重新點一次view裡面的顯示prefix才能正常顯示

==問題==
根據上文，如何解決protégé中的顯示問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2692792
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-25.md
# 1. PyQt的多執行緒
- 用單獨的thread管理PyQt
- 用threading.event來觸發顯示
- 用global參數來修改內容?

==問題==
根據上文，為甚麼系統要使用多執行緒?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.008740316
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-25.md
# 3. 根據chrome extensione官方說明，30秒會自動將service worker關閉，因此採用25秒一次的心跳來解決這個問題[^1]
- 之後如果確認後端不會主動傳訊息給SW，則可以考慮改為http ( 只要修改send函數應該就行了 )

==問題==
根據上文，service worker幾秒後會自動關閉?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.19715488
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-28.md
# 9. 關於chrome-extension中不允許在html中直接呼叫javascript函數
- 因為chrome-extension不允許CSP
- 但好像可以用[這個](https://stackoverflow.com/questions/72186787/chrome-extensions-and-csp)允許特定網站的CSP?

==問題==
根據上文，為什麼chrome-extension不能在html中直接呼叫javascript函數
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.109264515
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-13.md
# 4. 閱讀論文
- 在這篇[^4] 論文中提到，實驗中為了在最小化幻覺和嚴格生成之間取得平衡，將GPT的溫度設為0，llama的溫度設為0.1，但論文中未提及更詳細的理由

==問題==
根據上文，ChatGPT的溫度設為多少最恰當?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.20829745
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-22.md
# 999. 其他
- How can we evaluate the ability of each LLM to generate Cypher?
- tag嵌套的必要性
- markdown的結構化 #靈感
- 例如tab代表有
- 可能要重新考慮nDCG來比對[[Embeddeding|嵌入]]結果
- 可能要檢查 [[Mean Average Precision|MAP]] 的算法是否有誤
- 以前不熟悉的關鍵字會慢慢熟悉，要怎麼應對這種情況? #靈感
[^1]: https://github.com/microsoft/terminal/issues/14018
[^2]: https://stackoverflow.com/questions/32127524/how-to-install-and-use-make-in-windows

==問題==
根據上文，嵌入有可能遇到什麼問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.090603866
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-16.md
# 1. [[Whisper]]
嘗試解決幻覺問題
https://github.com/openai/whisper/discussions/679
加上參數--condition_on_previous_text False  
##  評估方式?
根據不同面向，例如冗字、專有名詞，其他錯誤等  
又加了一堆論文哈哈

==問題==
根據上文，有哪些方法可以解決語音辨識的幻聽問題
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16820273
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

==問題==
根據上文，語音辨識可以有哪些評估的方向
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.071613215
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 3. 關於瀏覽器插件的溝通方式選擇
pipe or websocket
選擇websocket，因為javascript無法操作作業系統層級的pipe
查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe
理論上也確實如此，否則瀏覽器插件的權限很容易太大

==問題==
根據上文，為什麼瀏覽器插件不使用pipe?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2258542
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

==問題==
根據上文，哪些因素可能會影響語音識別？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.26710048
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-30.md
# 3. 將宿舍電腦的 StableDiffusion 虛擬環境中的 [[pytorch]] 更新到pytorch2[^1]
1. 切換到虛擬環境
`.\envs\scripts\activate.bat`
2. 檢查pip路徑
`pip --version`
3. 參考[官網](https://pytorch.org/get-started/locally/)訊息，CUDA11.8
`pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`
4. 結果
```
Installing collected packages: mpmath, sympy, torch, torchvision, torchaudio
Attempting uninstall: torch
Found existing installation: torch 1.13.1+cu117

==問題==
根據上文，我參考了哪個教學將pytorch更新到pytorch2?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.3263341
float32
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 92%|█████████▏| 33/36 [01:41<00:08,  2.70s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 94%|█████████▍| 34/36 [01:43<00:05,  2.65s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 97%|█████████▋| 35/36 [01:46<00:02,  2.60s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

100%|██████████| 36/36 [01:49<00:00,  2.67s/it]
100%|██████████| 36/36 [01:49<00:00,  3.03s/it]
Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-11-15.md
# 1. 考慮和 [[EndNote]] 連動的可能性
- [[websocket]] 攔截
- [[RIS]] 等引用文件
- 文獻清單
- 其實 [[Bibtex]] 應該更適合作為相容性最好的引用格式而非[[RIS]]

==問題==
根據上文，bibtex和ris差在哪？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.4384315
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-11-23.md
# 2. 研究過程中，除了這個研究的貢獻外，在相關研究中也可以得到很多資訊
可以在筆記中包含，提到這篇研究的研究、該研究中的說明、評價、引用編號等
#靈感

==問題==
根據上文，可以從論文的相關研究中得到什麼？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.44338506
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-04.md
# 5. 土豆挑戰

==問題==
根據上文，土豆挑戰是什麼？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1314348
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-08.md
# 1. 撰寫chrome extension
- 關於popus.js和background.js的溝通
- 遇到錯誤 `Unchecked runtime.lastError: The message port closed before a response was received.`
- 經過正確的使用sendmessage的callback的第三個參數sendResponse完成完整的溝通。
- 準確的說是service-worker，因為在版本三中並沒有background page的存在，而是改為service worker。
- 同上，有很多用法在第二版可以用，但在第三版不能用。

==問題==
根據上文，如何解決The message port closed before a response was received
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.062017523
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-22.md
- 註: daemon關閉時會強制關閉，若有讀寫檔、暫存檔等需要額外處理，例如在主thread中捕捉相關的事件。  
- ChatGPT用模擬ctrl+c的方式實現自訂義複製快捷鍵，我喜歡
- 本來無法模擬ctrl+c，後來發現是因為模擬前沒有放開實體按鍵，使用time.sleep或keyboard.release都能解決這個問題，也不需要管理員權限  
- 讀取當前焦點視窗
- 暫時先考慮windows，不考慮mac和linux，因此使用pywin32  
- [[cypher]] 的參數化查詢無法用於標籤或關係上，因此需要使用python的格式化輸入來處理
`query = f"MATCH (n:{tagName})"`

==問題==
根據上文，哪些python套件能監聽快捷鍵？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2724631
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-16.md
`mklink "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\make.exe" "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\mingw32-make.exe"`
- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`
- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性
- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要
- [ ] 整理文獻
- [ ] 閱讀清單

==問題==
根據上文，除了pyqt外，當時還考慮哪些類似的套件？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.14854458
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-16.md
# 999. 其他
- 根據FastAPI的文檔，建議使用Union來取代Optional功能，但範例中有點錯誤
- 建議避免使用 `name: Optional[str]`，因為實際上name並不是可選的而是必選的
- 就算使用 `def say_hi(name: str | None)` 也不代表不需要參數，必須要設定初始值，如 `def say_hi(name: str | None = None)`  
[^1]: https://stackoverflow.com/questions/63872924/how-can-i-send-an-http-request-from-my-fastapi-app-to-another-site-api
[^2]: https://scrapfly.io/blog/httpx-vs-requests-vs-aiohttp/

==問題==
根據上文，系統中的FastAPI監聽哪個端口？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.28215396
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

==問題==
根據上文，RALM類似什麼概念？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.04661884
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-11.md
# 1. 修改論文
- Multi-Source Data Analysis與Multi-source infomation management system
- 多源資料分析主要注重統合、轉換、除錯並分析資料
- 多源資訊管理主要目的在蒐集與管理資訊

==問題==
根據上文，多源資料分析和管理差在哪？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.06321003
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-18.md
[^10]: https://community.neo4j.com/t/import-individuals-and-relate-to-classes-in-neo4j/24567/2

==問題==
根據上文，在2024/4/17，我看完NEUMAI了嗎？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2960534
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

==問題==
根據上文，在2024/4/17，我做了什麼實驗？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.0678077
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-21.md
# 2. 跑實驗
- google/gemma-2b-it
- 約20分鐘
- google/gemma-2b
- 約20分鐘
- meta-llama/Llama-2-7b-chat-hf
- 約一小時

==問題==
根據上文，在2024/4/17，我實驗過gemma了嗎?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.10619263
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-07.md
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典

==問題==
根據上文，在2024/4/17，我設計完整個架構和所需要的API需求及文件了嗎？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.12266735
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-17.md
# 2. 試用 [[Chat RTX]]
- 38G，好大
- 下載好久，安裝好久，安裝一個多小時吧，包含下載模型的時間
- 吃爆VRAM、反應不快，基本只收英文
- 因為很卡所以沒有繼續測試下去  
[^3]: https://www.volcengine.com/theme/3863827-W-7-1
[^4]: https://www.pythonforbeginners.com/basics/convert-ini-to-yaml-in-python
[^5]: https://docs.privategpt.dev/recipes/choice-of-llm/list-of-ll-ms

==問題==
根據上文，我對ChatRTX的評價是正面還是負面
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.056782953
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-21.md
# 2. 跑實驗
- google/gemma-2b-it
- 約20分鐘
- google/gemma-2b
- 約20分鐘
- meta-llama/Llama-2-7b-chat-hf
- 約一小時

==問題==
根據上文，在2024/4/21，我總共花了幾分鐘跑實驗
請用20個字簡潔回答問題。

None

(server) E:\Research\extension\chrome-extension>[05:45:37]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]
  0%|          | 0/36 [00:03<?, ?it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 114, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 97, in eval
    result = self.query(query)
             ^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 26, in query
    answer_text = self.generate_answer(query, context, model_name=self.config["llm_model"])
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 75, in generate_answer
    if self.llm == None:
       ^^^^^^^^
AttributeError: 'rag' object has no attribute 'llm'
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。


(server) E:\Research\extension\chrome-extension>[05:46:01]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  3%|▎         | 1/36 [00:06<03:34,  6.12s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  3%|▎         | 1/36 [00:09<05:31,  9.46s/it]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 115, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 100, in eval
    df = update_or_append_result(df, {
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\utils.py", line 23, in update_or_append_result
    mask &= (df[key]==value)
             ^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\ops\common.py", line 76, in new_method
    return method(self, other)
           ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\arraylike.py", line 40, in __eq__
    return self._cmp_method(other, operator.eq)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\series.py", line 6110, in _cmp_method
    res_values = ops.comparison_op(lvalues, rvalues, op)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\ops\array_ops.py", line 321, in comparison_op
    raise ValueError(
ValueError: ('Lengths must match to compare', (2,), (1,))
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.057200395
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-03.md
>In computing, an ontology is then a concrete, formal representation—a convention—on what terms mean within the scope in which they are used (e.g., a given domain). Like all conventions, the usefulness of an ontology depends on how broadly and consistently it is adopted and how detailed it is. Knowledge graphs that use a shared ontology will be more interoperable. Given that ontologies are formal representations, they can further be used to

==問題==
根據上文，Ontology是什麼?
請用20個字簡潔回答問題。


(server) E:\Research\extension\chrome-extension>[05:47:13]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  3%|▎         | 1/36 [00:05<03:21,  5.77s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  3%|▎         | 1/36 [00:08<05:04,  8.71s/it]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 116, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 100, in eval
    df = update_or_append_result(df, {
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\utils.py", line 23, in update_or_append_result
    mask &= (df[key]==value)
             ^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\ops\common.py", line 76, in new_method
    return method(self, other)
           ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\arraylike.py", line 40, in __eq__
    return self._cmp_method(other, operator.eq)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\series.py", line 6110, in _cmp_method
    res_values = ops.comparison_op(lvalues, rvalues, op)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\ops\array_ops.py", line 321, in comparison_op
    raise ValueError(
ValueError: ('Lengths must match to compare', (2,), (1,))
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.057200395
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-03.md
>In computing, an ontology is then a concrete, formal representation—a convention—on what terms mean within the scope in which they are used (e.g., a given domain). Like all conventions, the usefulness of an ontology depends on how broadly and consistently it is adopted and how detailed it is. Knowledge graphs that use a shared ontology will be more interoperable. Given that ontologies are formal representations, they can further be used to

==問題==
根據上文，Ontology是什麼?
請用20個字簡潔回答問題。


(server) E:\Research\extension\chrome-extension>[05:48:01]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  3%|▎         | 1/36 [00:05<03:19,  5.71s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  3%|▎         | 1/36 [00:08<05:03,  8.67s/it]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 116, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 100, in eval
    df = update_or_append_result(df, {
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\utils.py", line 23, in update_or_append_result
    mask &= (df[key]==value)
             ^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\ops\common.py", line 76, in new_method
    return method(self, other)
           ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\arraylike.py", line 40, in __eq__
    return self._cmp_method(other, operator.eq)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\series.py", line 6110, in _cmp_method
    res_values = ops.comparison_op(lvalues, rvalues, op)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\ops\array_ops.py", line 321, in comparison_op
    raise ValueError(
ValueError: ('Lengths must match to compare', (2,), (1,))
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.057200395
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-03.md
>In computing, an ontology is then a concrete, formal representation—a convention—on what terms mean within the scope in which they are used (e.g., a given domain). Like all conventions, the usefulness of an ontology depends on how broadly and consistently it is adopted and how detailed it is. Knowledge graphs that use a shared ontology will be more interoperable. Given that ontologies are formal representations, they can further be used to

==問題==
根據上文，Ontology是什麼?
請用20個字簡潔回答問題。


(server) E:\Research\extension\chrome-extension>[05:48:54]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  0%|          | 0/36 [00:05<?, ?it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 116, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 100, in eval
    df = update_or_append_result(df, {
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\utils.py", line 26, in update_or_append_result
    mask &= (df[key]==value)
             ^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\ops\common.py", line 76, in new_method
    return method(self, other)
           ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\arraylike.py", line 40, in __eq__
    return self._cmp_method(other, operator.eq)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\series.py", line 6110, in _cmp_method
    res_values = ops.comparison_op(lvalues, rvalues, op)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\pandas\core\ops\array_ops.py", line 321, in comparison_op
    raise ValueError(
ValueError: ('Lengths must match to compare', (2,), (1,))
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。

0    True
1    True
dtype: bool
======
0    MediaTek-Research/Breeze-7B-Instruct-v0_1
1    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0    True
1    True
dtype: bool
======
0    eetq
1    eetq
Name: 量化, dtype: object
0    True
1    True
dtype: bool
======
0    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0    True
1    True
dtype: bool
======
0    infgrad/puff-base-v1
1    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0    True
1    True
dtype: bool
======
0    如何設定Obsidian同步?
1    如何設定Obsidian同步?
Name: query, dtype: object
0    True
1    True
dtype: bool
======
0    1
1    1
Name: top_k, dtype: object
0    False
1    False
dtype: bool
======
0    ['chroma_similarity']
1    ['chroma_similarity']
Name: 檢索方法, dtype: object

(server) E:\Research\extension\chrome-extension>[05:50:47]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  3%|▎         | 1/36 [00:06<03:54,  6.71s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  6%|▌         | 2/36 [00:10<02:54,  5.13s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  8%|▊         | 3/36 [00:14<02:33,  4.67s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 11%|█         | 4/36 [00:19<02:23,  4.47s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 14%|█▍        | 5/36 [00:22<02:12,  4.28s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。

0    True
1    True
dtype: bool
======
0    MediaTek-Research/Breeze-7B-Instruct-v0_1
1    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0    True
1    True
dtype: bool
======
0    eetq
1    eetq
Name: 量化, dtype: object
0    True
1    True
dtype: bool
======
0    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0    True
1    True
dtype: bool
======
0    infgrad/puff-base-v1
1    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0    True
1    True
dtype: bool
======
0    如何設定Obsidian同步?
1    如何設定Obsidian同步?
Name: query, dtype: object
0    True
1    True
dtype: bool
======
0    1
1    1
Name: top_k, dtype: object
0    False
1    False
dtype: bool
======
0    ['chroma_similarity']
1    ['chroma_similarity']
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.057200395
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-03.md
>In computing, an ontology is then a concrete, formal representation—a convention—on what terms mean within the scope in which they are used (e.g., a given domain). Like all conventions, the usefulness of an ontology depends on how broadly and consistently it is adopted and how detailed it is. Knowledge graphs that use a shared ontology will be more interoperable. Given that ontologies are formal representations, they can further be used to

==問題==
根據上文，Ontology是什麼?
請用20個字簡潔回答問題。

0    True
1    True
2    True
dtype: bool
======
0    MediaTek-Research/Breeze-7B-Instruct-v0_1
1    MediaTek-Research/Breeze-7B-Instruct-v0_1
2    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0    True
1    True
2    True
dtype: bool
======
0    eetq
1    eetq
2    eetq
Name: 量化, dtype: object
0    True
1    True
2    True
dtype: bool
======
0    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0    True
1    True
2    True
dtype: bool
======
0    infgrad/puff-base-v1
1    infgrad/puff-base-v1
2    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0    True
1    True
2    True
dtype: bool
======
0    如何設定Obsidian同步?
1    如何設定Obsidian同步?
2    如何設定Obsidian同步?
Name: query, dtype: object
0    False
1    False
2    False
dtype: bool
======
0    1
1    1
2    1
Name: top_k, dtype: object
0    False
1    False
2    False
dtype: bool
======
0    ['chroma_similarity']
1    ['chroma_similarity']
2        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2588572
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-07.md
# 2. 測試[[LLaMA2]]
中文支援不佳，嘗試使用中文微調專案[[Chinese-LLaMA-Alpaca-2]]
及webui專案[[text-generation-webui]]
設定參考[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh)
- 須解決簡體中文的問題

==問題==
根據上文，llama支援中文嗎?
請用20個字簡潔回答問題。

0    True
1    True
2    True
3    True
dtype: bool
======
0    MediaTek-Research/Breeze-7B-Instruct-v0_1
1    MediaTek-Research/Breeze-7B-Instruct-v0_1
2    MediaTek-Research/Breeze-7B-Instruct-v0_1
3    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0    True
1    True
2    True
3    True
dtype: bool
======
0    eetq
1    eetq
2    eetq
3    eetq
Name: 量化, dtype: object
0    True
1    True
2    True
3    True
dtype: bool
======
0    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0    True
1    True
2    True
3    True
dtype: bool
======
0    infgrad/puff-base-v1
1    infgrad/puff-base-v1
2    infgrad/puff-base-v1
3    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0    True
1    True
2    True
3    True
dtype: bool
======
0    如何設定Obsidian同步?
1    如何設定Obsidian同步?
2    如何設定Obsidian同步?
3       Ontology是什麼?
Name: query, dtype: object
0    False
1    False
2    False
3    False
dtype: bool
======
0    1
1    1
2    1
3    1
Name: top_k, dtype: object
0    False
1    False
2    False
3    False
dtype: bool
======
0    ['chroma_similarity']
1    ['chroma_similarity']
2        chroma_similarity
3        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1619676
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

==問題==
根據上文，在mysql中如何將多張表合併?
請用20個字簡潔回答問題。

0    True
1    True
2    True
3    True
4    True
dtype: bool
======

 17%|█▋        | 6/36 [00:26<02:01,  4.06s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 19%|█▉        | 7/36 [00:31<02:02,  4.24s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0    MediaTek-Research/Breeze-7B-Instruct-v0_1
1    MediaTek-Research/Breeze-7B-Instruct-v0_1
2    MediaTek-Research/Breeze-7B-Instruct-v0_1
3    MediaTek-Research/Breeze-7B-Instruct-v0_1
4    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0    True
1    True
2    True
3    True
4    True
dtype: bool
======
0    eetq
1    eetq
2    eetq
3    eetq
4    eetq
Name: 量化, dtype: object
0    True
1    True
2    True
3    True
4    True
dtype: bool
======
0    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0    True
1    True
2    True
3    True
4    True
dtype: bool
======
0    infgrad/puff-base-v1
1    infgrad/puff-base-v1
2    infgrad/puff-base-v1
3    infgrad/puff-base-v1
4    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0    True
1    True
2    True
3    True
4    True
dtype: bool
======
0    如何設定Obsidian同步?
1    如何設定Obsidian同步?
2    如何設定Obsidian同步?
3       Ontology是什麼?
4        llama支援中文嗎?
Name: query, dtype: object
0    False
1    False
2    False
3    False
4    False
dtype: bool
======
0    1
1    1
2    1
3    1
4    1
Name: top_k, dtype: object
0    False
1    False
2    False
3    False
4    False
dtype: bool
======
0    ['chroma_similarity']
1    ['chroma_similarity']
2        chroma_similarity
3        chroma_similarity
4        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.32915065
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

==問題==
根據上文，如何將mysql的表匯出?
請用20個字簡潔回答問題。

0    True
1    True
2    True
3    True
4    True
5    True
dtype: bool
======
0    MediaTek-Research/Breeze-7B-Instruct-v0_1
1    MediaTek-Research/Breeze-7B-Instruct-v0_1
2    MediaTek-Research/Breeze-7B-Instruct-v0_1
3    MediaTek-Research/Breeze-7B-Instruct-v0_1
4    MediaTek-Research/Breeze-7B-Instruct-v0_1
5    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
dtype: bool
======
0    eetq
1    eetq
2    eetq
3    eetq
4    eetq
5    eetq
Name: 量化, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
dtype: bool
======
0    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
dtype: bool
======
0    infgrad/puff-base-v1
1    infgrad/puff-base-v1
2    infgrad/puff-base-v1
3    infgrad/puff-base-v1
4    infgrad/puff-base-v1
5    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
dtype: bool
======
0     如何設定Obsidian同步?
1     如何設定Obsidian同步?
2     如何設定Obsidian同步?
3        Ontology是什麼?
4         llama支援中文嗎?
5    在mysql中如何將多張表合併?
Name: query, dtype: object
0    False
1    False
2    False
3    False
4    False
5    False
dtype: bool
======
0    1
1    1
2    1
3    1
4    1
5    1
Name: top_k, dtype: object
0    False
1    False
2    False
3    False
4    False
5    False
dtype: bool
======
0    ['chroma_similarity']
1    ['chroma_similarity']
2        chroma_similarity
3        chroma_similarity
4        chroma_similarity
5        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1116085
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-06.md
# 4. 在引用上實在很不方便，找了一些別的插件
http://ob-plugin.eryajf.net/#/ob-plugin/01.Obsidian%E6%8F%92%E4%BB%B6%E5%91%A8%E5%88%8A%E7%AC%AC%E4%B8%80%E6%9C%9F

==問題==
根據上文，什麼時候安裝了obsidian的引用外掛?
請用20個字簡潔回答問題。

0    True
1    True
2    True
3    True
4    True
5    True
6    True
dtype: bool
======
0    MediaTek-Research/Breeze-7B-Instruct-v0_1
1    MediaTek-Research/Breeze-7B-Instruct-v0_1
2    MediaTek-Research/Breeze-7B-Instruct-v0_1
3    MediaTek-Research/Breeze-7B-Instruct-v0_1
4    MediaTek-Research/Breeze-7B-Instruct-v0_1
5    MediaTek-Research/Breeze-7B-Instruct-v0_1
6    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
6    True
dtype: bool
======
0    eetq
1    eetq
2    eetq
3    eetq
4    eetq
5    eetq
6    eetq
Name: 量化, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
6    True
dtype: bool
======
0    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
6    True
dtype: bool
======

 22%|██▏       | 8/36 [00:37<02:21,  5.05s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 25%|██▌       | 9/36 [00:41<02:06,  4.68s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0    infgrad/puff-base-v1
1    infgrad/puff-base-v1
2    infgrad/puff-base-v1
3    infgrad/puff-base-v1
4    infgrad/puff-base-v1
5    infgrad/puff-base-v1
6    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
6    True
dtype: bool
======
0     如何設定Obsidian同步?
1     如何設定Obsidian同步?
2     如何設定Obsidian同步?
3        Ontology是什麼?
4         llama支援中文嗎?
5    在mysql中如何將多張表合併?
6       如何將mysql的表匯出?
Name: query, dtype: object
0    False
1    False
2    False
3    False
4    False
5    False
6    False
dtype: bool
======
0    1
1    1
2    1
3    1
4    1
5    1
6    1
Name: top_k, dtype: object
0    False
1    False
2    False
3    False
4    False
5    False
6    False
dtype: bool
======
0    ['chroma_similarity']
1    ['chroma_similarity']
2        chroma_similarity
3        chroma_similarity
4        chroma_similarity
5        chroma_similarity
6        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.11549372
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 4. 如何選擇port?
參考[^2] ，選擇沒人佔用的27709  
[^1]: https://stackoverflow.com/questions/42631509/piping-node-js-to-python
[^2]: https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=27709

==問題==
根據上文，怎麼選擇端口的?
請用20個字簡潔回答問題。

0    True
1    True
2    True
3    True
4    True
5    True
6    True
7    True
dtype: bool
======
0    MediaTek-Research/Breeze-7B-Instruct-v0_1
1    MediaTek-Research/Breeze-7B-Instruct-v0_1
2    MediaTek-Research/Breeze-7B-Instruct-v0_1
3    MediaTek-Research/Breeze-7B-Instruct-v0_1
4    MediaTek-Research/Breeze-7B-Instruct-v0_1
5    MediaTek-Research/Breeze-7B-Instruct-v0_1
6    MediaTek-Research/Breeze-7B-Instruct-v0_1
7    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
6    True
7    True
dtype: bool
======
0    eetq
1    eetq
2    eetq
3    eetq
4    eetq
5    eetq
6    eetq
7    eetq
Name: 量化, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
6    True
7    True
dtype: bool
======
0    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
6    True
7    True
dtype: bool
======
0    infgrad/puff-base-v1
1    infgrad/puff-base-v1
2    infgrad/puff-base-v1
3    infgrad/puff-base-v1
4    infgrad/puff-base-v1
5    infgrad/puff-base-v1
6    infgrad/puff-base-v1
7    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
6    True
7    True
dtype: bool
======
0          如何設定Obsidian同步?
1          如何設定Obsidian同步?
2          如何設定Obsidian同步?
3             Ontology是什麼?
4              llama支援中文嗎?
5         在mysql中如何將多張表合併?
6            如何將mysql的表匯出?
7    什麼時候安裝了obsidian的引用外掛?
Name: query, dtype: object
0    False
1    False
2    False
3    False
4    False
5    False
6    False
7    False
dtype: bool
======
0    1
1    1
2    1
3    1
4    1
5    1
6    1
7    1
Name: top_k, dtype: object
0    False
1    False
2    False
3    False
4    False
5    False
6    False
7    False
dtype: bool
======
0    ['chroma_similarity']
1    ['chroma_similarity']
2        chroma_similarity
3        chroma_similarity
4        chroma_similarity
5        chroma_similarity
6        chroma_similarity
7        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.35214102
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-21.md
# 4. 開會
- 冒號問題，如果資訊比較不重要可以刪除
- 或者用減號、全形冒號等
```
▸標籤管理實作
▸PDF抽取方法實驗及整理
▸s2orc-doc2json、 grobid
▸文獻閱讀: Too many tags spoil the metadata: investigating the knowledge management of scientific research with semantic web technologies(2019)
▸其他: 冒號問題
```

==問題==
根據上文，如何解決論文標題中的冒號問題?
請用20個字簡潔回答問題。

0    True
1    True
2    True
3    True
4    True
5    True
6    True
7    True
8    True
dtype: bool
======
0    MediaTek-Research/Breeze-7B-Instruct-v0_1
1    MediaTek-Research/Breeze-7B-Instruct-v0_1
2    MediaTek-Research/Breeze-7B-Instruct-v0_1
3    MediaTek-Research/Breeze-7B-Instruct-v0_1
4    MediaTek-Research/Breeze-7B-Instruct-v0_1
5    MediaTek-Research/Breeze-7B-Instruct-v0_1
6    MediaTek-Research/Breeze-7B-Instruct-v0_1
7    MediaTek-Research/Breeze-7B-Instruct-v0_1
8    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
6    True
7    True
8    True
dtype: bool
======
0    eetq
1    eetq
2    eetq
3    eetq
4    eetq
5    eetq
6    eetq
7    eetq
8    eetq
Name: 量化, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
6    True
7    True
8    True
dtype: bool
======
0    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object

 28%|██▊       | 10/36 [00:45<01:56,  4.48s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0    True
1    True
2    True
3    True
4    True
5    True
6    True
7    True
8    True
dtype: bool
======
0    infgrad/puff-base-v1
1    infgrad/puff-base-v1
2    infgrad/puff-base-v1
3    infgrad/puff-base-v1
4    infgrad/puff-base-v1
5    infgrad/puff-base-v1
6    infgrad/puff-base-v1
7    infgrad/puff-base-v1
8    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
6    True
7    True
8    True
dtype: bool
======
0          如何設定Obsidian同步?
1          如何設定Obsidian同步?
2          如何設定Obsidian同步?
3             Ontology是什麼?
4              llama支援中文嗎?
5         在mysql中如何將多張表合併?
6            如何將mysql的表匯出?
7    什麼時候安裝了obsidian的引用外掛?
8                 怎麼選擇端口的?
Name: query, dtype: object
0    False
1    False
2    False
3    False
4    False
5    False
6    False
7    False
8    False
dtype: bool
======
0    1
1    1
2    1
3    1
4    1
5    1
6    1
7    1
8    1
Name: top_k, dtype: object
0    False
1    False
2    False
3    False
4    False
5    False
6    False
7    False
8    False
dtype: bool
======
0    ['chroma_similarity']
1    ['chroma_similarity']
2        chroma_similarity
3        chroma_similarity
4        chroma_similarity
5        chroma_similarity
6        chroma_similarity
7        chroma_similarity
8        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.1906288
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

==問題==
根據上文，哪些因素可能會影響語音識別的準確度?
請用20個字簡潔回答問題。

0    True
1    True
2    True
3    True
4    True
5    True
6    True
7    True
8    True
9    True
dtype: bool
======
0    MediaTek-Research/Breeze-7B-Instruct-v0_1
1    MediaTek-Research/Breeze-7B-Instruct-v0_1
2    MediaTek-Research/Breeze-7B-Instruct-v0_1
3    MediaTek-Research/Breeze-7B-Instruct-v0_1
4    MediaTek-Research/Breeze-7B-Instruct-v0_1
5    MediaTek-Research/Breeze-7B-Instruct-v0_1
6    MediaTek-Research/Breeze-7B-Instruct-v0_1
7    MediaTek-Research/Breeze-7B-Instruct-v0_1
8    MediaTek-Research/Breeze-7B-Instruct-v0_1
9    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
6    True
7    True
8    True
9    True
dtype: bool
======
0    eetq
1    eetq
2    eetq
3    eetq
4    eetq
5    eetq
6    eetq
7    eetq
8    eetq
9    eetq
Name: 量化, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
6    True
7    True
8    True
9    True
dtype: bool
======
0    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
6    True
7    True
8    True
9    True
dtype: bool
======
0    infgrad/puff-base-v1
1    infgrad/puff-base-v1
2    infgrad/puff-base-v1
3    infgrad/puff-base-v1
4    infgrad/puff-base-v1
5    infgrad/puff-base-v1
6    infgrad/puff-base-v1
7    infgrad/puff-base-v1
8    infgrad/puff-base-v1
9    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0    True
1    True
2    True
3    True
4    True
5    True
6    True
7    True
8    True
9    True
dtype: bool
======
0          如何設定Obsidian同步?
1          如何設定Obsidian同步?
2          如何設定Obsidian同步?
3             Ontology是什麼?
4              llama支援中文嗎?
5         在mysql中如何將多張表合併?
6            如何將mysql的表匯出?
7    什麼時候安裝了obsidian的引用外掛?
8                 怎麼選擇端口的?
9          如何解決論文標題中的冒號問題?
Name: query, dtype: object
0    False
1    False
2    False
3    False
4    False
5    False
6    False
7    False
8    False
9    False
dtype: bool
======
0    1
1    1
2    1
3    1
4    1
5    1
6    1
7    1
8    1
9    1
Name: top_k, dtype: object
0    False
1    False
2    False
3    False
4    False
5    False
6    False
7    False
8    False
9    False
dtype: bool
======
0    ['chroma_similarity']
1    ['chroma_similarity']
2        chroma_similarity
3        chroma_similarity
4        chroma_similarity
5        chroma_similarity
6        chroma_similarity
7        chroma_similarity
8        chroma_similarity
9        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16114116
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 999. 靈感
- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  
[^1]: https://ithelp.ithome.com.tw/articles/10340284
[^2]: https://github.com/huggingface/text-generation-inference/issues/1201

==問題==
根據上文，如何微調whisper?
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
dtype: bool
======

 31%|███       | 11/36 [00:49<01:45,  4.21s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 33%|███▎      | 12/36 [00:53<01:38,  4.11s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
dtype: bool
======
0           如何設定Obsidian同步?
1           如何設定Obsidian同步?
2           如何設定Obsidian同步?
3              Ontology是什麼?
4               llama支援中文嗎?
5          在mysql中如何將多張表合併?
6             如何將mysql的表匯出?
7     什麼時候安裝了obsidian的引用外掛?
8                  怎麼選擇端口的?
9           如何解決論文標題中的冒號問題?
10       哪些因素可能會影響語音識別的準確度?
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.106168725
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-03.md
# 2. 重新點一次view裡面的顯示prefix才能正常顯示

==問題==
根據上文，如何解決protégé中的顯示問題?
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
dtype: bool
======
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
dtype: bool
======
0           如何設定Obsidian同步?
1           如何設定Obsidian同步?
2           如何設定Obsidian同步?
3              Ontology是什麼?
4               llama支援中文嗎?
5          在mysql中如何將多張表合併?
6             如何將mysql的表匯出?
7     什麼時候安裝了obsidian的引用外掛?
8                  怎麼選擇端口的?
9           如何解決論文標題中的冒號問題?
10       哪些因素可能會影響語音識別的準確度?
11             如何微調whisper?
Name: query, dtype: object

 36%|███▌      | 13/36 [00:57<01:31,  3.99s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2692792
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-16.md
`mklink "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\make.exe" "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\mingw32-make.exe"`
- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`
- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性
- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要
- [ ] 整理文獻
- [ ] 閱讀清單

==問題==
根據上文，為甚麼系統要使用多執行緒?
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
dtype: bool
======
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
dtype: bool
======
0           如何設定Obsidian同步?
1           如何設定Obsidian同步?
2           如何設定Obsidian同步?
3              Ontology是什麼?
4               llama支援中文嗎?
5          在mysql中如何將多張表合併?
6             如何將mysql的表匯出?
7     什麼時候安裝了obsidian的引用外掛?
8                  怎麼選擇端口的?
9           如何解決論文標題中的冒號問題?
10       哪些因素可能會影響語音識別的準確度?
11             如何微調whisper?
12       如何解決protégé中的顯示問題?
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.008740316
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-25.md
# 3. 根據chrome extensione官方說明，30秒會自動將service worker關閉，因此採用25秒一次的心跳來解決這個問題[^1]
- 之後如果確認後端不會主動傳訊息給SW，則可以考慮改為http ( 只要修改send函數應該就行了 )

==問題==
根據上文，service worker幾秒後會自動關閉?
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
dtype: bool
======

 39%|███▉      | 14/36 [01:01<01:33,  4.23s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
dtype: bool
======
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
dtype: bool
======
0           如何設定Obsidian同步?
1           如何設定Obsidian同步?
2           如何設定Obsidian同步?
3              Ontology是什麼?
4               llama支援中文嗎?
5          在mysql中如何將多張表合併?
6             如何將mysql的表匯出?
7     什麼時候安裝了obsidian的引用外掛?
8                  怎麼選擇端口的?
9           如何解決論文標題中的冒號問題?
10       哪些因素可能會影響語音識別的準確度?
11             如何微調whisper?
12       如何解決protégé中的顯示問題?
13            為甚麼系統要使用多執行緒?
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.19715488
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-28.md
# 9. 關於chrome-extension中不允許在html中直接呼叫javascript函數
- 因為chrome-extension不允許CSP
- 但好像可以用[這個](https://stackoverflow.com/questions/72186787/chrome-extensions-and-csp)允許特定網站的CSP?

==問題==
根據上文，為什麼chrome-extension不能在html中直接呼叫javascript函數
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
dtype: bool
======

 42%|████▏     | 15/36 [01:05<01:25,  4.06s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
dtype: bool
======
0             如何設定Obsidian同步?
1             如何設定Obsidian同步?
2             如何設定Obsidian同步?
3                Ontology是什麼?
4                 llama支援中文嗎?
5            在mysql中如何將多張表合併?
6               如何將mysql的表匯出?
7       什麼時候安裝了obsidian的引用外掛?
8                    怎麼選擇端口的?
9             如何解決論文標題中的冒號問題?
10         哪些因素可能會影響語音識別的準確度?
11               如何微調whisper?
12         如何解決protégé中的顯示問題?
13              為甚麼系統要使用多執行緒?
14    service worker幾秒後會自動關閉?
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.109264515
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-13.md
# 4. 閱讀論文
- 在這篇[^4] 論文中提到，實驗中為了在最小化幻覺和嚴格生成之間取得平衡，將GPT的溫度設為0，llama的溫度設為0.1，但論文中未提及更詳細的理由

==問題==
根據上文，ChatGPT的溫度設為多少最恰當?
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
dtype: bool
======

 44%|████▍     | 16/36 [01:09<01:20,  4.03s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
dtype: bool
======
0                                 如何設定Obsidian同步?
1                                 如何設定Obsidian同步?
2                                 如何設定Obsidian同步?
3                                    Ontology是什麼?
4                                     llama支援中文嗎?
5                                在mysql中如何將多張表合併?
6                                   如何將mysql的表匯出?
7                           什麼時候安裝了obsidian的引用外掛?
8                                        怎麼選擇端口的?
9                                 如何解決論文標題中的冒號問題?
10                             哪些因素可能會影響語音識別的準確度?
11                                   如何微調whisper?
12                             如何解決protégé中的顯示問題?
13                                  為甚麼系統要使用多執行緒?
14                        service worker幾秒後會自動關閉?
15    為什麼chrome-extension不能在html中直接呼叫javascript函數
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.20829745
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-22.md
# 999. 其他
- How can we evaluate the ability of each LLM to generate Cypher?
- tag嵌套的必要性
- markdown的結構化 #靈感
- 例如tab代表有
- 可能要重新考慮nDCG來比對[[Embeddeding|嵌入]]結果
- 可能要檢查 [[Mean Average Precision|MAP]] 的算法是否有誤
- 以前不熟悉的關鍵字會慢慢熟悉，要怎麼應對這種情況? #靈感
[^1]: https://github.com/microsoft/terminal/issues/14018
[^2]: https://stackoverflow.com/questions/32127524/how-to-install-and-use-make-in-windows

==問題==
根據上文，嵌入有可能遇到什麼問題?
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
dtype: bool
======

 47%|████▋     | 17/36 [01:13<01:14,  3.91s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
dtype: bool
======
0                                 如何設定Obsidian同步?
1                                 如何設定Obsidian同步?
2                                 如何設定Obsidian同步?
3                                    Ontology是什麼?
4                                     llama支援中文嗎?
5                                在mysql中如何將多張表合併?
6                                   如何將mysql的表匯出?
7                           什麼時候安裝了obsidian的引用外掛?
8                                        怎麼選擇端口的?
9                                 如何解決論文標題中的冒號問題?
10                             哪些因素可能會影響語音識別的準確度?
11                                   如何微調whisper?
12                             如何解決protégé中的顯示問題?
13                                  為甚麼系統要使用多執行緒?
14                        service worker幾秒後會自動關閉?
15    為什麼chrome-extension不能在html中直接呼叫javascript函數
16                             ChatGPT的溫度設為多少最恰當?
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.090603866
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-16.md
# 1. [[Whisper]]
嘗試解決幻覺問題
https://github.com/openai/whisper/discussions/679
加上參數--condition_on_previous_text False  
##  評估方式?
根據不同面向，例如冗字、專有名詞，其他錯誤等  
又加了一堆論文哈哈

==問題==
根據上文，有哪些方法可以解決語音辨識的幻聽問題
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
dtype: bool
======

 50%|█████     | 18/36 [01:17<01:15,  4.17s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
dtype: bool
======
0                                 如何設定Obsidian同步?
1                                 如何設定Obsidian同步?
2                                 如何設定Obsidian同步?
3                                    Ontology是什麼?
4                                     llama支援中文嗎?
5                                在mysql中如何將多張表合併?
6                                   如何將mysql的表匯出?
7                           什麼時候安裝了obsidian的引用外掛?
8                                        怎麼選擇端口的?
9                                 如何解決論文標題中的冒號問題?
10                             哪些因素可能會影響語音識別的準確度?
11                                   如何微調whisper?
12                             如何解決protégé中的顯示問題?
13                                  為甚麼系統要使用多執行緒?
14                        service worker幾秒後會自動關閉?
15    為什麼chrome-extension不能在html中直接呼叫javascript函數
16                             ChatGPT的溫度設為多少最恰當?
17                                   嵌入有可能遇到什麼問題?
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16820273
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

==問題==
根據上文，語音辨識可以有哪些評估的方向
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
dtype: bool
======
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
dtype: bool
======
0                                 如何設定Obsidian同步?
1                                 如何設定Obsidian同步?
2                                 如何設定Obsidian同步?
3                                    Ontology是什麼?
4                                     llama支援中文嗎?
5                                在mysql中如何將多張表合併?
6                                   如何將mysql的表匯出?
7                           什麼時候安裝了obsidian的引用外掛?
8                                        怎麼選擇端口的?
9                                 如何解決論文標題中的冒號問題?
10                             哪些因素可能會影響語音識別的準確度?
11                                   如何微調whisper?
12                             如何解決protégé中的顯示問題?
13                                  為甚麼系統要使用多執行緒?
14                        service worker幾秒後會自動關閉?
15    為什麼chrome-extension不能在html中直接呼叫javascript函數
16                             ChatGPT的溫度設為多少最恰當?
17                                   嵌入有可能遇到什麼問題?
18                             有哪些方法可以解決語音辨識的幻聽問題
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.071613215
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 3. 關於瀏覽器插件的溝通方式選擇
pipe or websocket
選擇websocket，因為javascript無法操作作業系統層級的pipe
查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe
理論上也確實如此，否則瀏覽器插件的權限很容易太大

==問題==
根據上文，為什麼瀏覽器插件不使用pipe?
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
dtype: bool
======

 53%|█████▎    | 19/36 [01:21<01:09,  4.11s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
dtype: bool
======
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
dtype: bool
======
0                                 如何設定Obsidian同步?
1                                 如何設定Obsidian同步?
2                                 如何設定Obsidian同步?
3                                    Ontology是什麼?
4                                     llama支援中文嗎?
5                                在mysql中如何將多張表合併?
6                                   如何將mysql的表匯出?
7                           什麼時候安裝了obsidian的引用外掛?
8                                        怎麼選擇端口的?
9                                 如何解決論文標題中的冒號問題?
10                             哪些因素可能會影響語音識別的準確度?
11                                   如何微調whisper?
12                             如何解決protégé中的顯示問題?
13                                  為甚麼系統要使用多執行緒?
14                        service worker幾秒後會自動關閉?
15    為什麼chrome-extension不能在html中直接呼叫javascript函數
16                             ChatGPT的溫度設為多少最恰當?
17                                   嵌入有可能遇到什麼問題?
18                             有哪些方法可以解決語音辨識的幻聽問題
19                                 語音辨識可以有哪些評估的方向
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
dtype: bool
======

 56%|█████▌    | 20/36 [01:25<01:04,  4.02s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2258542
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

==問題==
根據上文，哪些因素可能會影響語音識別？
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
dtype: bool
======
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
dtype: bool
======

 58%|█████▊    | 21/36 [01:29<01:01,  4.07s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0                                 如何設定Obsidian同步?
1                                 如何設定Obsidian同步?
2                                 如何設定Obsidian同步?
3                                    Ontology是什麼?
4                                     llama支援中文嗎?
5                                在mysql中如何將多張表合併?
6                                   如何將mysql的表匯出?
7                           什麼時候安裝了obsidian的引用外掛?
8                                        怎麼選擇端口的?
9                                 如何解決論文標題中的冒號問題?
10                             哪些因素可能會影響語音識別的準確度?
11                                   如何微調whisper?
12                             如何解決protégé中的顯示問題?
13                                  為甚麼系統要使用多執行緒?
14                        service worker幾秒後會自動關閉?
15    為什麼chrome-extension不能在html中直接呼叫javascript函數
16                             ChatGPT的溫度設為多少最恰當?
17                                   嵌入有可能遇到什麼問題?
18                             有哪些方法可以解決語音辨識的幻聽問題
19                                 語音辨識可以有哪些評估的方向
20                               為什麼瀏覽器插件不使用pipe?
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.26710048
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-30.md
# 3. 將宿舍電腦的 StableDiffusion 虛擬環境中的 [[pytorch]] 更新到pytorch2[^1]
1. 切換到虛擬環境
`.\envs\scripts\activate.bat`
2. 檢查pip路徑
`pip --version`
3. 參考[官網](https://pytorch.org/get-started/locally/)訊息，CUDA11.8
`pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`
4. 結果
```
Installing collected packages: mpmath, sympy, torch, torchvision, torchaudio
Attempting uninstall: torch
Found existing installation: torch 1.13.1+cu117

==問題==
根據上文，我參考了哪個教學將pytorch更新到pytorch2?
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
dtype: bool
======
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
dtype: bool
======
0                                 如何設定Obsidian同步?
1                                 如何設定Obsidian同步?
2                                 如何設定Obsidian同步?
3                                    Ontology是什麼?
4                                     llama支援中文嗎?
5                                在mysql中如何將多張表合併?
6                                   如何將mysql的表匯出?
7                           什麼時候安裝了obsidian的引用外掛?
8                                        怎麼選擇端口的?
9                                 如何解決論文標題中的冒號問題?
10                             哪些因素可能會影響語音識別的準確度?
11                                   如何微調whisper?
12                             如何解決protégé中的顯示問題?
13                                  為甚麼系統要使用多執行緒?
14                        service worker幾秒後會自動關閉?
15    為什麼chrome-extension不能在html中直接呼叫javascript函數
16                             ChatGPT的溫度設為多少最恰當?
17                                   嵌入有可能遇到什麼問題?
18                             有哪些方法可以解決語音辨識的幻聽問題
19                                 語音辨識可以有哪些評估的方向
20                               為什麼瀏覽器插件不使用pipe?
21                                 哪些因素可能會影響語音識別？
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.3263341
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-11-15.md
# 1. 考慮和 [[EndNote]] 連動的可能性
- [[websocket]] 攔截
- [[RIS]] 等引用文件
- 文獻清單
- 其實 [[Bibtex]] 應該更適合作為相容性最好的引用格式而非[[RIS]]

==問題==
根據上文，bibtex和ris差在哪？
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
dtype: bool
======

 61%|██████    | 22/36 [01:33<00:56,  4.04s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
22    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
22    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
dtype: bool
======
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
22    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
22    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
dtype: bool
======
0                                 如何設定Obsidian同步?
1                                 如何設定Obsidian同步?
2                                 如何設定Obsidian同步?
3                                    Ontology是什麼?
4                                     llama支援中文嗎?
5                                在mysql中如何將多張表合併?
6                                   如何將mysql的表匯出?
7                           什麼時候安裝了obsidian的引用外掛?
8                                        怎麼選擇端口的?
9                                 如何解決論文標題中的冒號問題?
10                             哪些因素可能會影響語音識別的準確度?
11                                   如何微調whisper?
12                             如何解決protégé中的顯示問題?
13                                  為甚麼系統要使用多執行緒?
14                        service worker幾秒後會自動關閉?
15    為什麼chrome-extension不能在html中直接呼叫javascript函數
16                             ChatGPT的溫度設為多少最恰當?
17                                   嵌入有可能遇到什麼問題?
18                             有哪些方法可以解決語音辨識的幻聽問題
19                                 語音辨識可以有哪些評估的方向
20                               為什麼瀏覽器插件不使用pipe?
21                                 哪些因素可能會影響語音識別？
22                   我參考了哪個教學將pytorch更新到pytorch2?
Name: query, dtype: object

 64%|██████▍   | 23/36 [01:37<00:51,  4.00s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
22    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
22        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.4384315
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-11-23.md
# 2. 研究過程中，除了這個研究的貢獻外，在相關研究中也可以得到很多資訊
可以在筆記中包含，提到這篇研究的研究、該研究中的說明、評價、引用編號等
#靈感

==問題==
根據上文，可以從論文的相關研究中得到什麼？
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
22    MediaTek-Research/Breeze-7B-Instruct-v0_1
23    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
22    eetq
23    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
dtype: bool
======
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
22    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
23    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
dtype: bool
======

 67%|██████▋   | 24/36 [01:41<00:47,  3.96s/it]0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
22    infgrad/puff-base-v1
23    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
dtype: bool
======
0                                 如何設定Obsidian同步?
1                                 如何設定Obsidian同步?
2                                 如何設定Obsidian同步?
3                                    Ontology是什麼?
4                                     llama支援中文嗎?
5                                在mysql中如何將多張表合併?
6                                   如何將mysql的表匯出?
7                           什麼時候安裝了obsidian的引用外掛?
8                                        怎麼選擇端口的?
9                                 如何解決論文標題中的冒號問題?
10                             哪些因素可能會影響語音識別的準確度?
11                                   如何微調whisper?
12                             如何解決protégé中的顯示問題?
13                                  為甚麼系統要使用多執行緒?
14                        service worker幾秒後會自動關閉?
15    為什麼chrome-extension不能在html中直接呼叫javascript函數
16                             ChatGPT的溫度設為多少最恰當?
17                                   嵌入有可能遇到什麼問題?
18                             有哪些方法可以解決語音辨識的幻聽問題
19                                 語音辨識可以有哪些評估的方向
20                               為什麼瀏覽器插件不使用pipe?
21                                 哪些因素可能會影響語音識別？
22                   我參考了哪個教學將pytorch更新到pytorch2?
23                                 bibtex和ris差在哪？
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
22    1
23    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
22        chroma_similarity
23        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.44338506
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-04.md
# 5. 土豆挑戰

==問題==
根據上文，土豆挑戰是什麼？
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
22    MediaTek-Research/Breeze-7B-Instruct-v0_1
23    MediaTek-Research/Breeze-7B-Instruct-v0_1
24    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
22    eetq
23    eetq
24    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
dtype: bool
======
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
22    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
23    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
24    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
22    infgrad/puff-base-v1
23    infgrad/puff-base-v1
24    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
dtype: bool
======
0                                 如何設定Obsidian同步?
1                                 如何設定Obsidian同步?
2                                 如何設定Obsidian同步?
3                                    Ontology是什麼?
4                                     llama支援中文嗎?
5                                在mysql中如何將多張表合併?
6                                   如何將mysql的表匯出?
7                           什麼時候安裝了obsidian的引用外掛?
8                                        怎麼選擇端口的?
9                                 如何解決論文標題中的冒號問題?
10                             哪些因素可能會影響語音識別的準確度?
11                                   如何微調whisper?
12                             如何解決protégé中的顯示問題?
13                                  為甚麼系統要使用多執行緒?
14                        service worker幾秒後會自動關閉?
15    為什麼chrome-extension不能在html中直接呼叫javascript函數
16                             ChatGPT的溫度設為多少最恰當?
17                                   嵌入有可能遇到什麼問題?
18                             有哪些方法可以解決語音辨識的幻聽問題
19                                 語音辨識可以有哪些評估的方向
20                               為什麼瀏覽器插件不使用pipe?
21                                 哪些因素可能會影響語音識別？
22                   我參考了哪個教學將pytorch更新到pytorch2?
23                                 bibtex和ris差在哪？
24                               可以從論文的相關研究中得到什麼？
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
22    1
23    1
24    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
22        chroma_similarity
23        chroma_similarity
24        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...

 69%|██████▉   | 25/36 [01:45<00:43,  3.95s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1314348
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-08.md
# 1. 撰寫chrome extension
- 關於popus.js和background.js的溝通
- 遇到錯誤 `Unchecked runtime.lastError: The message port closed before a response was received.`
- 經過正確的使用sendmessage的callback的第三個參數sendResponse完成完整的溝通。
- 準確的說是service-worker，因為在版本三中並沒有background page的存在，而是改為service worker。
- 同上，有很多用法在第二版可以用，但在第三版不能用。

==問題==
根據上文，如何解決The message port closed before a response was received
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
22    MediaTek-Research/Breeze-7B-Instruct-v0_1
23    MediaTek-Research/Breeze-7B-Instruct-v0_1
24    MediaTek-Research/Breeze-7B-Instruct-v0_1
25    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
22    eetq
23    eetq
24    eetq
25    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
dtype: bool
======
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
22    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
23    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
24    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
25    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
22    infgrad/puff-base-v1
23    infgrad/puff-base-v1
24    infgrad/puff-base-v1
25    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
dtype: bool
======
0                                 如何設定Obsidian同步?
1                                 如何設定Obsidian同步?
2                                 如何設定Obsidian同步?
3                                    Ontology是什麼?
4                                     llama支援中文嗎?
5                                在mysql中如何將多張表合併?
6                                   如何將mysql的表匯出?
7                           什麼時候安裝了obsidian的引用外掛?
8                                        怎麼選擇端口的?
9                                 如何解決論文標題中的冒號問題?
10                             哪些因素可能會影響語音識別的準確度?
11                                   如何微調whisper?
12                             如何解決protégé中的顯示問題?
13                                  為甚麼系統要使用多執行緒?
14                        service worker幾秒後會自動關閉?
15    為什麼chrome-extension不能在html中直接呼叫javascript函數
16                             ChatGPT的溫度設為多少最恰當?
17                                   嵌入有可能遇到什麼問題?
18                             有哪些方法可以解決語音辨識的幻聽問題
19                                 語音辨識可以有哪些評估的方向
20                               為什麼瀏覽器插件不使用pipe?
21                                 哪些因素可能會影響語音識別？
22                   我參考了哪個教學將pytorch更新到pytorch2?
23                                 bibtex和ris差在哪？
24                               可以從論文的相關研究中得到什麼？
25                                       土豆挑戰是什麼？
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
22    1
23    1
24    1
25    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
22        chroma_similarity
23        chroma_similarity
24        chroma_similarity
25        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.062017523
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-22.md
- 註: daemon關閉時會強制關閉，若有讀寫檔、暫存檔等需要額外處理，例如在主thread中捕捉相關的事件。  
- ChatGPT用模擬ctrl+c的方式實現自訂義複製快捷鍵，我喜歡
- 本來無法模擬ctrl+c，後來發現是因為模擬前沒有放開實體按鍵，使用time.sleep或keyboard.release都能解決這個問題，也不需要管理員權限  
- 讀取當前焦點視窗
- 暫時先考慮windows，不考慮mac和linux，因此使用pywin32  
- [[cypher]] 的參數化查詢無法用於標籤或關係上，因此需要使用python的格式化輸入來處理
`query = f"MATCH (n:{tagName})"`

==問題==
根據上文，哪些python套件能監聽快捷鍵？
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
22    MediaTek-Research/Breeze-7B-Instruct-v0_1
23    MediaTek-Research/Breeze-7B-Instruct-v0_1
24    MediaTek-Research/Breeze-7B-Instruct-v0_1
25    MediaTek-Research/Breeze-7B-Instruct-v0_1
26    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
22    eetq
23    eetq
24    eetq
25    eetq
26    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
dtype: bool
======

 72%|███████▏  | 26/36 [01:49<00:39,  3.95s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
22    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
23    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
24    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
25    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
26    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
22    infgrad/puff-base-v1
23    infgrad/puff-base-v1
24    infgrad/puff-base-v1
25    infgrad/puff-base-v1
26    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
dtype: bool
======
0                                       如何設定Obsidian同步?
1                                       如何設定Obsidian同步?
2                                       如何設定Obsidian同步?
3                                          Ontology是什麼?
4                                           llama支援中文嗎?
5                                      在mysql中如何將多張表合併?
6                                         如何將mysql的表匯出?
7                                 什麼時候安裝了obsidian的引用外掛?
8                                              怎麼選擇端口的?
9                                       如何解決論文標題中的冒號問題?
10                                   哪些因素可能會影響語音識別的準確度?
11                                         如何微調whisper?
12                                   如何解決protégé中的顯示問題?
13                                        為甚麼系統要使用多執行緒?
14                              service worker幾秒後會自動關閉?
15          為什麼chrome-extension不能在html中直接呼叫javascript函數
16                                   ChatGPT的溫度設為多少最恰當?
17                                         嵌入有可能遇到什麼問題?
18                                   有哪些方法可以解決語音辨識的幻聽問題
19                                       語音辨識可以有哪些評估的方向
20                                     為什麼瀏覽器插件不使用pipe?
21                                       哪些因素可能會影響語音識別？
22                         我參考了哪個教學將pytorch更新到pytorch2?
23                                       bibtex和ris差在哪？
24                                     可以從論文的相關研究中得到什麼？
25                                             土豆挑戰是什麼？
26    如何解決The message port closed before a response ...
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
22    1
23    1
24    1
25    1
26    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
22        chroma_similarity
23        chroma_similarity
24        chroma_similarity
25        chroma_similarity
26        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2724631
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-16.md
`mklink "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\make.exe" "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\mingw32-make.exe"`
- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`
- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性
- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要
- [ ] 整理文獻
- [ ] 閱讀清單

==問題==
根據上文，除了pyqt外，當時還考慮哪些類似的套件？
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
22    MediaTek-Research/Breeze-7B-Instruct-v0_1
23    MediaTek-Research/Breeze-7B-Instruct-v0_1
24    MediaTek-Research/Breeze-7B-Instruct-v0_1
25    MediaTek-Research/Breeze-7B-Instruct-v0_1
26    MediaTek-Research/Breeze-7B-Instruct-v0_1
27    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
22    eetq
23    eetq
24    eetq
25    eetq
26    eetq
27    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
dtype: bool
======

 75%|███████▌  | 27/36 [01:53<00:35,  3.93s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
22    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
23    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
24    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
25    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
26    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
27    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
22    infgrad/puff-base-v1
23    infgrad/puff-base-v1
24    infgrad/puff-base-v1
25    infgrad/puff-base-v1
26    infgrad/puff-base-v1
27    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
dtype: bool
======
0                                       如何設定Obsidian同步?
1                                       如何設定Obsidian同步?
2                                       如何設定Obsidian同步?
3                                          Ontology是什麼?
4                                           llama支援中文嗎?
5                                      在mysql中如何將多張表合併?
6                                         如何將mysql的表匯出?
7                                 什麼時候安裝了obsidian的引用外掛?
8                                              怎麼選擇端口的?
9                                       如何解決論文標題中的冒號問題?
10                                   哪些因素可能會影響語音識別的準確度?
11                                         如何微調whisper?
12                                   如何解決protégé中的顯示問題?
13                                        為甚麼系統要使用多執行緒?
14                              service worker幾秒後會自動關閉?
15          為什麼chrome-extension不能在html中直接呼叫javascript函數
16                                   ChatGPT的溫度設為多少最恰當?
17                                         嵌入有可能遇到什麼問題?
18                                   有哪些方法可以解決語音辨識的幻聽問題
19                                       語音辨識可以有哪些評估的方向
20                                     為什麼瀏覽器插件不使用pipe?
21                                       哪些因素可能會影響語音識別？
22                         我參考了哪個教學將pytorch更新到pytorch2?
23                                       bibtex和ris差在哪？
24                                     可以從論文的相關研究中得到什麼？
25                                             土豆挑戰是什麼？
26    如何解決The message port closed before a response ...
27                                    哪些python套件能監聽快捷鍵？
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
22    1
23    1
24    1
25    1
26    1
27    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
22        chroma_similarity
23        chroma_similarity
24        chroma_similarity
25        chroma_similarity
26        chroma_similarity
27        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.14854458
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-16.md
# 999. 其他
- 根據FastAPI的文檔，建議使用Union來取代Optional功能，但範例中有點錯誤
- 建議避免使用 `name: Optional[str]`，因為實際上name並不是可選的而是必選的
- 就算使用 `def say_hi(name: str | None)` 也不代表不需要參數，必須要設定初始值，如 `def say_hi(name: str | None = None)`  
[^1]: https://stackoverflow.com/questions/63872924/how-can-i-send-an-http-request-from-my-fastapi-app-to-another-site-api
[^2]: https://scrapfly.io/blog/httpx-vs-requests-vs-aiohttp/

==問題==
根據上文，系統中的FastAPI監聽哪個端口？
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
22    MediaTek-Research/Breeze-7B-Instruct-v0_1
23    MediaTek-Research/Breeze-7B-Instruct-v0_1
24    MediaTek-Research/Breeze-7B-Instruct-v0_1
25    MediaTek-Research/Breeze-7B-Instruct-v0_1
26    MediaTek-Research/Breeze-7B-Instruct-v0_1
27    MediaTek-Research/Breeze-7B-Instruct-v0_1
28    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
22    eetq
23    eetq
24    eetq
25    eetq
26    eetq
27    eetq
28    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
dtype: bool
======

 78%|███████▊  | 28/36 [01:57<00:30,  3.84s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
22    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
23    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
24    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
25    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
26    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
27    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
28    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
22    infgrad/puff-base-v1
23    infgrad/puff-base-v1
24    infgrad/puff-base-v1
25    infgrad/puff-base-v1
26    infgrad/puff-base-v1
27    infgrad/puff-base-v1
28    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
dtype: bool
======
0                                       如何設定Obsidian同步?
1                                       如何設定Obsidian同步?
2                                       如何設定Obsidian同步?
3                                          Ontology是什麼?
4                                           llama支援中文嗎?
5                                      在mysql中如何將多張表合併?
6                                         如何將mysql的表匯出?
7                                 什麼時候安裝了obsidian的引用外掛?
8                                              怎麼選擇端口的?
9                                       如何解決論文標題中的冒號問題?
10                                   哪些因素可能會影響語音識別的準確度?
11                                         如何微調whisper?
12                                   如何解決protégé中的顯示問題?
13                                        為甚麼系統要使用多執行緒?
14                              service worker幾秒後會自動關閉?
15          為什麼chrome-extension不能在html中直接呼叫javascript函數
16                                   ChatGPT的溫度設為多少最恰當?
17                                         嵌入有可能遇到什麼問題?
18                                   有哪些方法可以解決語音辨識的幻聽問題
19                                       語音辨識可以有哪些評估的方向
20                                     為什麼瀏覽器插件不使用pipe?
21                                       哪些因素可能會影響語音識別？
22                         我參考了哪個教學將pytorch更新到pytorch2?
23                                       bibtex和ris差在哪？
24                                     可以從論文的相關研究中得到什麼？
25                                             土豆挑戰是什麼？
26    如何解決The message port closed before a response ...
27                                    哪些python套件能監聽快捷鍵？
28                                除了pyqt外，當時還考慮哪些類似的套件？
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
22    1
23    1
24    1
25    1
26    1
27    1
28    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
22        chroma_similarity
23        chroma_similarity
24        chroma_similarity
25        chroma_similarity
26        chroma_similarity
27        chroma_similarity
28        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.28215396
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

==問題==
根據上文，RALM類似什麼概念？
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
22    MediaTek-Research/Breeze-7B-Instruct-v0_1
23    MediaTek-Research/Breeze-7B-Instruct-v0_1
24    MediaTek-Research/Breeze-7B-Instruct-v0_1
25    MediaTek-Research/Breeze-7B-Instruct-v0_1
26    MediaTek-Research/Breeze-7B-Instruct-v0_1
27    MediaTek-Research/Breeze-7B-Instruct-v0_1
28    MediaTek-Research/Breeze-7B-Instruct-v0_1
29    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
22    eetq
23    eetq
24    eetq
25    eetq
26    eetq
27    eetq
28    eetq
29    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
dtype: bool
======

 81%|████████  | 29/36 [02:00<00:26,  3.82s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
22    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
23    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
24    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
25    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
26    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
27    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
28    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
29    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
22    infgrad/puff-base-v1
23    infgrad/puff-base-v1
24    infgrad/puff-base-v1
25    infgrad/puff-base-v1
26    infgrad/puff-base-v1
27    infgrad/puff-base-v1
28    infgrad/puff-base-v1
29    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
dtype: bool
======
0                                       如何設定Obsidian同步?
1                                       如何設定Obsidian同步?
2                                       如何設定Obsidian同步?
3                                          Ontology是什麼?
4                                           llama支援中文嗎?
5                                      在mysql中如何將多張表合併?
6                                         如何將mysql的表匯出?
7                                 什麼時候安裝了obsidian的引用外掛?
8                                              怎麼選擇端口的?
9                                       如何解決論文標題中的冒號問題?
10                                   哪些因素可能會影響語音識別的準確度?
11                                         如何微調whisper?
12                                   如何解決protégé中的顯示問題?
13                                        為甚麼系統要使用多執行緒?
14                              service worker幾秒後會自動關閉?
15          為什麼chrome-extension不能在html中直接呼叫javascript函數
16                                   ChatGPT的溫度設為多少最恰當?
17                                         嵌入有可能遇到什麼問題?
18                                   有哪些方法可以解決語音辨識的幻聽問題
19                                       語音辨識可以有哪些評估的方向
20                                     為什麼瀏覽器插件不使用pipe?
21                                       哪些因素可能會影響語音識別？
22                         我參考了哪個教學將pytorch更新到pytorch2?
23                                       bibtex和ris差在哪？
24                                     可以從論文的相關研究中得到什麼？
25                                             土豆挑戰是什麼？
26    如何解決The message port closed before a response ...
27                                    哪些python套件能監聽快捷鍵？
28                                除了pyqt外，當時還考慮哪些類似的套件？
29                                   系統中的FastAPI監聽哪個端口？
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
22    1
23    1
24    1
25    1
26    1
27    1
28    1
29    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
22        chroma_similarity
23        chroma_similarity
24        chroma_similarity
25        chroma_similarity
26        chroma_similarity
27        chroma_similarity
28        chroma_similarity
29        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.04661884
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-16.md
```
- DB變數問題
- 由於launch.py使用subprocess.popen開啟後，無法再取得launch中建立的DB連線，因此在fastapi需要重新呼叫一次handler並建立連線
- 將ini轉成yaml
- 考慮到llm中可能會用到換行相關的設定、整體彈性
- 設定檔的修改以gradio介面為主，而非人工設定
- 作法參考[^4]
- Aura的log紀錄只有profession版才有，未來遲早要移到本地端
- 同樣是因subprocess，造成logging設定跑掉，需要在fastapi設定Log
- 造成除錯困難，例如明明log沒有query成功，但資料庫卻有新增資料

==問題==
根據上文，多源資料分析和管理差在哪？
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
22    MediaTek-Research/Breeze-7B-Instruct-v0_1
23    MediaTek-Research/Breeze-7B-Instruct-v0_1
24    MediaTek-Research/Breeze-7B-Instruct-v0_1
25    MediaTek-Research/Breeze-7B-Instruct-v0_1
26    MediaTek-Research/Breeze-7B-Instruct-v0_1
27    MediaTek-Research/Breeze-7B-Instruct-v0_1
28    MediaTek-Research/Breeze-7B-Instruct-v0_1
29    MediaTek-Research/Breeze-7B-Instruct-v0_1
30    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
22    eetq
23    eetq
24    eetq
25    eetq
26    eetq
27    eetq
28    eetq
29    eetq
30    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
dtype: bool
======

 83%|████████▎ | 30/36 [02:04<00:23,  3.89s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
22    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
23    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
24    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
25    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
26    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
27    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
28    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
29    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
30    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
22    infgrad/puff-base-v1
23    infgrad/puff-base-v1
24    infgrad/puff-base-v1
25    infgrad/puff-base-v1
26    infgrad/puff-base-v1
27    infgrad/puff-base-v1
28    infgrad/puff-base-v1
29    infgrad/puff-base-v1
30    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
dtype: bool
======
0                                       如何設定Obsidian同步?
1                                       如何設定Obsidian同步?
2                                       如何設定Obsidian同步?
3                                          Ontology是什麼?
4                                           llama支援中文嗎?
5                                      在mysql中如何將多張表合併?
6                                         如何將mysql的表匯出?
7                                 什麼時候安裝了obsidian的引用外掛?
8                                              怎麼選擇端口的?
9                                       如何解決論文標題中的冒號問題?
10                                   哪些因素可能會影響語音識別的準確度?
11                                         如何微調whisper?
12                                   如何解決protégé中的顯示問題?
13                                        為甚麼系統要使用多執行緒?
14                              service worker幾秒後會自動關閉?
15          為什麼chrome-extension不能在html中直接呼叫javascript函數
16                                   ChatGPT的溫度設為多少最恰當?
17                                         嵌入有可能遇到什麼問題?
18                                   有哪些方法可以解決語音辨識的幻聽問題
19                                       語音辨識可以有哪些評估的方向
20                                     為什麼瀏覽器插件不使用pipe?
21                                       哪些因素可能會影響語音識別？
22                         我參考了哪個教學將pytorch更新到pytorch2?
23                                       bibtex和ris差在哪？
24                                     可以從論文的相關研究中得到什麼？
25                                             土豆挑戰是什麼？
26    如何解決The message port closed before a response ...
27                                    哪些python套件能監聽快捷鍵？
28                                除了pyqt外，當時還考慮哪些類似的套件？
29                                   系統中的FastAPI監聽哪個端口？
30                                          RALM類似什麼概念？
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
30    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
22    1
23    1
24    1
25    1
26    1
27    1
28    1
29    1
30    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
30    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
22        chroma_similarity
23        chroma_similarity
24        chroma_similarity
25        chroma_similarity
26        chroma_similarity
27        chroma_similarity
28        chroma_similarity
29        chroma_similarity
30        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.06321003
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-18.md
[^10]: https://community.neo4j.com/t/import-individuals-and-relate-to-classes-in-neo4j/24567/2

==問題==
根據上文，在2024/4/17，我看完NEUMAI了嗎？
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
22    MediaTek-Research/Breeze-7B-Instruct-v0_1
23    MediaTek-Research/Breeze-7B-Instruct-v0_1
24    MediaTek-Research/Breeze-7B-Instruct-v0_1
25    MediaTek-Research/Breeze-7B-Instruct-v0_1
26    MediaTek-Research/Breeze-7B-Instruct-v0_1
27    MediaTek-Research/Breeze-7B-Instruct-v0_1
28    MediaTek-Research/Breeze-7B-Instruct-v0_1
29    MediaTek-Research/Breeze-7B-Instruct-v0_1
30    MediaTek-Research/Breeze-7B-Instruct-v0_1
31    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
22    eetq
23    eetq
24    eetq
25    eetq
26    eetq
27    eetq
28    eetq
29    eetq
30    eetq
31    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
dtype: bool
======

 86%|████████▌ | 31/36 [02:08<00:18,  3.80s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
22    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
23    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
24    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
25    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
26    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
27    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
28    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
29    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
30    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
31    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
22    infgrad/puff-base-v1
23    infgrad/puff-base-v1
24    infgrad/puff-base-v1
25    infgrad/puff-base-v1
26    infgrad/puff-base-v1
27    infgrad/puff-base-v1
28    infgrad/puff-base-v1
29    infgrad/puff-base-v1
30    infgrad/puff-base-v1
31    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
dtype: bool
======
0                                       如何設定Obsidian同步?
1                                       如何設定Obsidian同步?
2                                       如何設定Obsidian同步?
3                                          Ontology是什麼?
4                                           llama支援中文嗎?
5                                      在mysql中如何將多張表合併?
6                                         如何將mysql的表匯出?
7                                 什麼時候安裝了obsidian的引用外掛?
8                                              怎麼選擇端口的?
9                                       如何解決論文標題中的冒號問題?
10                                   哪些因素可能會影響語音識別的準確度?
11                                         如何微調whisper?
12                                   如何解決protégé中的顯示問題?
13                                        為甚麼系統要使用多執行緒?
14                              service worker幾秒後會自動關閉?
15          為什麼chrome-extension不能在html中直接呼叫javascript函數
16                                   ChatGPT的溫度設為多少最恰當?
17                                         嵌入有可能遇到什麼問題?
18                                   有哪些方法可以解決語音辨識的幻聽問題
19                                       語音辨識可以有哪些評估的方向
20                                     為什麼瀏覽器插件不使用pipe?
21                                       哪些因素可能會影響語音識別？
22                         我參考了哪個教學將pytorch更新到pytorch2?
23                                       bibtex和ris差在哪？
24                                     可以從論文的相關研究中得到什麼？
25                                             土豆挑戰是什麼？
26    如何解決The message port closed before a response ...
27                                    哪些python套件能監聽快捷鍵？
28                                除了pyqt外，當時還考慮哪些類似的套件？
29                                   系統中的FastAPI監聽哪個端口？
30                                          RALM類似什麼概念？
31                                        多源資料分析和管理差在哪？
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
30    False
31    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
22    1
23    1
24    1
25    1
26    1
27    1
28    1
29    1
30    1
31    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
30    False
31    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
22        chroma_similarity
23        chroma_similarity
24        chroma_similarity
25        chroma_similarity
26        chroma_similarity
27        chroma_similarity
28        chroma_similarity
29        chroma_similarity
30        chroma_similarity
31        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2960534
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

==問題==
根據上文，在2024/4/17，我做了什麼實驗？
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
22    MediaTek-Research/Breeze-7B-Instruct-v0_1
23    MediaTek-Research/Breeze-7B-Instruct-v0_1
24    MediaTek-Research/Breeze-7B-Instruct-v0_1
25    MediaTek-Research/Breeze-7B-Instruct-v0_1
26    MediaTek-Research/Breeze-7B-Instruct-v0_1
27    MediaTek-Research/Breeze-7B-Instruct-v0_1
28    MediaTek-Research/Breeze-7B-Instruct-v0_1
29    MediaTek-Research/Breeze-7B-Instruct-v0_1
30    MediaTek-Research/Breeze-7B-Instruct-v0_1
31    MediaTek-Research/Breeze-7B-Instruct-v0_1
32    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
22    eetq
23    eetq
24    eetq
25    eetq
26    eetq
27    eetq
28    eetq
29    eetq
30    eetq
31    eetq
32    eetq
Name: 量化, dtype: object

 89%|████████▉ | 32/36 [02:12<00:14,  3.74s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
dtype: bool
======
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
22    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
23    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
24    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
25    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
26    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
27    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
28    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
29    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
30    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
31    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
32    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
22    infgrad/puff-base-v1
23    infgrad/puff-base-v1
24    infgrad/puff-base-v1
25    infgrad/puff-base-v1
26    infgrad/puff-base-v1
27    infgrad/puff-base-v1
28    infgrad/puff-base-v1
29    infgrad/puff-base-v1
30    infgrad/puff-base-v1
31    infgrad/puff-base-v1
32    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
dtype: bool
======
0                                       如何設定Obsidian同步?
1                                       如何設定Obsidian同步?
2                                       如何設定Obsidian同步?
3                                          Ontology是什麼?
4                                           llama支援中文嗎?
5                                      在mysql中如何將多張表合併?
6                                         如何將mysql的表匯出?
7                                 什麼時候安裝了obsidian的引用外掛?
8                                              怎麼選擇端口的?
9                                       如何解決論文標題中的冒號問題?
10                                   哪些因素可能會影響語音識別的準確度?
11                                         如何微調whisper?
12                                   如何解決protégé中的顯示問題?
13                                        為甚麼系統要使用多執行緒?
14                              service worker幾秒後會自動關閉?
15          為什麼chrome-extension不能在html中直接呼叫javascript函數
16                                   ChatGPT的溫度設為多少最恰當?
17                                         嵌入有可能遇到什麼問題?
18                                   有哪些方法可以解決語音辨識的幻聽問題
19                                       語音辨識可以有哪些評估的方向
20                                     為什麼瀏覽器插件不使用pipe?
21                                       哪些因素可能會影響語音識別？
22                         我參考了哪個教學將pytorch更新到pytorch2?
23                                       bibtex和ris差在哪？
24                                     可以從論文的相關研究中得到什麼？
25                                             土豆挑戰是什麼？
26    如何解決The message port closed before a response ...
27                                    哪些python套件能監聽快捷鍵？
28                                除了pyqt外，當時還考慮哪些類似的套件？
29                                   系統中的FastAPI監聽哪個端口？
30                                          RALM類似什麼概念？
31                                        多源資料分析和管理差在哪？
32                              在2024/4/17，我看完NEUMAI了嗎？
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
30    False
31    False
32    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
22    1
23    1
24    1
25    1
26    1
27    1
28    1
29    1
30    1
31    1
32    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
30    False
31    False
32    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
22        chroma_similarity
23        chroma_similarity
24        chroma_similarity
25        chroma_similarity
26        chroma_similarity
27        chroma_similarity
28        chroma_similarity
29        chroma_similarity
30        chroma_similarity
31        chroma_similarity
32        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.0678077
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-21.md
# 2. 跑實驗
- google/gemma-2b-it
- 約20分鐘
- google/gemma-2b
- 約20分鐘
- meta-llama/Llama-2-7b-chat-hf
- 約一小時

==問題==
根據上文，在2024/4/17，我實驗過gemma了嗎?
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
22    MediaTek-Research/Breeze-7B-Instruct-v0_1
23    MediaTek-Research/Breeze-7B-Instruct-v0_1
24    MediaTek-Research/Breeze-7B-Instruct-v0_1
25    MediaTek-Research/Breeze-7B-Instruct-v0_1
26    MediaTek-Research/Breeze-7B-Instruct-v0_1
27    MediaTek-Research/Breeze-7B-Instruct-v0_1
28    MediaTek-Research/Breeze-7B-Instruct-v0_1
29    MediaTek-Research/Breeze-7B-Instruct-v0_1
30    MediaTek-Research/Breeze-7B-Instruct-v0_1
31    MediaTek-Research/Breeze-7B-Instruct-v0_1
32    MediaTek-Research/Breeze-7B-Instruct-v0_1
33    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
dtype: bool
======

 92%|█████████▏| 33/36 [02:15<00:11,  3.69s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
22    eetq
23    eetq
24    eetq
25    eetq
26    eetq
27    eetq
28    eetq
29    eetq
30    eetq
31    eetq
32    eetq
33    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
dtype: bool
======
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
22    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
23    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
24    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
25    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
26    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
27    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
28    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
29    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
30    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
31    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
32    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
33    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
22    infgrad/puff-base-v1
23    infgrad/puff-base-v1
24    infgrad/puff-base-v1
25    infgrad/puff-base-v1
26    infgrad/puff-base-v1
27    infgrad/puff-base-v1
28    infgrad/puff-base-v1
29    infgrad/puff-base-v1
30    infgrad/puff-base-v1
31    infgrad/puff-base-v1
32    infgrad/puff-base-v1
33    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
dtype: bool
======
0                                       如何設定Obsidian同步?
1                                       如何設定Obsidian同步?
2                                       如何設定Obsidian同步?
3                                          Ontology是什麼?
4                                           llama支援中文嗎?
5                                      在mysql中如何將多張表合併?
6                                         如何將mysql的表匯出?
7                                 什麼時候安裝了obsidian的引用外掛?
8                                              怎麼選擇端口的?
9                                       如何解決論文標題中的冒號問題?
10                                   哪些因素可能會影響語音識別的準確度?
11                                         如何微調whisper?
12                                   如何解決protégé中的顯示問題?
13                                        為甚麼系統要使用多執行緒?
14                              service worker幾秒後會自動關閉?
15          為什麼chrome-extension不能在html中直接呼叫javascript函數
16                                   ChatGPT的溫度設為多少最恰當?
17                                         嵌入有可能遇到什麼問題?
18                                   有哪些方法可以解決語音辨識的幻聽問題
19                                       語音辨識可以有哪些評估的方向
20                                     為什麼瀏覽器插件不使用pipe?
21                                       哪些因素可能會影響語音識別？
22                         我參考了哪個教學將pytorch更新到pytorch2?
23                                       bibtex和ris差在哪？
24                                     可以從論文的相關研究中得到什麼？
25                                             土豆挑戰是什麼？
26    如何解決The message port closed before a response ...
27                                    哪些python套件能監聽快捷鍵？
28                                除了pyqt外，當時還考慮哪些類似的套件？
29                                   系統中的FastAPI監聽哪個端口？
30                                          RALM類似什麼概念？
31                                        多源資料分析和管理差在哪？
32                              在2024/4/17，我看完NEUMAI了嗎？
33                                  在2024/4/17，我做了什麼實驗？
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
30    False
31    False
32    False
33    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
22    1
23    1
24    1
25    1
26    1
27    1
28    1
29    1
30    1
31    1
32    1
33    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
30    False
31    False
32    False
33    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
22        chroma_similarity
23        chroma_similarity
24        chroma_similarity
25        chroma_similarity
26        chroma_similarity
27        chroma_similarity
28        chroma_similarity
29        chroma_similarity
30        chroma_similarity
31        chroma_similarity
32        chroma_similarity
33        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.10619263
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-07.md
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典

==問題==
根據上文，在2024/4/17，我設計完整個架構和所需要的API需求及文件了嗎？
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
34    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
22    MediaTek-Research/Breeze-7B-Instruct-v0_1
23    MediaTek-Research/Breeze-7B-Instruct-v0_1
24    MediaTek-Research/Breeze-7B-Instruct-v0_1
25    MediaTek-Research/Breeze-7B-Instruct-v0_1
26    MediaTek-Research/Breeze-7B-Instruct-v0_1
27    MediaTek-Research/Breeze-7B-Instruct-v0_1
28    MediaTek-Research/Breeze-7B-Instruct-v0_1
29    MediaTek-Research/Breeze-7B-Instruct-v0_1
30    MediaTek-Research/Breeze-7B-Instruct-v0_1
31    MediaTek-Research/Breeze-7B-Instruct-v0_1
32    MediaTek-Research/Breeze-7B-Instruct-v0_1
33    MediaTek-Research/Breeze-7B-Instruct-v0_1
34    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
34    True
dtype: bool
======

 94%|█████████▍| 34/36 [02:19<00:07,  3.66s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
22    eetq
23    eetq
24    eetq
25    eetq
26    eetq
27    eetq
28    eetq
29    eetq
30    eetq
31    eetq
32    eetq
33    eetq
34    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
34    True
dtype: bool
======
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
22    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
23    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
24    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
25    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
26    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
27    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
28    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
29    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
30    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
31    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
32    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
33    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
34    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
34    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
22    infgrad/puff-base-v1
23    infgrad/puff-base-v1
24    infgrad/puff-base-v1
25    infgrad/puff-base-v1
26    infgrad/puff-base-v1
27    infgrad/puff-base-v1
28    infgrad/puff-base-v1
29    infgrad/puff-base-v1
30    infgrad/puff-base-v1
31    infgrad/puff-base-v1
32    infgrad/puff-base-v1
33    infgrad/puff-base-v1
34    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
34    True
dtype: bool
======
0                                       如何設定Obsidian同步?
1                                       如何設定Obsidian同步?
2                                       如何設定Obsidian同步?
3                                          Ontology是什麼?
4                                           llama支援中文嗎?
5                                      在mysql中如何將多張表合併?
6                                         如何將mysql的表匯出?
7                                 什麼時候安裝了obsidian的引用外掛?
8                                              怎麼選擇端口的?
9                                       如何解決論文標題中的冒號問題?
10                                   哪些因素可能會影響語音識別的準確度?
11                                         如何微調whisper?
12                                   如何解決protégé中的顯示問題?
13                                        為甚麼系統要使用多執行緒?
14                              service worker幾秒後會自動關閉?
15          為什麼chrome-extension不能在html中直接呼叫javascript函數
16                                   ChatGPT的溫度設為多少最恰當?
17                                         嵌入有可能遇到什麼問題?
18                                   有哪些方法可以解決語音辨識的幻聽問題
19                                       語音辨識可以有哪些評估的方向
20                                     為什麼瀏覽器插件不使用pipe?
21                                       哪些因素可能會影響語音識別？
22                         我參考了哪個教學將pytorch更新到pytorch2?
23                                       bibtex和ris差在哪？
24                                     可以從論文的相關研究中得到什麼？
25                                             土豆挑戰是什麼？
26    如何解決The message port closed before a response ...
27                                    哪些python套件能監聽快捷鍵？
28                                除了pyqt外，當時還考慮哪些類似的套件？
29                                   系統中的FastAPI監聽哪個端口？
30                                          RALM類似什麼概念？
31                                        多源資料分析和管理差在哪？
32                              在2024/4/17，我看完NEUMAI了嗎？
33                                  在2024/4/17，我做了什麼實驗？
34                              在2024/4/17，我實驗過gemma了嗎?
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
30    False
31    False
32    False
33    False
34    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
22    1
23    1
24    1
25    1
26    1
27    1
28    1
29    1
30    1
31    1
32    1
33    1
34    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
30    False
31    False
32    False
33    False
34    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
22        chroma_similarity
23        chroma_similarity
24        chroma_similarity
25        chroma_similarity
26        chroma_similarity
27        chroma_similarity
28        chroma_similarity
29        chroma_similarity
30        chroma_similarity
31        chroma_similarity
32        chroma_similarity
33        chroma_similarity
34        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.12266735
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-17.md
# 2. 試用 [[Chat RTX]]
- 38G，好大
- 下載好久，安裝好久，安裝一個多小時吧，包含下載模型的時間
- 吃爆VRAM、反應不快，基本只收英文
- 因為很卡所以沒有繼續測試下去  
[^3]: https://www.volcengine.com/theme/3863827-W-7-1
[^4]: https://www.pythonforbeginners.com/basics/convert-ini-to-yaml-in-python
[^5]: https://docs.privategpt.dev/recipes/choice-of-llm/list-of-ll-ms

==問題==
根據上文，我對ChatRTX的評價是正面還是負面
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
34    True
35    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
22    MediaTek-Research/Breeze-7B-Instruct-v0_1
23    MediaTek-Research/Breeze-7B-Instruct-v0_1
24    MediaTek-Research/Breeze-7B-Instruct-v0_1
25    MediaTek-Research/Breeze-7B-Instruct-v0_1
26    MediaTek-Research/Breeze-7B-Instruct-v0_1
27    MediaTek-Research/Breeze-7B-Instruct-v0_1
28    MediaTek-Research/Breeze-7B-Instruct-v0_1
29    MediaTek-Research/Breeze-7B-Instruct-v0_1
30    MediaTek-Research/Breeze-7B-Instruct-v0_1
31    MediaTek-Research/Breeze-7B-Instruct-v0_1
32    MediaTek-Research/Breeze-7B-Instruct-v0_1
33    MediaTek-Research/Breeze-7B-Instruct-v0_1
34    MediaTek-Research/Breeze-7B-Instruct-v0_1
35    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object

 97%|█████████▋| 35/36 [02:22<00:03,  3.64s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
34    True
35    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
22    eetq
23    eetq
24    eetq
25    eetq
26    eetq
27    eetq
28    eetq
29    eetq
30    eetq
31    eetq
32    eetq
33    eetq
34    eetq
35    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
34    True
35    True
dtype: bool
======
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
22    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
23    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
24    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
25    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
26    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
27    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
28    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
29    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
30    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
31    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
32    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
33    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
34    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
35    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
34    True
35    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
22    infgrad/puff-base-v1
23    infgrad/puff-base-v1
24    infgrad/puff-base-v1
25    infgrad/puff-base-v1
26    infgrad/puff-base-v1
27    infgrad/puff-base-v1
28    infgrad/puff-base-v1
29    infgrad/puff-base-v1
30    infgrad/puff-base-v1
31    infgrad/puff-base-v1
32    infgrad/puff-base-v1
33    infgrad/puff-base-v1
34    infgrad/puff-base-v1
35    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
34    True
35    True
dtype: bool
======
0                                       如何設定Obsidian同步?
1                                       如何設定Obsidian同步?
2                                       如何設定Obsidian同步?
3                                          Ontology是什麼?
4                                           llama支援中文嗎?
5                                      在mysql中如何將多張表合併?
6                                         如何將mysql的表匯出?
7                                 什麼時候安裝了obsidian的引用外掛?
8                                              怎麼選擇端口的?
9                                       如何解決論文標題中的冒號問題?
10                                   哪些因素可能會影響語音識別的準確度?
11                                         如何微調whisper?
12                                   如何解決protégé中的顯示問題?
13                                        為甚麼系統要使用多執行緒?
14                              service worker幾秒後會自動關閉?
15          為什麼chrome-extension不能在html中直接呼叫javascript函數
16                                   ChatGPT的溫度設為多少最恰當?
17                                         嵌入有可能遇到什麼問題?
18                                   有哪些方法可以解決語音辨識的幻聽問題
19                                       語音辨識可以有哪些評估的方向
20                                     為什麼瀏覽器插件不使用pipe?
21                                       哪些因素可能會影響語音識別？
22                         我參考了哪個教學將pytorch更新到pytorch2?
23                                       bibtex和ris差在哪？
24                                     可以從論文的相關研究中得到什麼？
25                                             土豆挑戰是什麼？
26    如何解決The message port closed before a response ...
27                                    哪些python套件能監聽快捷鍵？
28                                除了pyqt外，當時還考慮哪些類似的套件？
29                                   系統中的FastAPI監聽哪個端口？
30                                          RALM類似什麼概念？
31                                        多源資料分析和管理差在哪？
32                              在2024/4/17，我看完NEUMAI了嗎？
33                                  在2024/4/17，我做了什麼實驗？
34                              在2024/4/17，我實驗過gemma了嗎?
35                  在2024/4/17，我設計完整個架構和所需要的API需求及文件了嗎？
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
30    False
31    False
32    False
33    False
34    False
35    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
22    1
23    1
24    1
25    1
26    1
27    1
28    1
29    1
30    1
31    1
32    1
33    1
34    1
35    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
30    False
31    False
32    False
33    False
34    False
35    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
22        chroma_similarity
23        chroma_similarity
24        chroma_similarity
25        chroma_similarity
26        chroma_similarity
27        chroma_similarity
28        chroma_similarity
29        chroma_similarity
30        chroma_similarity
31        chroma_similarity
32        chroma_similarity
33        chroma_similarity
34        chroma_similarity
35        chroma_similarity
Name: 檢索方法, dtype: object
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.056782953
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-21.md
# 2. 跑實驗
- google/gemma-2b-it
- 約20分鐘
- google/gemma-2b
- 約20分鐘
- meta-llama/Llama-2-7b-chat-hf
- 約一小時

==問題==
根據上文，在2024/4/21，我總共花了幾分鐘跑實驗
請用20個字簡潔回答問題。

0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
34    True
35    True
36    True
dtype: bool
======
0     MediaTek-Research/Breeze-7B-Instruct-v0_1
1     MediaTek-Research/Breeze-7B-Instruct-v0_1
2     MediaTek-Research/Breeze-7B-Instruct-v0_1
3     MediaTek-Research/Breeze-7B-Instruct-v0_1
4     MediaTek-Research/Breeze-7B-Instruct-v0_1
5     MediaTek-Research/Breeze-7B-Instruct-v0_1
6     MediaTek-Research/Breeze-7B-Instruct-v0_1
7     MediaTek-Research/Breeze-7B-Instruct-v0_1
8     MediaTek-Research/Breeze-7B-Instruct-v0_1
9     MediaTek-Research/Breeze-7B-Instruct-v0_1
10    MediaTek-Research/Breeze-7B-Instruct-v0_1
11    MediaTek-Research/Breeze-7B-Instruct-v0_1
12    MediaTek-Research/Breeze-7B-Instruct-v0_1
13    MediaTek-Research/Breeze-7B-Instruct-v0_1
14    MediaTek-Research/Breeze-7B-Instruct-v0_1
15    MediaTek-Research/Breeze-7B-Instruct-v0_1
16    MediaTek-Research/Breeze-7B-Instruct-v0_1
17    MediaTek-Research/Breeze-7B-Instruct-v0_1
18    MediaTek-Research/Breeze-7B-Instruct-v0_1
19    MediaTek-Research/Breeze-7B-Instruct-v0_1
20    MediaTek-Research/Breeze-7B-Instruct-v0_1
21    MediaTek-Research/Breeze-7B-Instruct-v0_1
22    MediaTek-Research/Breeze-7B-Instruct-v0_1
23    MediaTek-Research/Breeze-7B-Instruct-v0_1
24    MediaTek-Research/Breeze-7B-Instruct-v0_1
25    MediaTek-Research/Breeze-7B-Instruct-v0_1
26    MediaTek-Research/Breeze-7B-Instruct-v0_1
27    MediaTek-Research/Breeze-7B-Instruct-v0_1
28    MediaTek-Research/Breeze-7B-Instruct-v0_1
29    MediaTek-Research/Breeze-7B-Instruct-v0_1
30    MediaTek-Research/Breeze-7B-Instruct-v0_1
31    MediaTek-Research/Breeze-7B-Instruct-v0_1
32    MediaTek-Research/Breeze-7B-Instruct-v0_1
33    MediaTek-Research/Breeze-7B-Instruct-v0_1
34    MediaTek-Research/Breeze-7B-Instruct-v0_1
35    MediaTek-Research/Breeze-7B-Instruct-v0_1
36    MediaTek-Research/Breeze-7B-Instruct-v0_1
Name: LLM, dtype: object

100%|██████████| 36/36 [02:26<00:00,  3.70s/it]
100%|██████████| 36/36 [02:26<00:00,  4.07s/it]
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
34    True
35    True
36    True
dtype: bool
======
0     eetq
1     eetq
2     eetq
3     eetq
4     eetq
5     eetq
6     eetq
7     eetq
8     eetq
9     eetq
10    eetq
11    eetq
12    eetq
13    eetq
14    eetq
15    eetq
16    eetq
17    eetq
18    eetq
19    eetq
20    eetq
21    eetq
22    eetq
23    eetq
24    eetq
25    eetq
26    eetq
27    eetq
28    eetq
29    eetq
30    eetq
31    eetq
32    eetq
33    eetq
34    eetq
35    eetq
36    eetq
Name: 量化, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
34    True
35    True
36    True
dtype: bool
======
0     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
1     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
2     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
3     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
4     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
5     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
6     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
7     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
8     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
9     不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
10    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
11    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
12    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
13    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
14    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
15    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
16    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
17    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
18    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
19    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
20    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
21    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
22    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
23    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
24    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
25    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
26    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
27    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
28    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
29    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
30    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
31    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
32    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
33    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
34    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
35    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
36    不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。\n==參考文獻==\n{c...
Name: prompt_template, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
34    True
35    True
36    True
dtype: bool
======
0     infgrad/puff-base-v1
1     infgrad/puff-base-v1
2     infgrad/puff-base-v1
3     infgrad/puff-base-v1
4     infgrad/puff-base-v1
5     infgrad/puff-base-v1
6     infgrad/puff-base-v1
7     infgrad/puff-base-v1
8     infgrad/puff-base-v1
9     infgrad/puff-base-v1
10    infgrad/puff-base-v1
11    infgrad/puff-base-v1
12    infgrad/puff-base-v1
13    infgrad/puff-base-v1
14    infgrad/puff-base-v1
15    infgrad/puff-base-v1
16    infgrad/puff-base-v1
17    infgrad/puff-base-v1
18    infgrad/puff-base-v1
19    infgrad/puff-base-v1
20    infgrad/puff-base-v1
21    infgrad/puff-base-v1
22    infgrad/puff-base-v1
23    infgrad/puff-base-v1
24    infgrad/puff-base-v1
25    infgrad/puff-base-v1
26    infgrad/puff-base-v1
27    infgrad/puff-base-v1
28    infgrad/puff-base-v1
29    infgrad/puff-base-v1
30    infgrad/puff-base-v1
31    infgrad/puff-base-v1
32    infgrad/puff-base-v1
33    infgrad/puff-base-v1
34    infgrad/puff-base-v1
35    infgrad/puff-base-v1
36    infgrad/puff-base-v1
Name: 嵌入模型, dtype: object
0     True
1     True
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9     True
10    True
11    True
12    True
13    True
14    True
15    True
16    True
17    True
18    True
19    True
20    True
21    True
22    True
23    True
24    True
25    True
26    True
27    True
28    True
29    True
30    True
31    True
32    True
33    True
34    True
35    True
36    True
dtype: bool
======
0                                       如何設定Obsidian同步?
1                                       如何設定Obsidian同步?
2                                       如何設定Obsidian同步?
3                                          Ontology是什麼?
4                                           llama支援中文嗎?
5                                      在mysql中如何將多張表合併?
6                                         如何將mysql的表匯出?
7                                 什麼時候安裝了obsidian的引用外掛?
8                                              怎麼選擇端口的?
9                                       如何解決論文標題中的冒號問題?
10                                   哪些因素可能會影響語音識別的準確度?
11                                         如何微調whisper?
12                                   如何解決protégé中的顯示問題?
13                                        為甚麼系統要使用多執行緒?
14                              service worker幾秒後會自動關閉?
15          為什麼chrome-extension不能在html中直接呼叫javascript函數
16                                   ChatGPT的溫度設為多少最恰當?
17                                         嵌入有可能遇到什麼問題?
18                                   有哪些方法可以解決語音辨識的幻聽問題
19                                       語音辨識可以有哪些評估的方向
20                                     為什麼瀏覽器插件不使用pipe?
21                                       哪些因素可能會影響語音識別？
22                         我參考了哪個教學將pytorch更新到pytorch2?
23                                       bibtex和ris差在哪？
24                                     可以從論文的相關研究中得到什麼？
25                                             土豆挑戰是什麼？
26    如何解決The message port closed before a response ...
27                                    哪些python套件能監聽快捷鍵？
28                                除了pyqt外，當時還考慮哪些類似的套件？
29                                   系統中的FastAPI監聽哪個端口？
30                                          RALM類似什麼概念？
31                                        多源資料分析和管理差在哪？
32                              在2024/4/17，我看完NEUMAI了嗎？
33                                  在2024/4/17，我做了什麼實驗？
34                              在2024/4/17，我實驗過gemma了嗎?
35                  在2024/4/17，我設計完整個架構和所需要的API需求及文件了嗎？
36                                  我對ChatRTX的評價是正面還是負面
Name: query, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
30    False
31    False
32    False
33    False
34    False
35    False
36    False
dtype: bool
======
0     1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
11    1
12    1
13    1
14    1
15    1
16    1
17    1
18    1
19    1
20    1
21    1
22    1
23    1
24    1
25    1
26    1
27    1
28    1
29    1
30    1
31    1
32    1
33    1
34    1
35    1
36    1
Name: top_k, dtype: object
0     False
1     False
2     False
3     False
4     False
5     False
6     False
7     False
8     False
9     False
10    False
11    False
12    False
13    False
14    False
15    False
16    False
17    False
18    False
19    False
20    False
21    False
22    False
23    False
24    False
25    False
26    False
27    False
28    False
29    False
30    False
31    False
32    False
33    False
34    False
35    False
36    False
dtype: bool
======
0     ['chroma_similarity']
1     ['chroma_similarity']
2         chroma_similarity
3         chroma_similarity
4         chroma_similarity
5         chroma_similarity
6         chroma_similarity
7         chroma_similarity
8         chroma_similarity
9         chroma_similarity
10        chroma_similarity
11        chroma_similarity
12        chroma_similarity
13        chroma_similarity
14        chroma_similarity
15        chroma_similarity
16        chroma_similarity
17        chroma_similarity
18        chroma_similarity
19        chroma_similarity
20        chroma_similarity
21        chroma_similarity
22        chroma_similarity
23        chroma_similarity
24        chroma_similarity
25        chroma_similarity
26        chroma_similarity
27        chroma_similarity
28        chroma_similarity
29        chroma_similarity
30        chroma_similarity
31        chroma_similarity
32        chroma_similarity
33        chroma_similarity
34        chroma_similarity
35        chroma_similarity
36        chroma_similarity
Name: 檢索方法, dtype: object
None

(server) E:\Research\extension\chrome-extension>[06:00:56]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  3%|▎         | 1/36 [00:05<03:18,  5.68s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  6%|▌         | 2/36 [00:09<02:26,  4.31s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  8%|▊         | 3/36 [00:12<02:02,  3.70s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 11%|█         | 4/36 [00:15<01:55,  3.60s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 14%|█▍        | 5/36 [00:18<01:47,  3.48s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 17%|█▋        | 6/36 [00:21<01:41,  3.37s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 19%|█▉        | 7/36 [00:26<01:49,  3.77s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 22%|██▏       | 8/36 [00:29<01:43,  3.69s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 25%|██▌       | 9/36 [00:33<01:34,  3.51s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 28%|██▊       | 10/36 [00:36<01:28,  3.41s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 31%|███       | 11/36 [00:40<01:28,  3.55s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 33%|███▎      | 12/36 [00:44<01:29,  3.72s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 36%|███▌      | 13/36 [00:50<01:40,  4.38s/it]嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-06.md
# 1. 安裝 [[praat]]

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.057200395
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-03.md
>In computing, an ontology is then a concrete, formal representation—a convention—on what terms mean within the scope in which they are used (e.g., a given domain). Like all conventions, the usefulness of an ontology depends on how broadly and consistently it is adopted and how detailed it is. Knowledge graphs that use a shared ontology will be more interoperable. Given that ontologies are formal representations, they can further be used to

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-28.md
# 2. 論文整理及概覽
[[OntoLTCn： A Chinese Text Oriented Semi-auto Ontology Knowledge Discovery Tool|OntoLTCn: A Chinese Text Oriented Semi-auto Ontology Knowledge Discovery Tool]]  
[[Approximate Reasoning for Large-Scale ABox in OWL DL Based on Neural-Symbolic Learning]]  
张异卓, 周璐, 孙燕, 郑丰杰, 徐凤芹及李宇航. 「辨证论治思想指导下的中医主题词自动标引模型构建」. 中国中医药信息杂志 29, 期 8 (2022年): 18–23. https://doi.org/10.19879/j.cnki.1005-5304.202109202.

==問題==
根據上文，Ontology是什麼?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2588572
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-07.md
# 2. 測試[[LLaMA2]]
中文支援不佳，嘗試使用中文微調專案[[Chinese-LLaMA-Alpaca-2]]
及webui專案[[text-generation-webui]]
設定參考[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh)
- 須解決簡體中文的問題

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-22.md
# 5. 試用 [[Obsidian-copilot]] 及 [[obsidian-smart-connections]]
- 都不太支援中文，要想辦法

==問題==
根據上文，llama支援中文嗎?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1619676
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]三表[[join]]
``` mysql
SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` FROM `standard_symptoms_table` as A RIGHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;
```

==問題==
根據上文，在mysql中如何將多張表合併?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.32915065
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]三表[[join]]
``` mysql
SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` FROM `standard_symptoms_table` as A RIGHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;
```

==問題==
根據上文，如何將mysql的表匯出?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1116085
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-06.md
# 4. 在引用上實在很不方便，找了一些別的插件
http://ob-plugin.eryajf.net/#/ob-plugin/01.Obsidian%E6%8F%92%E4%BB%B6%E5%91%A8%E5%88%8A%E7%AC%AC%E4%B8%80%E6%9C%9F

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-30.md
# 1. 幫宿舍電腦安裝引用套件[[obsidian-citation-plugin]]
步驟如[[Github project/obsidian-citation-plugin|obsidian-citation-plugin]]中所寫

==問題==
根據上文，什麼時候安裝了obsidian的引用外掛?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.11549372
float32
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 39%|███▉      | 14/36 [00:53<01:28,  4.00s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 42%|████▏     | 15/36 [00:59<01:37,  4.62s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 44%|████▍     | 16/36 [01:02<01:24,  4.23s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 47%|████▋     | 17/36 [01:06<01:20,  4.26s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 50%|█████     | 18/36 [01:10<01:11,  3.96s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 53%|█████▎    | 19/36 [01:13<01:03,  3.75s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 56%|█████▌    | 20/36 [01:16<00:55,  3.46s/it]Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 4. 如何選擇port?
參考[^2] ，選擇沒人佔用的27709  
[^1]: https://stackoverflow.com/questions/42631509/piping-node-js-to-python
[^2]: https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=27709

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 3. 關於瀏覽器插件的溝通方式選擇
pipe or websocket
選擇websocket，因為javascript無法操作作業系統層級的pipe
查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe
理論上也確實如此，否則瀏覽器插件的權限很容易太大

==問題==
根據上文，怎麼選擇端口的?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.35214102
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-21.md
# 4. 開會
- 冒號問題，如果資訊比較不重要可以刪除
- 或者用減號、全形冒號等
```
▸標籤管理實作
▸PDF抽取方法實驗及整理
▸s2orc-doc2json、 grobid
▸文獻閱讀: Too many tags spoil the metadata: investigating the knowledge management of scientific research with semantic web technologies(2019)
▸其他: 冒號問題
```

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-21.md
# 4. 考量windows檔案名稱問題
https://stackoverflow.com/questions/10386344/how-to-get-a-file-in-windows-with-a-colon-in-the-filename
想辦法讓windows檔案名稱能支援論文標題。
[Automatically convert colons in {{title}} to other symbols, such as "-"](https://github.com/hans/obsidian-citation-plugin/issues/89)
#研究/feature

==問題==
根據上文，如何解決論文標題中的冒號問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.1906288
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-28.md
# 1. 關於語音辨識準確度
![[Automatic Speech Recognition#關於準確度]]

==問題==
根據上文，哪些因素可能會影響語音識別的準確度?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16114116
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 999. 靈感
- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  
[^1]: https://ithelp.ithome.com.tw/articles/10340284
[^2]: https://github.com/huggingface/text-generation-inference/issues/1201

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-11-02.md
# 2. 關於 [[whisper]] 的術語問題
[這裡](https://stackoverflow.com/questions/73833916/how-can-i-give-some-hint-phrases-to-openais-whisper-asr)

==問題==
根據上文，如何微調whisper?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.106168725
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-03.md
# 2. 重新點一次view裡面的顯示prefix才能正常顯示

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-24.md
- 多次運行的結果相同，但與我自己組起來的prompt結果不同，~~猜測是generate_prompt的問題~~ 是prompt格式的問題
- 參考[這篇](https://stackoverflow.com/questions/77625508/how-to-activate-verbosity-in-langchain)提到可以用 `from langchain.globals import set_debug` 來debug
- 修改HF_HUB_CACHE並使用 `$sudo chmod a+rwx -R ./` 將TGI的模型檔與transformers共用
- 跑完TAIDE的message、transformers、手動prompt三種實驗
- message和手動Prompt可以相同，但huggingface不行，感覺是generate_prompt的問題

==問題==
根據上文，如何解決protégé中的顯示問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2692792
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-16.md
`mklink "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\make.exe" "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\mingw32-make.exe"`
- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`
- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性
- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要
- [ ] 整理文獻
- [ ] 閱讀清單

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-15.md
# 999. 靈感
- 需要考慮subprocess執行時執行較慢的問題
- 未來可以考慮包裝方便性，例如將虛擬環境改成venv，並以資料夾保存，可參考 [[stable-diffusion-webui]]
-

==問題==
根據上文，為甚麼系統要使用多執行緒?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.008740316
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-25.md
# 3. 根據chrome extensione官方說明，30秒會自動將service worker關閉，因此採用25秒一次的心跳來解決這個問題[^1]
- 之後如果確認後端不會主動傳訊息給SW，則可以考慮改為http ( 只要修改send函數應該就行了 )

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-15.md
- 感覺不是純粹切視窗或關視窗的問題，也許跟省電或其他的websocket管理有關

==問題==
根據上文，service worker幾秒後會自動關閉?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.19715488
float32
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 58%|█████▊    | 21/36 [01:19<00:50,  3.34s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 61%|██████    | 22/36 [01:21<00:43,  3.10s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 64%|██████▍   | 23/36 [01:24<00:39,  3.02s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 67%|██████▋   | 24/36 [01:28<00:40,  3.35s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 69%|██████▉   | 25/36 [01:31<00:35,  3.20s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 72%|███████▏  | 26/36 [01:34<00:30,  3.05s/it]Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-28.md
# 9. 關於chrome-extension中不允許在html中直接呼叫javascript函數
- 因為chrome-extension不允許CSP
- 但好像可以用[這個](https://stackoverflow.com/questions/72186787/chrome-extensions-and-csp)允許特定網站的CSP?

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-04.md
- <class 'str'>不行，<class 'bytes'>才對
- 交叉比對
- 另外開一個.py，避免非同步之類的問題
- 就算在字串前加上u也沒用
-
- 和[這個](https://stackoverflow.com/questions/34618149/post-unicode-string-to-web-service-using-python-requests-library)情況有點類似
- 實際原因是，requests針對text類的body，會自動使用ISO-8859-1編碼[^1]
- 但實測將content-type改成 `text/markdown; charset=UTF-8` 也不行
- github上同樣有人提出，但requests目前處於盡量不修改的狀況，因此雖然python3的整個生態都使用utf-8，但仍建議在requests時使用.encode("utf-8")轉成byte來傳送處理[^2]

==問題==
根據上文，為什麼chrome-extension不能在html中直接呼叫javascript函數
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.109264515
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-13.md
# 4. 閱讀論文
- 在這篇[^4] 論文中提到，實驗中為了在最小化幻覺和嚴格生成之間取得平衡，將GPT的溫度設為0，llama的溫度設為0.1，但論文中未提及更詳細的理由

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
endpoint _url=" http://localhost:8080/" ,
cache = False,
max _new_tokens=256,
do _sample=False, # 關閉採樣
top _k=1,
top _p=0.99,
temperature=0.1, # 已經關閉採樣了所以其實設多少都沒差
)
```
```
chat_completion = client.chat.completions.create(
messages=message_list,
temperature=0,
max_tokens=256,
)
```
- 實驗證明
1. langchain的chat就算設定do_sample為False也不是完全貪婪，尤其top_k是必要的
2. 以上的參數可以使結果相同
3. 雖然相關討論的結論認為關鍵在do_sample + temperature=None[^2]，但直覺上我覺得top_k也行

==問題==
根據上文，ChatGPT的溫度設為多少最恰當?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.20829745
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-22.md
# 999. 其他
- How can we evaluate the ability of each LLM to generate Cypher?
- tag嵌套的必要性
- markdown的結構化 #靈感
- 例如tab代表有
- 可能要重新考慮nDCG來比對[[Embeddeding|嵌入]]結果
- 可能要檢查 [[Mean Average Precision|MAP]] 的算法是否有誤
- 以前不熟悉的關鍵字會慢慢熟悉，要怎麼應對這種情況? #靈感
[^1]: https://github.com/microsoft/terminal/issues/14018
[^2]: https://stackoverflow.com/questions/32127524/how-to-install-and-use-make-in-windows

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-01-13.md
# 4. 沒找到什麼特別有用的免費嵌入方式

==問題==
根據上文，嵌入有可能遇到什麼問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.090603866
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-16.md
# 1. [[Whisper]]
嘗試解決幻覺問題
https://github.com/openai/whisper/discussions/679
加上參數--condition_on_previous_text False  
##  評估方式?
根據不同面向，例如冗字、專有名詞，其他錯誤等  
又加了一堆論文哈哈

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-05.md
# 4. 測試[[SpeechRecognition]]
建立虛擬環境並安裝此套件，
clone範例程式<https://github.com/Uberi/speech_recognition/blob/master/examples/microphone_recognition.py>
1. 實驗[[Sphinx]]及[[Google Speech Recognition]]兩個語音辨識API
安裝pocketsphinx
2. 實驗background_listening
1. 安裝[[PyAudio]]
結論: 在中文精準度上需要多測試，可能要找找看[[機器學習]]方面的辨識方法。

==問題==
根據上文，有哪些方法可以解決語音辨識的幻聽問題
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16820273
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-19.md
# 今日計畫
- [ ] 論文整理
- [ ] 語音助理技術進展
- [ ] 基於[[Knowledge Base]]的GPT似乎已存在了，檢查相關方法
https://www.bilibili.com/video/BV19o4y1J7mL/?spm_id_from=333.788.recommend_more_video.18&vd_source=591675bcd42bc693ef34911801b34eb2
- [ ] 將上課或會議內容錄音後，藉由語音辨識產生知識本體的可能性
- [ ] 比較不同降噪間的逐字稿結果是否不同
- [ ] 有沒有比較高效或公正的檢查標準?
- [ ] 不同模型
- [ ] sentence to triple的技術

==問題==
根據上文，語音辨識可以有哪些評估的方向
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.071613215
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 3. 關於瀏覽器插件的溝通方式選擇
pipe or websocket
選擇websocket，因為javascript無法操作作業系統層級的pipe
查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe
理論上也確實如此，否則瀏覽器插件的權限很容易太大

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-11.md
# 3. Vosk使用測試
![[Vosk#0910實驗記錄]]
#筆記用標籤/疑問 為什麼使用pip安裝後就可以使用command line tool?

==問題==
根據上文，為什麼瀏覽器插件不使用pipe?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2258542
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-28.md
# 1. 關於語音辨識準確度
![[Automatic Speech Recognition#關於準確度]]

==問題==
根據上文，哪些因素可能會影響語音識別？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.26710048
float32
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 75%|███████▌  | 27/36 [01:36<00:26,  2.90s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 78%|███████▊  | 28/36 [01:39<00:22,  2.80s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 81%|████████  | 29/36 [01:43<00:21,  3.08s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 83%|████████▎ | 30/36 [01:46<00:18,  3.06s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 86%|████████▌ | 31/36 [01:48<00:14,  2.91s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 89%|████████▉ | 32/36 [01:51<00:11,  2.80s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 92%|█████████▏| 33/36 [01:53<00:08,  2.74s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 94%|█████████▍| 34/36 [01:56<00:05,  2.68s/it]Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-30.md
# 3. 將宿舍電腦的 StableDiffusion 虛擬環境中的 [[pytorch]] 更新到pytorch2[^1]
1. 切換到虛擬環境
`.\envs\scripts\activate.bat`
2. 檢查pip路徑
`pip --version`
3. 參考[官網](https://pytorch.org/get-started/locally/)訊息，CUDA11.8
`pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`
4. 結果
```
Installing collected packages: mpmath, sympy, torch, torchvision, torchaudio
Attempting uninstall: torch
Found existing installation: torch 1.13.1+cu117

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-27.md
# 4. 嘗試[[ChatPaper2Xmind]]
參考README
```
git clone git@github.com:MasterYip/ChatPaper2Xmind.git
pip install -r requirements.txt
git submodule update --init --recursive
```
設定config.py，包含API key及LANGUAGE = "Chinese"
python paper2xmind.py  
報錯:
```
You exceeded your current quota, please check your plan and billing details.
```
ChatGPT要付錢啦嗚嗚嗚

==問題==
根據上文，我參考了哪個教學將pytorch更新到pytorch2?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.3263341
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-28.md
# 999. 靈感  
[^1]: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=key1YF/record?r1=16&h1=0
[^2]: https://aws.amazon.com/tw/compare/the-difference-between-grpc-and-rest/

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-20.md
# 999. 靈感
- 在[這篇](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/discussions/82)討論區中提到，幫選擇題加上「以上皆非」是一個不錯的想法
- 關於比較模型的部分，可以用比較的方式  
[^6]: https://medium.com/%E5%BD%BC%E5%BE%97%E6%BD%98%E7%9A%84-swift-ios-app-%E9%96%8B%E7%99%BC%E5%95%8F%E9%A1%8C%E8%A7%A3%E7%AD%94%E9%9B%86/%E7%94%A8%E8%80%81%E5%B8%AB-%E5%AD%B8%E7%94%9F%E8%BA%AB%E4%BB%BD%E5%85%8D%E8%B2%BB%E4%BD%BF%E7%94%A8-github-copilot-223236e0e0e8

==問題==
根據上文，bibtex和ris差在哪？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.4384315
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-11-23.md
# 2. 研究過程中，除了這個研究的貢獻外，在相關研究中也可以得到很多資訊
可以在筆記中包含，提到這篇研究的研究、該研究中的說明、評價、引用編號等
#靈感

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-01-10.md
# 1. [閱讀筆記](https://blog.csdn.net/Delusional/article/details/109186531)
- 讀完一篇論文後可以用表格等方式將論文的內容簡單紀錄，包含以下資訊:
1. 來源
2. 研究機構Institution
3. 論文Paper
4. 關鍵字Topic
5. 目標Aim
6. 研究問題Problem to solve
7. 解決方法Solutions
8. 阻礙?Strength
9. 限制
10. 資料集
11. 評估分數Evaluation Score
12. 程式碼

==問題==
根據上文，可以從論文的相關研究中得到什麼？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.44338506
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-01-13.md
問題：請介紹這篇論文
回答：
這篇論文介紹了一個學術知識圖譜問答（KGQA）系統，該系統利用大型語言模型（LLM）以few-shot方式回答文獻資料庫中的自然語言問題。該模型通過一個基於BERT的句子編碼器識別與測試問題相關的前n個相似訓練問題，並檢索它們對應的SPARQL查詢語句。使用這些相似問題-SPARQL對作為示例，與測試問題一起創建一個提示語句，然後將提示語句傳遞給LLM進行SPARQL生成。最後，運行SPARQL查詢以對應的學術知識圖譜進行查詢，並返回答案。這個系統在SciQA測試集上達到了99.0\%的F1分數，是Scholarly-QALD-23挑戰賽SciQA排行榜的亞軍。
```
```
(myLLM) domaj@Domaj-server:~/Research/myLLM$ python step2.query.py
Distance: [[0.49441427 0.5016975  0.50322545 0.5052259  0.51162815]]

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-04.md
# 2. 找時間測試pizza.owl
- [ ] 找時間測試pizza.owl (@2023-10-27)

==問題==
根據上文，土豆挑戰是什麼？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1314348
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-08.md
# 1. 撰寫chrome extension
- 關於popus.js和background.js的溝通
- 遇到錯誤 `Unchecked runtime.lastError: The message port closed before a response was received.`
- 經過正確的使用sendmessage的callback的第三個參數sendResponse完成完整的溝通。
- 準確的說是service-worker，因為在版本三中並沒有background page的存在，而是改為service worker。
- 同上，有很多用法在第二版可以用，但在第三版不能用。

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 5. bug
1. DOMException: Failed to execute 'send' on 'WebSocket': Still in CONNECTING state.
[參考](https://stackoverflow.com/questions/23051416/uncaught-invalidstateerror-failed-to-execute-send-on-websocket-still-in-co)將傳送訊息函數包在open=>{}中，確保傳送訊息前已經建立好連線

==問題==
根據上文，如何解決The message port closed before a response was received
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.062017523
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-22.md
- 註: daemon關閉時會強制關閉，若有讀寫檔、暫存檔等需要額外處理，例如在主thread中捕捉相關的事件。  
- ChatGPT用模擬ctrl+c的方式實現自訂義複製快捷鍵，我喜歡
- 本來無法模擬ctrl+c，後來發現是因為模擬前沒有放開實體按鍵，使用time.sleep或keyboard.release都能解決這個問題，也不需要管理員權限  
- 讀取當前焦點視窗
- 暫時先考慮windows，不考慮mac和linux，因此使用pywin32  
- [[cypher]] 的參數化查詢無法用於標籤或關係上，因此需要使用python的格式化輸入來處理
`query = f"MATCH (n:{tagName})"`

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-13.md
# 5. [[FastAPI]]
- Python的酷套件，要找時間把系統改成這個

==問題==
根據上文，哪些python套件能監聽快捷鍵？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2724631
float32
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 97%|█████████▋| 35/36 [01:59<00:02,  2.83s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

100%|██████████| 36/36 [02:02<00:00,  2.86s/it]
100%|██████████| 36/36 [02:02<00:00,  3.41s/it]
Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-16.md
`mklink "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\make.exe" "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\mingw32-make.exe"`
- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`
- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性
- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要
- [ ] 整理文獻
- [ ] 閱讀清單

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-25.md
# 1. PyQt的多執行緒
- 用單獨的thread管理PyQt
- 用threading.event來觸發顯示
- 用global參數來修改內容?

==問題==
根據上文，除了pyqt外，當時還考慮哪些類似的套件？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.14854458
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-16.md
# 999. 其他
- 根據FastAPI的文檔，建議使用Union來取代Optional功能，但範例中有點錯誤
- 建議避免使用 `name: Optional[str]`，因為實際上name並不是可選的而是必選的
- 就算使用 `def say_hi(name: str | None)` 也不代表不需要參數，必須要設定初始值，如 `def say_hi(name: str | None = None)`  
[^1]: https://stackoverflow.com/questions/63872924/how-can-i-send-an-http-request-from-my-fastapi-app-to-another-site-api
[^2]: https://scrapfly.io/blog/httpx-vs-requests-vs-aiohttp/

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-16.md
# 1. 系統
- neo4j
- 根據[官方教學](https://neo4j.com/docs/operations-manual/current/configuration/connectors/) 修改neo4j的監聽ip讓台北電腦測試neo4j chain

==問題==
根據上文，系統中的FastAPI監聽哪個端口？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.28215396
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
- [ ] [NEUMAI](https://docs.neum.ai/get-started/introduction)  
- [ ] 待實驗
- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/
- [ ] GEMMA
- [ ] [[HyDE]]
- [ ] LLM的上下文與few-shot
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典

==問題==
根據上文，RALM類似什麼概念？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.04661884
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-11.md
# 1. 修改論文
- Multi-Source Data Analysis與Multi-source infomation management system
- 多源資料分析主要注重統合、轉換、除錯並分析資料
- 多源資訊管理主要目的在蒐集與管理資訊

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

==問題==
根據上文，多源資料分析和管理差在哪？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.06321003
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-18.md
[^10]: https://community.neo4j.com/t/import-individuals-and-relate-to-classes-in-neo4j/24567/2

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-09.md
# 1. 閱讀文獻
- 看完並整理Dai, Zhuyun, Vincent Y. Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov, Kelvin Guu, Keith B. Hall及Ming-Wei Chang. 「Promptagator: Few-Shot Dense Retrieval From 8 Examples」. arXiv, 2022年9月23日. [https://doi.org/10.48550/arXiv.2209.11755](https://doi.org/10.48550/arXiv.2209.11755).

==問題==
根據上文，在2024/4/17，我看完NEUMAI了嗎？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2960534
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-24.md
# 1. [[Whisper-Finetune]]
![[Whisper-Finetune#0924實驗]]

==問題==
根據上文，在2024/4/17，我做了什麼實驗？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.0678077
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-14.md
- TAIDE-llama3
- nf4: 01:05，可filter
- eetq: 01:06, 可filter
- 實驗mistral-7B的fine-tune，MediaTek-Research/Breeze-7B-Instruct-v0_1
- eetq: 基礎測試34秒，通過魔法測驗、
-

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-18.md
# 0. 今日計畫
- [ ] 整理文獻
- [ ] 待實驗
- [ ] GEMMA
- [ ] [[HyDE]]
- [ ] LLM的上下文與few-shot
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典
- 教育版copilot，要印英文在校證明[^6]

==問題==
根據上文，在2024/4/17，我實驗過gemma了嗎?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.10619263
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-07.md
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-18.md
# 0. 今日計畫
- [ ] 整理文獻
- [ ] 待實驗
- [ ] GEMMA
- [ ] [[HyDE]]
- [ ] LLM的上下文與few-shot
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典
- 教育版copilot，要印英文在校證明[^6]

==問題==
根據上文，在2024/4/17，我設計完整個架構和所需要的API需求及文件了嗎？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.12266735
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-17.md
# 2. 試用 [[Chat RTX]]
- 38G，好大
- 下載好久，安裝好久，安裝一個多小時吧，包含下載模型的時間
- 吃爆VRAM、反應不快，基本只收英文
- 因為很卡所以沒有繼續測試下去  
[^3]: https://www.volcengine.com/theme/3863827-W-7-1
[^4]: https://www.pythonforbeginners.com/basics/convert-ini-to-yaml-in-python
[^5]: https://docs.privategpt.dev/recipes/choice-of-llm/list-of-ll-ms

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-07.md
# 2. 發現 [[Chat RTX]]
- 中文能力不佳
- 與研究著重在API不同

==問題==
根據上文，我對ChatRTX的評價是正面還是負面
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.056782953
float32
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-21.md
# 2. 跑實驗
- google/gemma-2b-it
- 約20分鐘
- google/gemma-2b
- 約20分鐘
- meta-llama/Llama-2-7b-chat-hf
- 約一小時

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

==問題==
根據上文，在2024/4/21，我總共花了幾分鐘跑實驗
請用20個字簡潔回答問題。

None

(server) E:\Research\extension\chrome-extension>[06:07:59]python -m modules.rag

Generating train split: 0 examples [00:00, ? examples/s]
Generating train split: 51 examples [00:00, 5666.03 examples/s]

Filter:   0%|          | 0/51 [00:00<?, ? examples/s]
Filter: 100%|██████████| 51/51 [00:00<00:00, 3399.98 examples/s]

Filter:   0%|          | 0/38 [00:00<?, ? examples/s]
Filter: 100%|██████████| 38/38 [00:00<00:00, 2923.24 examples/s]

  0%|          | 0/36 [00:00<?, ?it/s]
  0%|          | 0/36 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 793, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 537, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connection.py", line 466, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 1378, in getresponse
    response.begin()
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 847, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\util\retry.py", line 470, in increment
    raise reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 793, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connectionpool.py", line 537, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\urllib3\connection.py", line 466, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 1378, in getresponse
    response.begin()
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\http\client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 116, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 99, in eval
    result = self.query(query)
             ^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 21, in query
    self.embedded()
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 45, in embedded
    self.embedded_obj = embedded(model_name=self.embedded_model_name)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 34, in __init__
    self.model_info = self.set_embedded_model(model_id=model_name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\embedded.py", line 79, in set_embedded_model
    response = requests.get(
               ^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
嵌入模型載入中...

(server) E:\Research\extension\chrome-extension>[06:11:06]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  0%|          | 0/36 [00:09<?, ?it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 116, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 99, in eval
    result = self.query(query)
             ^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 27, in query
    answer_text = self.generate_answer(query, context, model_name=self.config["llm_model"])
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 79, in generate_answer
    llm_result = self.llm.chat(input=prompt, system_message="")
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\llm.py", line 46, in chat
    response = chat.invoke(message_list)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 170, in invoke
    self.generate_prompt(
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 599, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 456, in generate
    raise e
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 446, in generate
    self._generate_with_cache(
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 671, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_openai\chat_models\base.py", line 522, in _generate
    response = self.client.create(messages=message_dicts, **params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_utils\_utils.py", line 277, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\resources\chat\completions.py", line 579, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 1240, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 921, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 1020, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt4o` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-07-24.md\n# 新增宿舍的筆記同步\n1. 參考[[Git指令]]，新增ssh key\n2. 使用ssh -T測試OK\n3. 用[[git clone]]將整份筆記下載\n4. 在Obsidian中開啟vault\n5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)\n6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題\n7. 使用以下指令重製ssh-key密碼為空\n```\nssh-keygen -p -f github_key\n```\n8. 重製為空後即可正常使用\n註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-07-24.md', '標題1': '新增宿舍的筆記同步'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-10-06.md\n# 1. 安裝 [[praat]]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-10-06.md', '標題1': '1. 安裝 [[praat]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-06.md
# 1. 安裝 [[praat]]

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。


(server) E:\Research\extension\chrome-extension>[06:13:48]pip install -U langchain-core
Requirement already satisfied: langchain-core in d:\programdata\anaconda3\envs\server\lib\site-packages (0.2.0)
Collecting langchain-core
  Downloading langchain_core-0.2.1-py3-none-any.whl.metadata (5.9 kB)
Requirement already satisfied: PyYAML>=5.3 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-core) (6.0.1)
Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-core) (1.33)
Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-core) (0.1.60)
Requirement already satisfied: packaging<24.0,>=23.2 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-core) (23.2)
Requirement already satisfied: pydantic<3,>=1 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-core) (2.6.4)
Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langchain-core) (8.3.0)
Requirement already satisfied: jsonpointer>=1.9 in d:\programdata\anaconda3\envs\server\lib\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.4)
Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core) (3.10.0)
Requirement already satisfied: requests<3,>=2 in d:\programdata\anaconda3\envs\server\lib\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core) (2.31.0)
Requirement already satisfied: annotated-types>=0.4.0 in d:\programdata\anaconda3\envs\server\lib\site-packages (from pydantic<3,>=1->langchain-core) (0.6.0)
Requirement already satisfied: pydantic-core==2.16.3 in d:\programdata\anaconda3\envs\server\lib\site-packages (from pydantic<3,>=1->langchain-core) (2.16.3)
Requirement already satisfied: typing-extensions>=4.6.1 in d:\programdata\anaconda3\envs\server\lib\site-packages (from pydantic<3,>=1->langchain-core) (4.10.0)
Requirement already satisfied: charset-normalizer<4,>=2 in d:\programdata\anaconda3\envs\server\lib\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in d:\programdata\anaconda3\envs\server\lib\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core) (3.6)
Requirement already satisfied: urllib3<3,>=1.21.1 in d:\programdata\anaconda3\envs\server\lib\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core) (2.2.1)
Requirement already satisfied: certifi>=2017.4.17 in d:\programdata\anaconda3\envs\server\lib\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core) (2024.2.2)
Downloading langchain_core-0.2.1-py3-none-any.whl (308 kB)
   -------------------------------------- 308.5/308.5 kB 795.4 kB/s eta 0:00:00
Installing collected packages: langchain-core
  Attempting uninstall: langchain-core
    Found existing installation: langchain-core 0.2.0
    Uninstalling langchain-core-0.2.0:
      Successfully uninstalled langchain-core-0.2.0
Successfully installed langchain-core-0.2.1

(server) E:\Research\extension\chrome-extension>[06:13:57]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  0%|          | 0/36 [00:05<?, ?it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 116, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 99, in eval
    result = self.query(query)
             ^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 27, in query
    answer_text = self.generate_answer(query, context, model_name=self.config["llm_model"])
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 79, in generate_answer
    llm_result = self.llm.chat(input=prompt, system_message="")
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\llm.py", line 46, in chat
    response = chat.invoke(message_list)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 170, in invoke
    self.generate_prompt(
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 599, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 456, in generate
    raise e
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 446, in generate
    self._generate_with_cache(
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 671, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_openai\chat_models\base.py", line 522, in _generate
    response = self.client.create(messages=message_dicts, **params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_utils\_utils.py", line 277, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\resources\chat\completions.py", line 579, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 1240, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 921, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 1020, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt4o` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-07-24.md\n# 新增宿舍的筆記同步\n1. 參考[[Git指令]]，新增ssh key\n2. 使用ssh -T測試OK\n3. 用[[git clone]]將整份筆記下載\n4. 在Obsidian中開啟vault\n5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)\n6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題\n7. 使用以下指令重製ssh-key密碼為空\n```\nssh-keygen -p -f github_key\n```\n8. 重製為空後即可正常使用\n註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-07-24.md', '標題1': '新增宿舍的筆記同步'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-10-06.md\n# 1. 安裝 [[praat]]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-10-06.md', '標題1': '1. 安裝 [[praat]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-06.md
# 1. 安裝 [[praat]]

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。


(server) E:\Research\extension\chrome-extension>[06:15:36]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  3%|▎         | 1/36 [00:06<03:36,  6.20s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  6%|▌         | 2/36 [00:10<02:44,  4.84s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  8%|▊         | 3/36 [00:13<02:15,  4.09s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 11%|█         | 4/36 [00:16<02:01,  3.78s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 14%|█▍        | 5/36 [00:19<01:46,  3.45s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 17%|█▋        | 6/36 [00:22<01:39,  3.33s/it]嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-07-24.md\n# 新增宿舍的筆記同步\n1. 參考[[Git指令]]，新增ssh key\n2. 使用ssh -T測試OK\n3. 用[[git clone]]將整份筆記下載\n4. 在Obsidian中開啟vault\n5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)\n6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題\n7. 使用以下指令重製ssh-key密碼為空\n```\nssh-keygen -p -f github_key\n```\n8. 重製為空後即可正常使用\n註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-07-24.md', '標題1': '新增宿舍的筆記同步'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-10-06.md\n# 1. 安裝 [[praat]]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-10-06.md', '標題1': '1. 安裝 [[praat]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-06.md
# 1. 安裝 [[praat]]

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.057200395
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-03.md\n>In computing, an ontology is then a concrete, formal representation—a convention—on what terms mean within the scope in which they are used (e.g., a given domain). Like all conventions, the usefulness of an ontology depends on how broadly and consistently it is adopted and how detailed it is. Knowledge graphs that use a shared ontology will be more interoperable. Given that ontologies are formal representations, they can further be used to', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-03.md', '標題1': '1. 釐清知識本體和知識圖譜的差別'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-07-28.md\n# 2. 論文整理及概覽\n[[OntoLTCn： A Chinese Text Oriented Semi-auto Ontology Knowledge Discovery Tool|OntoLTCn: A Chinese Text Oriented Semi-auto Ontology Knowledge Discovery Tool]]  \n[[Approximate Reasoning for Large-Scale ABox in OWL DL Based on Neural-Symbolic Learning]]  \n张异卓, 周璐, 孙燕, 郑丰杰, 徐凤芹及李宇航. 「辨证论治思想指导下的中医主题词自动标引模型构建」. 中国中医药信息杂志 29, 期 8 (2022年): 18–23. https://doi.org/10.19879/j.cnki.1005-5304.202109202.', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-07-28.md', '標題1': '2. 論文整理及概覽'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-03.md
>In computing, an ontology is then a concrete, formal representation—a convention—on what terms mean within the scope in which they are used (e.g., a given domain). Like all conventions, the usefulness of an ontology depends on how broadly and consistently it is adopted and how detailed it is. Knowledge graphs that use a shared ontology will be more interoperable. Given that ontologies are formal representations, they can further be used to

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-28.md
# 2. 論文整理及概覽
[[OntoLTCn： A Chinese Text Oriented Semi-auto Ontology Knowledge Discovery Tool|OntoLTCn: A Chinese Text Oriented Semi-auto Ontology Knowledge Discovery Tool]]  
[[Approximate Reasoning for Large-Scale ABox in OWL DL Based on Neural-Symbolic Learning]]  
张异卓, 周璐, 孙燕, 郑丰杰, 徐凤芹及李宇航. 「辨证论治思想指导下的中医主题词自动标引模型构建」. 中国中医药信息杂志 29, 期 8 (2022年): 18–23. https://doi.org/10.19879/j.cnki.1005-5304.202109202.

==問題==
根據上文，Ontology是什麼?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2588572
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-07.md\n# 2. 測試[[LLaMA2]]\n中文支援不佳，嘗試使用中文微調專案[[Chinese-LLaMA-Alpaca-2]]\n及webui專案[[text-generation-webui]]\n設定參考[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh)\n- 須解決簡體中文的問題', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-07.md', '標題1': '2. 測試[[LLaMA2]]'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-22.md\n# 5. 試用 [[Obsidian-copilot]] 及 [[obsidian-smart-connections]]\n- 都不太支援中文，要想辦法', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-22.md', '標題1': '5. 試用 [[Obsidian-copilot]] 及 [[obsidian-smart-connections]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-07.md
# 2. 測試[[LLaMA2]]
中文支援不佳，嘗試使用中文微調專案[[Chinese-LLaMA-Alpaca-2]]
及webui專案[[text-generation-webui]]
設定參考[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh)
- 須解決簡體中文的問題

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-22.md
# 5. 試用 [[Obsidian-copilot]] 及 [[obsidian-smart-connections]]
- 都不太支援中文，要想辦法

==問題==
根據上文，llama支援中文嗎?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1619676
float32
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 19%|█▉        | 7/36 [00:25<01:32,  3.21s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 22%|██▏       | 8/36 [00:29<01:34,  3.38s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 25%|██▌       | 9/36 [00:32<01:27,  3.24s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 28%|██▊       | 10/36 [00:35<01:21,  3.15s/it][Document(page_content="來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md\n# [[MySQL]]匯出檔案\n參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join\n``` mysql\nmysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG\nHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;", metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md', '標題1': '[[MySQL]]匯出檔案'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md\n# [[MySQL]]三表[[join]]\n``` mysql\nSELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` FROM `standard_symptoms_table` as A RIGHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;\n```', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md', '標題1': '[[MySQL]]三表[[join]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]三表[[join]]
``` mysql
SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` FROM `standard_symptoms_table` as A RIGHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;
```

==問題==
根據上文，在mysql中如何將多張表合併?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.32915065
float32
[Document(page_content="來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md\n# [[MySQL]]匯出檔案\n參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join\n``` mysql\nmysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG\nHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;", metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md', '標題1': '[[MySQL]]匯出檔案'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md\n# [[MySQL]]三表[[join]]\n``` mysql\nSELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` FROM `standard_symptoms_table` as A RIGHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;\n```', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md', '標題1': '[[MySQL]]三表[[join]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]三表[[join]]
``` mysql
SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` FROM `standard_symptoms_table` as A RIGHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;
```

==問題==
根據上文，如何將mysql的表匯出?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1116085
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-06.md\n# 4. 在引用上實在很不方便，找了一些別的插件\nhttp://ob-plugin.eryajf.net/#/ob-plugin/01.Obsidian%E6%8F%92%E4%BB%B6%E5%91%A8%E5%88%8A%E7%AC%AC%E4%B8%80%E6%9C%9F', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-06.md', '標題1': '4. 在引用上實在很不方便，找了一些別的插件'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-30.md\n# 1. 幫宿舍電腦安裝引用套件[[obsidian-citation-plugin]]\n步驟如[[Github project/obsidian-citation-plugin|obsidian-citation-plugin]]中所寫', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-30.md', '標題1': '1. 幫宿舍電腦安裝引用套件[[obsidian-citation-plugin]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-06.md
# 4. 在引用上實在很不方便，找了一些別的插件
http://ob-plugin.eryajf.net/#/ob-plugin/01.Obsidian%E6%8F%92%E4%BB%B6%E5%91%A8%E5%88%8A%E7%AC%AC%E4%B8%80%E6%9C%9F

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-30.md
# 1. 幫宿舍電腦安裝引用套件[[obsidian-citation-plugin]]
步驟如[[Github project/obsidian-citation-plugin|obsidian-citation-plugin]]中所寫

==問題==
根據上文，什麼時候安裝了obsidian的引用外掛?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.11549372
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md\n# 4. 如何選擇port?\n參考[^2] ，選擇沒人佔用的27709  \n[^1]: https://stackoverflow.com/questions/42631509/piping-node-js-to-python\n[^2]: https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=27709', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md', '標題1': '4. 如何選擇port?'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md\n# 3. 關於瀏覽器插件的溝通方式選擇\npipe or websocket\n選擇websocket，因為javascript無法操作作業系統層級的pipe\n查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe\n理論上也確實如此，否則瀏覽器插件的權限很容易太大', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md', '標題1': '3. 關於瀏覽器插件的溝通方式選擇'})]
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 31%|███       | 11/36 [00:37<01:16,  3.04s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 33%|███▎      | 12/36 [00:42<01:22,  3.43s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 36%|███▌      | 13/36 [00:45<01:14,  3.24s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 39%|███▉      | 14/36 [00:48<01:10,  3.21s/it]Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 4. 如何選擇port?
參考[^2] ，選擇沒人佔用的27709  
[^1]: https://stackoverflow.com/questions/42631509/piping-node-js-to-python
[^2]: https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=27709

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 3. 關於瀏覽器插件的溝通方式選擇
pipe or websocket
選擇websocket，因為javascript無法操作作業系統層級的pipe
查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe
理論上也確實如此，否則瀏覽器插件的權限很容易太大

==問題==
根據上文，怎麼選擇端口的?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.35214102
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-21.md\n# 4. 開會\n- 冒號問題，如果資訊比較不重要可以刪除\n- 或者用減號、全形冒號等\n```\n▸標籤管理實作\n▸PDF抽取方法實驗及整理\n▸s2orc-doc2json、 grobid\n▸文獻閱讀: Too many tags spoil the metadata: investigating the knowledge management of scientific research with semantic web technologies(2019)\n▸其他: 冒號問題\n```', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-21.md', '標題1': '4. 開會'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-21.md\n# 4. 考量windows檔案名稱問題\nhttps://stackoverflow.com/questions/10386344/how-to-get-a-file-in-windows-with-a-colon-in-the-filename\n想辦法讓windows檔案名稱能支援論文標題。\n[Automatically convert colons in {{title}} to other symbols, such as "-"](https://github.com/hans/obsidian-citation-plugin/issues/89)\n#研究/feature', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-21.md', '標題1': '4. 考量windows檔案名稱問題'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-21.md
# 4. 開會
- 冒號問題，如果資訊比較不重要可以刪除
- 或者用減號、全形冒號等
```
▸標籤管理實作
▸PDF抽取方法實驗及整理
▸s2orc-doc2json、 grobid
▸文獻閱讀: Too many tags spoil the metadata: investigating the knowledge management of scientific research with semantic web technologies(2019)
▸其他: 冒號問題
```

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-21.md
# 4. 考量windows檔案名稱問題
https://stackoverflow.com/questions/10386344/how-to-get-a-file-in-windows-with-a-colon-in-the-filename
想辦法讓windows檔案名稱能支援論文標題。
[Automatically convert colons in {{title}} to other symbols, such as "-"](https://github.com/hans/obsidian-citation-plugin/issues/89)
#研究/feature

==問題==
根據上文，如何解決論文標題中的冒號問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.1906288
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md\n# 3. 除了降噪外其他可能影響語音識別的因素\n#靈感/語音識別\n1. 聲道\n2. 取樣率\n3. 語速\n4. bit率', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md', '標題1': '3. 除了降噪外其他可能影響語音識別的因素'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-28.md\n# 1. 關於語音辨識準確度\n![[Automatic Speech Recognition#關於準確度]]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-28.md', '標題1': '1. 關於語音辨識準確度'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-28.md
# 1. 關於語音辨識準確度
![[Automatic Speech Recognition#關於準確度]]

==問題==
根據上文，哪些因素可能會影響語音識別的準確度?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16114116
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md\n# 999. 靈感\n- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  \n[^1]: https://ithelp.ithome.com.tw/articles/10340284\n[^2]: https://github.com/huggingface/text-generation-inference/issues/1201', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md', '標題1': '999. 靈感'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-11-02.md\n# 2. 關於 [[whisper]] 的術語問題\n[這裡](https://stackoverflow.com/questions/73833916/how-can-i-give-some-hint-phrases-to-openais-whisper-asr)', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-11-02.md', '標題1': '2. 關於 [[whisper]] 的術語問題'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 999. 靈感
- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  
[^1]: https://ithelp.ithome.com.tw/articles/10340284
[^2]: https://github.com/huggingface/text-generation-inference/issues/1201

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-11-02.md
# 2. 關於 [[whisper]] 的術語問題
[這裡](https://stackoverflow.com/questions/73833916/how-can-i-give-some-hint-phrases-to-openais-whisper-asr)

==問題==
根據上文，如何微調whisper?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.106168725
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-10-03.md\n# 2. 重新點一次view裡面的顯示prefix才能正常顯示', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-10-03.md', '標題1': '2. 重新點一次view裡面的顯示prefix才能正常顯示'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-24.md\n- 多次運行的結果相同，但與我自己組起來的prompt結果不同，~~猜測是generate_prompt的問題~~ 是prompt格式的問題\n- 參考[這篇](https://stackoverflow.com/questions/77625508/how-to-activate-verbosity-in-langchain)提到可以用 `from langchain.globals import set_debug` 來debug\n- 修改HF_HUB_CACHE並使用 `$sudo chmod a+rwx -R ./` 將TGI的模型檔與transformers共用\n- 跑完TAIDE的message、transformers、手動prompt三種實驗\n- message和手動Prompt可以相同，但huggingface不行，感覺是generate_prompt的問題', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-24.md', '標題1': '2. 跑實驗'})]
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 42%|████▏     | 15/36 [00:51<01:06,  3.17s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 44%|████▍     | 16/36 [00:54<01:02,  3.10s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 47%|████▋     | 17/36 [00:56<00:56,  3.00s/it]Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-03.md
# 2. 重新點一次view裡面的顯示prefix才能正常顯示

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-24.md
- 多次運行的結果相同，但與我自己組起來的prompt結果不同，~~猜測是generate_prompt的問題~~ 是prompt格式的問題
- 參考[這篇](https://stackoverflow.com/questions/77625508/how-to-activate-verbosity-in-langchain)提到可以用 `from langchain.globals import set_debug` 來debug
- 修改HF_HUB_CACHE並使用 `$sudo chmod a+rwx -R ./` 將TGI的模型檔與transformers共用
- 跑完TAIDE的message、transformers、手動prompt三種實驗
- message和手動Prompt可以相同，但huggingface不行，感覺是generate_prompt的問題

==問題==
根據上文，如何解決protégé中的顯示問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2692792
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-25.md\n# 1. PyQt的多執行緒\n- 用單獨的thread管理PyQt\n- 用threading.event來觸發顯示\n- 用global參數來修改內容?', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-25.md', '標題1': '1. PyQt的多執行緒'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-11.md\n# 1. 修改論文\n- Multi-Source Data Analysis與Multi-source infomation management system\n- 多源資料分析主要注重統合、轉換、除錯並分析資料\n- 多源資訊管理主要目的在蒐集與管理資訊', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-11.md', '標題1': '1. 修改論文'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-25.md
# 1. PyQt的多執行緒
- 用單獨的thread管理PyQt
- 用threading.event來觸發顯示
- 用global參數來修改內容?

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-11.md
# 1. 修改論文
- Multi-Source Data Analysis與Multi-source infomation management system
- 多源資料分析主要注重統合、轉換、除錯並分析資料
- 多源資訊管理主要目的在蒐集與管理資訊

==問題==
根據上文，為甚麼系統要使用多執行緒?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.008740316
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-25.md\n# 3. 根據chrome extensione官方說明，30秒會自動將service worker關閉，因此採用25秒一次的心跳來解決這個問題[^1]\n- 之後如果確認後端不會主動傳訊息給SW，則可以考慮改為http ( 只要修改send函數應該就行了 )', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-25.md', '標題1': '3. 根據chrome extensione官方說明，30秒會自動將service worker關閉，因此採用25秒一次的心跳來解決這個問題[^1]'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-15.md\n- 感覺不是純粹切視窗或關視窗的問題，也許跟省電或其他的websocket管理有關', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-15.md', '標題1': '1. 修復匯出摘錄時會用到之前資料的問題'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-25.md
# 3. 根據chrome extensione官方說明，30秒會自動將service worker關閉，因此採用25秒一次的心跳來解決這個問題[^1]
- 之後如果確認後端不會主動傳訊息給SW，則可以考慮改為http ( 只要修改send函數應該就行了 )

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-15.md
- 感覺不是純粹切視窗或關視窗的問題，也許跟省電或其他的websocket管理有關

==問題==
根據上文，service worker幾秒後會自動關閉?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.19715488
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-28.md\n# 9. 關於chrome-extension中不允許在html中直接呼叫javascript函數\n- 因為chrome-extension不允許CSP\n- 但好像可以用[這個](https://stackoverflow.com/questions/72186787/chrome-extensions-and-csp)允許特定網站的CSP?', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-28.md', '標題1': '9. 關於chrome-extension中不允許在html中直接呼叫javascript函數'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-04.md\n- <class \'str\'>不行，<class \'bytes\'>才對\n- 交叉比對\n- 另外開一個.py，避免非同步之類的問題\n- 就算在字串前加上u也沒用\n-\n- 和[這個](https://stackoverflow.com/questions/34618149/post-unicode-string-to-web-service-using-python-requests-library)情況有點類似\n- 實際原因是，requests針對text類的body，會自動使用ISO-8859-1編碼[^1]\n- 但實測將content-type改成 `text/markdown; charset=UTF-8` 也不行\n- github上同樣有人提出，但requests目前處於盡量不修改的狀況，因此雖然python3的整個生態都使用utf-8，但仍建議在requests時使用.encode("utf-8")轉成byte來傳送處理[^2]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-04.md', '標題1': '1. 系統'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-28.md
# 9. 關於chrome-extension中不允許在html中直接呼叫javascript函數
- 因為chrome-extension不允許CSP
- 但好像可以用[這個](https://stackoverflow.com/questions/72186787/chrome-extensions-and-csp)允許特定網站的CSP?

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-04.md
- <class 'str'>不行，<class 'bytes'>才對
- 交叉比對
- 另外開一個.py，避免非同步之類的問題
- 就算在字串前加上u也沒用
-
- 和[這個](https://stackoverflow.com/questions/34618149/post-unicode-string-to-web-service-using-python-requests-library)情況有點類似
- 實際原因是，requests針對text類的body，會自動使用ISO-8859-1編碼[^1]
- 但實測將content-type改成 `text/markdown; charset=UTF-8` 也不行
- github上同樣有人提出，但requests目前處於盡量不修改的狀況，因此雖然python3的整個生態都使用utf-8，但仍建議在requests時使用.encode("utf-8")轉成byte來傳送處理[^2]

==問題==
根據上文，為什麼chrome-extension不能在html中直接呼叫javascript函數
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.109264515
float32
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 50%|█████     | 18/36 [01:00<00:55,  3.07s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 53%|█████▎    | 19/36 [01:03<00:50,  3.00s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 56%|█████▌    | 20/36 [01:05<00:47,  2.97s/it][Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-13.md\n# 4. 閱讀論文\n- 在這篇[^4] 論文中提到，實驗中為了在最小化幻覺和嚴格生成之間取得平衡，將GPT的溫度設為0，llama的溫度設為0.1，但論文中未提及更詳細的理由', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-13.md', '標題1': '4. 閱讀論文'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md\nendpoint _url=" http://localhost:8080/" ,\ncache = False,\nmax _new_tokens=256,\ndo _sample=False, # 關閉採樣\ntop _k=1,\ntop _p=0.99,\ntemperature=0.1, # 已經關閉採樣了所以其實設多少都沒差\n)\n```\n```\nchat_completion = client.chat.completions.create(\nmessages=message_list,\ntemperature=0,\nmax_tokens=256,\n)\n```\n- 實驗證明\n1. langchain的chat就算設定do_sample為False也不是完全貪婪，尤其top_k是必要的\n2. 以上的參數可以使結果相同\n3. 雖然相關討論的結論認為關鍵在do_sample + temperature=None[^2]，但直覺上我覺得top_k也行', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md', '標題1': '2. 實驗'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-13.md
# 4. 閱讀論文
- 在這篇[^4] 論文中提到，實驗中為了在最小化幻覺和嚴格生成之間取得平衡，將GPT的溫度設為0，llama的溫度設為0.1，但論文中未提及更詳細的理由

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
endpoint _url=" http://localhost:8080/" ,
cache = False,
max _new_tokens=256,
do _sample=False, # 關閉採樣
top _k=1,
top _p=0.99,
temperature=0.1, # 已經關閉採樣了所以其實設多少都沒差
)
```
```
chat_completion = client.chat.completions.create(
messages=message_list,
temperature=0,
max_tokens=256,
)
```
- 實驗證明
1. langchain的chat就算設定do_sample為False也不是完全貪婪，尤其top_k是必要的
2. 以上的參數可以使結果相同
3. 雖然相關討論的結論認為關鍵在do_sample + temperature=None[^2]，但直覺上我覺得top_k也行

==問題==
根據上文，ChatGPT的溫度設為多少最恰當?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.20829745
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-22.md\n# 999. 其他\n- How can we evaluate the ability of each LLM to generate Cypher?\n- tag嵌套的必要性\n- markdown的結構化 #靈感\n- 例如tab代表有\n- 可能要重新考慮nDCG來比對[[Embeddeding|嵌入]]結果\n- 可能要檢查 [[Mean Average Precision|MAP]] 的算法是否有誤\n- 以前不熟悉的關鍵字會慢慢熟悉，要怎麼應對這種情況? #靈感\n[^1]: https://github.com/microsoft/terminal/issues/14018\n[^2]: https://stackoverflow.com/questions/32127524/how-to-install-and-use-make-in-windows', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-22.md', '標題1': '999. 其他'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-16.md\n# 2. 嵌入模型\n- e5模型應該使用intfloat/multilingual-e5-large而非e5-large，因為原版只支援英文\n- 需要找時間重新測試', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-16.md', '標題1': '2. 嵌入模型'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-22.md
# 999. 其他
- How can we evaluate the ability of each LLM to generate Cypher?
- tag嵌套的必要性
- markdown的結構化 #靈感
- 例如tab代表有
- 可能要重新考慮nDCG來比對[[Embeddeding|嵌入]]結果
- 可能要檢查 [[Mean Average Precision|MAP]] 的算法是否有誤
- 以前不熟悉的關鍵字會慢慢熟悉，要怎麼應對這種情況? #靈感
[^1]: https://github.com/microsoft/terminal/issues/14018
[^2]: https://stackoverflow.com/questions/32127524/how-to-install-and-use-make-in-windows

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-16.md
# 2. 嵌入模型
- e5模型應該使用intfloat/multilingual-e5-large而非e5-large，因為原版只支援英文
- 需要找時間重新測試

==問題==
根據上文，嵌入有可能遇到什麼問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.090603866
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-16.md\n# 1. [[Whisper]]\n嘗試解決幻覺問題\nhttps://github.com/openai/whisper/discussions/679\n加上參數--condition_on_previous_text False  \n##  評估方式?\n根據不同面向，例如冗字、專有名詞，其他錯誤等  \n又加了一堆論文哈哈', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-16.md', '標題1': '1. [[Whisper]]'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-05.md\n# 4. 測試[[SpeechRecognition]]\n建立虛擬環境並安裝此套件，\nclone範例程式<https://github.com/Uberi/speech_recognition/blob/master/examples/microphone_recognition.py>\n1. 實驗[[Sphinx]]及[[Google Speech Recognition]]兩個語音辨識API\n安裝pocketsphinx\n2. 實驗background_listening\n1. 安裝[[PyAudio]]\n結論: 在中文精準度上需要多測試，可能要找找看[[機器學習]]方面的辨識方法。', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-05.md', '標題1': '4. 測試[[SpeechRecognition]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-16.md
# 1. [[Whisper]]
嘗試解決幻覺問題
https://github.com/openai/whisper/discussions/679
加上參數--condition_on_previous_text False  
##  評估方式?
根據不同面向，例如冗字、專有名詞，其他錯誤等  
又加了一堆論文哈哈

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-05.md
# 4. 測試[[SpeechRecognition]]
建立虛擬環境並安裝此套件，
clone範例程式<https://github.com/Uberi/speech_recognition/blob/master/examples/microphone_recognition.py>
1. 實驗[[Sphinx]]及[[Google Speech Recognition]]兩個語音辨識API
安裝pocketsphinx
2. 實驗background_listening
1. 安裝[[PyAudio]]
結論: 在中文精準度上需要多測試，可能要找找看[[機器學習]]方面的辨識方法。

==問題==
根據上文，有哪些方法可以解決語音辨識的幻聽問題
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16820273
float32
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 58%|█████▊    | 21/36 [01:08<00:44,  2.98s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 61%|██████    | 22/36 [01:11<00:39,  2.85s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 64%|██████▍   | 23/36 [01:14<00:37,  2.90s/it][Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md\n# 3. 除了降噪外其他可能影響語音識別的因素\n#靈感/語音識別\n1. 聲道\n2. 取樣率\n3. 語速\n4. bit率', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md', '標題1': '3. 除了降噪外其他可能影響語音識別的因素'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-19.md\n# 今日計畫\n- [ ] 論文整理\n- [ ] 語音助理技術進展\n- [ ] 基於[[Knowledge Base]]的GPT似乎已存在了，檢查相關方法\nhttps://www.bilibili.com/video/BV19o4y1J7mL/?spm_id_from=333.788.recommend_more_video.18&vd_source=591675bcd42bc693ef34911801b34eb2\n- [ ] 將上課或會議內容錄音後，藉由語音辨識產生知識本體的可能性\n- [ ] 比較不同降噪間的逐字稿結果是否不同\n- [ ] 有沒有比較高效或公正的檢查標準?\n- [ ] 不同模型\n- [ ] sentence to triple的技術', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-19.md', '標題1': '今日計畫'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-19.md
# 今日計畫
- [ ] 論文整理
- [ ] 語音助理技術進展
- [ ] 基於[[Knowledge Base]]的GPT似乎已存在了，檢查相關方法
https://www.bilibili.com/video/BV19o4y1J7mL/?spm_id_from=333.788.recommend_more_video.18&vd_source=591675bcd42bc693ef34911801b34eb2
- [ ] 將上課或會議內容錄音後，藉由語音辨識產生知識本體的可能性
- [ ] 比較不同降噪間的逐字稿結果是否不同
- [ ] 有沒有比較高效或公正的檢查標準?
- [ ] 不同模型
- [ ] sentence to triple的技術

==問題==
根據上文，語音辨識可以有哪些評估的方向
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.071613215
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md\n# 3. 關於瀏覽器插件的溝通方式選擇\npipe or websocket\n選擇websocket，因為javascript無法操作作業系統層級的pipe\n查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe\n理論上也確實如此，否則瀏覽器插件的權限很容易太大', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md', '標題1': '3. 關於瀏覽器插件的溝通方式選擇'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-11.md\n# 3. Vosk使用測試\n![[Vosk#0910實驗記錄]]\n#筆記用標籤/疑問 為什麼使用pip安裝後就可以使用command line tool?', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-11.md', '標題1': '3. Vosk使用測試'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 3. 關於瀏覽器插件的溝通方式選擇
pipe or websocket
選擇websocket，因為javascript無法操作作業系統層級的pipe
查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe
理論上也確實如此，否則瀏覽器插件的權限很容易太大

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-11.md
# 3. Vosk使用測試
![[Vosk#0910實驗記錄]]
#筆記用標籤/疑問 為什麼使用pip安裝後就可以使用command line tool?

==問題==
根據上文，為什麼瀏覽器插件不使用pipe?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2258542
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md\n# 3. 除了降噪外其他可能影響語音識別的因素\n#靈感/語音識別\n1. 聲道\n2. 取樣率\n3. 語速\n4. bit率', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md', '標題1': '3. 除了降噪外其他可能影響語音識別的因素'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-28.md\n# 1. 關於語音辨識準確度\n![[Automatic Speech Recognition#關於準確度]]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-28.md', '標題1': '1. 關於語音辨識準確度'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-28.md
# 1. 關於語音辨識準確度
![[Automatic Speech Recognition#關於準確度]]

==問題==
根據上文，哪些因素可能會影響語音識別？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.26710048
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-30.md\n# 3. 將宿舍電腦的 StableDiffusion 虛擬環境中的 [[pytorch]] 更新到pytorch2[^1]\n1. 切換到虛擬環境\n`.\\envs\\scripts\\activate.bat`\n2. 檢查pip路徑\n`pip --version`\n3. 參考[官網](https://pytorch.org/get-started/locally/)訊息，CUDA11.8\n`pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`\n4. 結果\n```\nInstalling collected packages: mpmath, sympy, torch, torchvision, torchaudio\nAttempting uninstall: torch\nFound existing installation: torch 1.13.1+cu117', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-30.md', '標題1': '3. 將宿舍電腦的 StableDiffusion 虛擬環境中的 [[pytorch]] 更新到pytorch2[^1]'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-07-27.md\n# 4. 嘗試[[ChatPaper2Xmind]]\n參考README\n```\ngit clone git@github.com:MasterYip/ChatPaper2Xmind.git\npip install -r requirements.txt\ngit submodule update --init --recursive\n```\n設定config.py，包含API key及LANGUAGE = "Chinese"\npython paper2xmind.py  \n報錯:\n```\nYou exceeded your current quota, please check your plan and billing details.\n```\nChatGPT要付錢啦嗚嗚嗚', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-07-27.md', '標題1': '4. 嘗試[[ChatPaper2Xmind]]'})]
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 67%|██████▋   | 24/36 [01:17<00:33,  2.81s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 69%|██████▉   | 25/36 [01:19<00:30,  2.78s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 72%|███████▏  | 26/36 [01:22<00:28,  2.82s/it]Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-30.md
# 3. 將宿舍電腦的 StableDiffusion 虛擬環境中的 [[pytorch]] 更新到pytorch2[^1]
1. 切換到虛擬環境
`.\envs\scripts\activate.bat`
2. 檢查pip路徑
`pip --version`
3. 參考[官網](https://pytorch.org/get-started/locally/)訊息，CUDA11.8
`pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`
4. 結果
```
Installing collected packages: mpmath, sympy, torch, torchvision, torchaudio
Attempting uninstall: torch
Found existing installation: torch 1.13.1+cu117

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-27.md
# 4. 嘗試[[ChatPaper2Xmind]]
參考README
```
git clone git@github.com:MasterYip/ChatPaper2Xmind.git
pip install -r requirements.txt
git submodule update --init --recursive
```
設定config.py，包含API key及LANGUAGE = "Chinese"
python paper2xmind.py  
報錯:
```
You exceeded your current quota, please check your plan and billing details.
```
ChatGPT要付錢啦嗚嗚嗚

==問題==
根據上文，我參考了哪個教學將pytorch更新到pytorch2?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.3263341
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-28.md\n# 999. 靈感  \n[^1]: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=key1YF/record?r1=16&h1=0\n[^2]: https://aws.amazon.com/tw/compare/the-difference-between-grpc-and-rest/', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-28.md', '標題1': '999. 靈感'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-20.md\n# 999. 靈感\n- 在[這篇](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/discussions/82)討論區中提到，幫選擇題加上「以上皆非」是一個不錯的想法\n- 關於比較模型的部分，可以用比較的方式  \n[^6]: https://medium.com/%E5%BD%BC%E5%BE%97%E6%BD%98%E7%9A%84-swift-ios-app-%E9%96%8B%E7%99%BC%E5%95%8F%E9%A1%8C%E8%A7%A3%E7%AD%94%E9%9B%86/%E7%94%A8%E8%80%81%E5%B8%AB-%E5%AD%B8%E7%94%9F%E8%BA%AB%E4%BB%BD%E5%85%8D%E8%B2%BB%E4%BD%BF%E7%94%A8-github-copilot-223236e0e0e8', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-20.md', '標題1': '999. 靈感'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-28.md
# 999. 靈感  
[^1]: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=key1YF/record?r1=16&h1=0
[^2]: https://aws.amazon.com/tw/compare/the-difference-between-grpc-and-rest/

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-20.md
# 999. 靈感
- 在[這篇](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/discussions/82)討論區中提到，幫選擇題加上「以上皆非」是一個不錯的想法
- 關於比較模型的部分，可以用比較的方式  
[^6]: https://medium.com/%E5%BD%BC%E5%BE%97%E6%BD%98%E7%9A%84-swift-ios-app-%E9%96%8B%E7%99%BC%E5%95%8F%E9%A1%8C%E8%A7%A3%E7%AD%94%E9%9B%86/%E7%94%A8%E8%80%81%E5%B8%AB-%E5%AD%B8%E7%94%9F%E8%BA%AB%E4%BB%BD%E5%85%8D%E8%B2%BB%E4%BD%BF%E7%94%A8-github-copilot-223236e0e0e8

==問題==
根據上文，bibtex和ris差在哪？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.4384315
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-11-23.md\n# 2. 研究過程中，除了這個研究的貢獻外，在相關研究中也可以得到很多資訊\n可以在筆記中包含，提到這篇研究的研究、該研究中的說明、評價、引用編號等\n#靈感', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-11-23.md', '標題1': '2. 研究過程中，除了這個研究的貢獻外，在相關研究中也可以得到很多資訊'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-01-10.md\n# 1. [閱讀筆記](https://blog.csdn.net/Delusional/article/details/109186531)\n- 讀完一篇論文後可以用表格等方式將論文的內容簡單紀錄，包含以下資訊:\n1. 來源\n2. 研究機構Institution\n3. 論文Paper\n4. 關鍵字Topic\n5. 目標Aim\n6. 研究問題Problem to solve\n7. 解決方法Solutions\n8. 阻礙?Strength\n9. 限制\n10. 資料集\n11. 評估分數Evaluation Score\n12. 程式碼', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-01-10.md', '標題1': '1. [閱讀筆記](https://blog.csdn.net/Delusional/article/details/109186531)'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-11-23.md
# 2. 研究過程中，除了這個研究的貢獻外，在相關研究中也可以得到很多資訊
可以在筆記中包含，提到這篇研究的研究、該研究中的說明、評價、引用編號等
#靈感

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-01-10.md
# 1. [閱讀筆記](https://blog.csdn.net/Delusional/article/details/109186531)
- 讀完一篇論文後可以用表格等方式將論文的內容簡單紀錄，包含以下資訊:
1. 來源
2. 研究機構Institution
3. 論文Paper
4. 關鍵字Topic
5. 目標Aim
6. 研究問題Problem to solve
7. 解決方法Solutions
8. 阻礙?Strength
9. 限制
10. 資料集
11. 評估分數Evaluation Score
12. 程式碼

==問題==
根據上文，可以從論文的相關研究中得到什麼？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.44338506
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md\n# 0. 今日計畫\n- [ ] 找關於note問答的研究或系統或應用，例如到底有哪些問題可能被提出?\n- [ ] [[PrivateGPT]] 實驗 https://medium.com/@ingridwickstevens/chat-with-your-local-documents-privategpt-lm-studio-c6ff94d0dfe3\n- [ ] 整理文獻\n- [ ] 閱讀清單\n- [ ] [嵌入的選擇](https://medium.com/thirdai-blog/demystifying-llm-driven-search-stop-comparing-embeddings-or-vectordbs-and-start-fine-tuning-d9b6791146fe)，超重要!\n- [ ] [中文問答數據調研](https://zhuanlan.zhihu.com/p/576399437)', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md', '標題1': '0. 今日計畫'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-14.md\n- TAIDE-llama3\n- nf4: 01:05，可filter\n- eetq: 01:06, 可filter\n- 實驗mistral-7B的fine-tune，MediaTek-Research/Breeze-7B-Instruct-v0_1\n- eetq: 基礎測試34秒，通過魔法測驗、\n-', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-14.md', '標題1': '1. 實驗'})]
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 75%|███████▌  | 27/36 [01:26<00:28,  3.16s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 78%|███████▊  | 28/36 [01:30<00:26,  3.29s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 81%|████████  | 29/36 [01:32<00:21,  3.08s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 83%|████████▎ | 30/36 [01:36<00:18,  3.10s/it]Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 0. 今日計畫
- [ ] 找關於note問答的研究或系統或應用，例如到底有哪些問題可能被提出?
- [ ] [[PrivateGPT]] 實驗 https://medium.com/@ingridwickstevens/chat-with-your-local-documents-privategpt-lm-studio-c6ff94d0dfe3
- [ ] 整理文獻
- [ ] 閱讀清單
- [ ] [嵌入的選擇](https://medium.com/thirdai-blog/demystifying-llm-driven-search-stop-comparing-embeddings-or-vectordbs-and-start-fine-tuning-d9b6791146fe)，超重要!
- [ ] [中文問答數據調研](https://zhuanlan.zhihu.com/p/576399437)

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-14.md
- TAIDE-llama3
- nf4: 01:05，可filter
- eetq: 01:06, 可filter
- 實驗mistral-7B的fine-tune，MediaTek-Research/Breeze-7B-Instruct-v0_1
- eetq: 基礎測試34秒，通過魔法測驗、
-

==問題==
根據上文，土豆挑戰是什麼？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1314348
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-08.md\n# 1. 撰寫chrome extension\n- 關於popus.js和background.js的溝通\n- 遇到錯誤 `Unchecked runtime.lastError: The message port closed before a response was received.`\n- 經過正確的使用sendmessage的callback的第三個參數sendResponse完成完整的溝通。\n- 準確的說是service-worker，因為在版本三中並沒有background page的存在，而是改為service worker。\n- 同上，有很多用法在第二版可以用，但在第三版不能用。', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-08.md', '標題1': '1. 撰寫chrome extension'}), Document(page_content="來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md\n# 5. bug\n1. DOMException: Failed to execute 'send' on 'WebSocket': Still in CONNECTING state.\n[參考](https://stackoverflow.com/questions/23051416/uncaught-invalidstateerror-failed-to-execute-send-on-websocket-still-in-co)將傳送訊息函數包在open=>{}中，確保傳送訊息前已經建立好連線", metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md', '標題1': '5. bug'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-08.md
# 1. 撰寫chrome extension
- 關於popus.js和background.js的溝通
- 遇到錯誤 `Unchecked runtime.lastError: The message port closed before a response was received.`
- 經過正確的使用sendmessage的callback的第三個參數sendResponse完成完整的溝通。
- 準確的說是service-worker，因為在版本三中並沒有background page的存在，而是改為service worker。
- 同上，有很多用法在第二版可以用，但在第三版不能用。

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 5. bug
1. DOMException: Failed to execute 'send' on 'WebSocket': Still in CONNECTING state.
[參考](https://stackoverflow.com/questions/23051416/uncaught-invalidstateerror-failed-to-execute-send-on-websocket-still-in-co)將傳送訊息函數包在open=>{}中，確保傳送訊息前已經建立好連線

==問題==
根據上文，如何解決The message port closed before a response was received
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.062017523
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-22.md\n- 註: daemon關閉時會強制關閉，若有讀寫檔、暫存檔等需要額外處理，例如在主thread中捕捉相關的事件。  \n- ChatGPT用模擬ctrl+c的方式實現自訂義複製快捷鍵，我喜歡\n- 本來無法模擬ctrl+c，後來發現是因為模擬前沒有放開實體按鍵，使用time.sleep或keyboard.release都能解決這個問題，也不需要管理員權限  \n- 讀取當前焦點視窗\n- 暫時先考慮windows，不考慮mac和linux，因此使用pywin32  \n- [[cypher]] 的參數化查詢無法用於標籤或關係上，因此需要使用python的格式化輸入來處理\n`query = f"MATCH (n:{tagName})"`', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-22.md', '標題1': '2. python的系統級快捷鍵'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-13.md\n# 5. [[FastAPI]]\n- Python的酷套件，要找時間把系統改成這個', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-13.md', '標題1': '5. [[FastAPI]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-22.md
- 註: daemon關閉時會強制關閉，若有讀寫檔、暫存檔等需要額外處理，例如在主thread中捕捉相關的事件。  
- ChatGPT用模擬ctrl+c的方式實現自訂義複製快捷鍵，我喜歡
- 本來無法模擬ctrl+c，後來發現是因為模擬前沒有放開實體按鍵，使用time.sleep或keyboard.release都能解決這個問題，也不需要管理員權限  
- 讀取當前焦點視窗
- 暫時先考慮windows，不考慮mac和linux，因此使用pywin32  
- [[cypher]] 的參數化查詢無法用於標籤或關係上，因此需要使用python的格式化輸入來處理
`query = f"MATCH (n:{tagName})"`

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-13.md
# 5. [[FastAPI]]
- Python的酷套件，要找時間把系統改成這個

==問題==
根據上文，哪些python套件能監聽快捷鍵？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2724631
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-16.md\n`mklink "E:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin\\make.exe" "E:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin\\mingw32-make.exe"`\n- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`\n- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性\n- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要\n- [ ] 整理文獻\n- [ ] 閱讀清單', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-16.md', '標題1': '0. 今日計畫'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-25.md\n# 1. PyQt的多執行緒\n- 用單獨的thread管理PyQt\n- 用threading.event來觸發顯示\n- 用global參數來修改內容?', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-25.md', '標題1': '1. PyQt的多執行緒'})]
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 86%|████████▌ | 31/36 [01:38<00:15,  3.00s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 89%|████████▉ | 32/36 [01:42<00:12,  3.10s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 92%|█████████▏| 33/36 [01:45<00:09,  3.21s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 94%|█████████▍| 34/36 [01:48<00:06,  3.11s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 97%|█████████▋| 35/36 [01:51<00:02,  2.99s/it]Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-16.md
`mklink "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\make.exe" "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\mingw32-make.exe"`
- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`
- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性
- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要
- [ ] 整理文獻
- [ ] 閱讀清單

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-25.md
# 1. PyQt的多執行緒
- 用單獨的thread管理PyQt
- 用threading.event來觸發顯示
- 用global參數來修改內容?

==問題==
根據上文，除了pyqt外，當時還考慮哪些類似的套件？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.14854458
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-16.md\n# 999. 其他\n- 根據FastAPI的文檔，建議使用Union來取代Optional功能，但範例中有點錯誤\n- 建議避免使用 `name: Optional[str]`，因為實際上name並不是可選的而是必選的\n- 就算使用 `def say_hi(name: str | None)` 也不代表不需要參數，必須要設定初始值，如 `def say_hi(name: str | None = None)`  \n[^1]: https://stackoverflow.com/questions/63872924/how-can-i-send-an-http-request-from-my-fastapi-app-to-another-site-api\n[^2]: https://scrapfly.io/blog/httpx-vs-requests-vs-aiohttp/', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-16.md', '標題1': '999. 其他'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-16.md\n# 1. 系統\n- neo4j\n- 根據[官方教學](https://neo4j.com/docs/operations-manual/current/configuration/connectors/) 修改neo4j的監聽ip讓台北電腦測試neo4j chain', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-16.md', '標題1': '1. 系統'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-16.md
# 999. 其他
- 根據FastAPI的文檔，建議使用Union來取代Optional功能，但範例中有點錯誤
- 建議避免使用 `name: Optional[str]`，因為實際上name並不是可選的而是必選的
- 就算使用 `def say_hi(name: str | None)` 也不代表不需要參數，必須要設定初始值，如 `def say_hi(name: str | None = None)`  
[^1]: https://stackoverflow.com/questions/63872924/how-can-i-send-an-http-request-from-my-fastapi-app-to-another-site-api
[^2]: https://scrapfly.io/blog/httpx-vs-requests-vs-aiohttp/

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-16.md
# 1. 系統
- neo4j
- 根據[官方教學](https://neo4j.com/docs/operations-manual/current/configuration/connectors/) 修改neo4j的監聽ip讓台北電腦測試neo4j chain

==問題==
根據上文，系統中的FastAPI監聽哪個端口？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.28215396
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md\n# 3. 找到新關鍵字(ChatGPT)\n- Multi-Source Information Management\n- RALM，重要，需要了解具體定義及其與RAG的區別', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md', '標題1': '3. 找到新關鍵字(ChatGPT)'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md\n- [ ] [NEUMAI](https://docs.neum.ai/get-started/introduction)  \n- [ ] 待實驗\n- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/\n- [ ] GEMMA\n- [ ] [[HyDE]]\n- [ ] LLM的上下文與few-shot\n- 系統\n- [ ] 設計整個架構和所需要的API需求及文件\n- [ ] 浮動視窗，類似字典', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md', '標題1': '0. 今日計畫'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
- [ ] [NEUMAI](https://docs.neum.ai/get-started/introduction)  
- [ ] 待實驗
- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/
- [ ] GEMMA
- [ ] [[HyDE]]
- [ ] LLM的上下文與few-shot
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典

==問題==
根據上文，RALM類似什麼概念？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.04661884
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-11.md\n# 1. 修改論文\n- Multi-Source Data Analysis與Multi-source infomation management system\n- 多源資料分析主要注重統合、轉換、除錯並分析資料\n- 多源資訊管理主要目的在蒐集與管理資訊', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-11.md', '標題1': '1. 修改論文'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md\n# 3. 找到新關鍵字(ChatGPT)\n- Multi-Source Information Management\n- RALM，重要，需要了解具體定義及其與RAG的區別', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md', '標題1': '3. 找到新關鍵字(ChatGPT)'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-11.md
# 1. 修改論文
- Multi-Source Data Analysis與Multi-source infomation management system
- 多源資料分析主要注重統合、轉換、除錯並分析資料
- 多源資訊管理主要目的在蒐集與管理資訊

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

==問題==
根據上文，多源資料分析和管理差在哪？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.06321003
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-18.md\n[^10]: https://community.neo4j.com/t/import-individuals-and-relate-to-classes-in-neo4j/24567/2', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-18.md', '標題1': '999. 靈感'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-09.md\n# 1. 閱讀文獻\n- 看完並整理Dai, Zhuyun, Vincent Y. Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov, Kelvin Guu, Keith B. Hall及Ming-Wei Chang. 「Promptagator: Few-Shot Dense Retrieval From 8 Examples」. arXiv, 2022年9月23日. [https://doi.org/10.48550/arXiv.2209.11755](https://doi.org/10.48550/arXiv.2209.11755).', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-09.md', '標題1': '1. 閱讀文獻'})]
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

100%|██████████| 36/36 [01:53<00:00,  2.94s/it]
100%|██████████| 36/36 [01:53<00:00,  3.17s/it]
Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-18.md
[^10]: https://community.neo4j.com/t/import-individuals-and-relate-to-classes-in-neo4j/24567/2

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-09.md
# 1. 閱讀文獻
- 看完並整理Dai, Zhuyun, Vincent Y. Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov, Kelvin Guu, Keith B. Hall及Ming-Wei Chang. 「Promptagator: Few-Shot Dense Retrieval From 8 Examples」. arXiv, 2022年9月23日. [https://doi.org/10.48550/arXiv.2209.11755](https://doi.org/10.48550/arXiv.2209.11755).

==問題==
根據上文，在2024/4/17，我看完NEUMAI了嗎？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2960534
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-27.md\n# 2. 跑實驗', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-27.md', '標題1': '2. 跑實驗'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-24.md\n# 1. [[Whisper-Finetune]]\n![[Whisper-Finetune#0924實驗]]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-24.md', '標題1': '1. [[Whisper-Finetune]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-24.md
# 1. [[Whisper-Finetune]]
![[Whisper-Finetune#0924實驗]]

==問題==
根據上文，在2024/4/17，我做了什麼實驗？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.0678077
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-21.md\n# 2. 跑實驗\n- google/gemma-2b-it\n- 約20分鐘\n- google/gemma-2b\n- 約20分鐘\n- meta-llama/Llama-2-7b-chat-hf\n- 約一小時', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-21.md', '標題1': '2. 跑實驗'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-22.md\n- 以後不再測試未經指令微調的模型\n- 備份之前的結果後，刪除gemma-2b及TAIDE-LX-7B共計930筆紀錄', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-22.md', '標題1': '2. 跑實驗'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-21.md
# 2. 跑實驗
- google/gemma-2b-it
- 約20分鐘
- google/gemma-2b
- 約20分鐘
- meta-llama/Llama-2-7b-chat-hf
- 約一小時

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-22.md
- 以後不再測試未經指令微調的模型
- 備份之前的結果後，刪除gemma-2b及TAIDE-LX-7B共計930筆紀錄

==問題==
根據上文，在2024/4/17，我實驗過gemma了嗎?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.10619263
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-07.md\n- [ ] [[HyDE]]\n- 系統\n- [ ] 設計整個架構和所需要的API需求及文件\n- [ ] 浮動視窗，類似字典', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-07.md', '標題1': '0. 今日計畫'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-18.md\n# 0. 今日計畫\n- [ ] 整理文獻\n- [ ] 待實驗\n- [ ] GEMMA\n- [ ] [[HyDE]]\n- [ ] LLM的上下文與few-shot\n- 系統\n- [ ] 設計整個架構和所需要的API需求及文件\n- [ ] 浮動視窗，類似字典\n- 教育版copilot，要印英文在校證明[^6]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-18.md', '標題1': '0. 今日計畫'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-07.md
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-18.md
# 0. 今日計畫
- [ ] 整理文獻
- [ ] 待實驗
- [ ] GEMMA
- [ ] [[HyDE]]
- [ ] LLM的上下文與few-shot
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典
- 教育版copilot，要印英文在校證明[^6]

==問題==
根據上文，在2024/4/17，我設計完整個架構和所需要的API需求及文件了嗎？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.12266735
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-17.md\n# 2. 試用 [[Chat RTX]]\n- 38G，好大\n- 下載好久，安裝好久，安裝一個多小時吧，包含下載模型的時間\n- 吃爆VRAM、反應不快，基本只收英文\n- 因為很卡所以沒有繼續測試下去  \n[^3]: https://www.volcengine.com/theme/3863827-W-7-1\n[^4]: https://www.pythonforbeginners.com/basics/convert-ini-to-yaml-in-python\n[^5]: https://docs.privategpt.dev/recipes/choice-of-llm/list-of-ll-ms', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-17.md', '標題1': '2. 試用 [[Chat RTX]]'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-07.md\n# 2. 發現 [[Chat RTX]]\n- 中文能力不佳\n- 與研究著重在API不同', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-07.md', '標題1': '2. 發現 [[Chat RTX]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-17.md
# 2. 試用 [[Chat RTX]]
- 38G，好大
- 下載好久，安裝好久，安裝一個多小時吧，包含下載模型的時間
- 吃爆VRAM、反應不快，基本只收英文
- 因為很卡所以沒有繼續測試下去  
[^3]: https://www.volcengine.com/theme/3863827-W-7-1
[^4]: https://www.pythonforbeginners.com/basics/convert-ini-to-yaml-in-python
[^5]: https://docs.privategpt.dev/recipes/choice-of-llm/list-of-ll-ms

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-07.md
# 2. 發現 [[Chat RTX]]
- 中文能力不佳
- 與研究著重在API不同

==問題==
根據上文，我對ChatRTX的評價是正面還是負面
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.056782953
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-21.md\n# 2. 跑實驗\n- google/gemma-2b-it\n- 約20分鐘\n- google/gemma-2b\n- 約20分鐘\n- meta-llama/Llama-2-7b-chat-hf\n- 約一小時', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-21.md', '標題1': '2. 跑實驗'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-27.md\n# 2. 跑實驗', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-27.md', '標題1': '2. 跑實驗'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-21.md
# 2. 跑實驗
- google/gemma-2b-it
- 約20分鐘
- google/gemma-2b
- 約20分鐘
- meta-llama/Llama-2-7b-chat-hf
- 約一小時

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

==問題==
根據上文，在2024/4/21，我總共花了幾分鐘跑實驗
請用20個字簡潔回答問題。

None

(server) E:\Research\extension\chrome-extension>[06:32:11]python -m modules.rag

Generating train split: 0 examples [00:00, ? examples/s]
Generating train split: 51 examples [00:00, 6375.84 examples/s]

Filter:   0%|          | 0/51 [00:00<?, ? examples/s]
Filter: 100%|██████████| 51/51 [00:00<00:00, 3399.81 examples/s]

Filter:   0%|          | 0/38 [00:00<?, ? examples/s]
Filter: 100%|██████████| 38/38 [00:00<00:00, 2922.81 examples/s]

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  0%|          | 0/36 [00:17<?, ?it/s]
Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\httpcore\_sync\connection.py", line 99, in handle_request
    raise exc
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\httpcore\_sync\connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\httpcore\_sync\connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\httpcore\_backends\sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "D:\ProgramData\Anaconda3\envs\server\Lib\contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [WinError 10061] 無法連線，因為目標電腦拒絕連線。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 952, in _request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\ProgramData\Anaconda3\envs\server\Lib\contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [WinError 10061] 無法連線，因為目標電腦拒絕連線。

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 116, in <module>
    result = rag_obj.eval()
             ^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 99, in eval
    result = self.query(query)
             ^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 27, in query
    answer_text = self.generate_answer(query, context, model_name=self.config["llm_model"])
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\rag.py", line 79, in generate_answer
    llm_result = self.llm.chat(input=prompt, system_message="")
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Research\extension\chrome-extension\modules\llm.py", line 46, in chat
    response = chat.invoke(message_list)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 170, in invoke
    self.generate_prompt(
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 599, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 456, in generate
    raise e
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 446, in generate
    self._generate_with_cache(
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\language_models\chat_models.py", line 671, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_openai\chat_models\base.py", line 522, in _generate
    response = self.client.create(messages=message_dicts, **params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_utils\_utils.py", line 277, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\resources\chat\completions.py", line 579, in create
    return self._post(
           ^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 1240, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 921, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 976, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 1053, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 976, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 1053, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\openai\_base_client.py", line 986, in _request
    raise APIConnectionError(request=request) from err
openai.APIConnectionError: Connection error.
嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-07-24.md\n# 新增宿舍的筆記同步\n1. 參考[[Git指令]]，新增ssh key\n2. 使用ssh -T測試OK\n3. 用[[git clone]]將整份筆記下載\n4. 在Obsidian中開啟vault\n5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)\n6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題\n7. 使用以下指令重製ssh-key密碼為空\n```\nssh-keygen -p -f github_key\n```\n8. 重製為空後即可正常使用\n註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-07-24.md', '標題1': '新增宿舍的筆記同步'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-10-06.md\n# 1. 安裝 [[praat]]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-10-06.md', '標題1': '1. 安裝 [[praat]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-06.md
# 1. 安裝 [[praat]]

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。


(server) E:\Research\extension\chrome-extension>[06:33:31]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  3%|▎         | 1/36 [00:17<10:13, 17.53s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  6%|▌         | 2/36 [00:30<08:23, 14.81s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  8%|▊         | 3/36 [00:39<06:48, 12.37s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 11%|█         | 4/36 [00:49<06:04, 11.38s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 14%|█▍        | 5/36 [01:02<06:12, 12.00s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 17%|█▋        | 6/36 [01:14<06:00, 12.01s/it]嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-07-24.md\n# 新增宿舍的筆記同步\n1. 參考[[Git指令]]，新增ssh key\n2. 使用ssh -T測試OK\n3. 用[[git clone]]將整份筆記下載\n4. 在Obsidian中開啟vault\n5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)\n6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題\n7. 使用以下指令重製ssh-key密碼為空\n```\nssh-keygen -p -f github_key\n```\n8. 重製為空後即可正常使用\n註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-07-24.md', '標題1': '新增宿舍的筆記同步'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-10-06.md\n# 1. 安裝 [[praat]]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-10-06.md', '標題1': '1. 安裝 [[praat]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-06.md
# 1. 安裝 [[praat]]

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.057200395
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-03.md\n>In computing, an ontology is then a concrete, formal representation—a convention—on what terms mean within the scope in which they are used (e.g., a given domain). Like all conventions, the usefulness of an ontology depends on how broadly and consistently it is adopted and how detailed it is. Knowledge graphs that use a shared ontology will be more interoperable. Given that ontologies are formal representations, they can further be used to', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-03.md', '標題1': '1. 釐清知識本體和知識圖譜的差別'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-07-28.md\n# 2. 論文整理及概覽\n[[OntoLTCn： A Chinese Text Oriented Semi-auto Ontology Knowledge Discovery Tool|OntoLTCn: A Chinese Text Oriented Semi-auto Ontology Knowledge Discovery Tool]]  \n[[Approximate Reasoning for Large-Scale ABox in OWL DL Based on Neural-Symbolic Learning]]  \n张异卓, 周璐, 孙燕, 郑丰杰, 徐凤芹及李宇航. 「辨证论治思想指导下的中医主题词自动标引模型构建」. 中国中医药信息杂志 29, 期 8 (2022年): 18–23. https://doi.org/10.19879/j.cnki.1005-5304.202109202.', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-07-28.md', '標題1': '2. 論文整理及概覽'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-03.md
>In computing, an ontology is then a concrete, formal representation—a convention—on what terms mean within the scope in which they are used (e.g., a given domain). Like all conventions, the usefulness of an ontology depends on how broadly and consistently it is adopted and how detailed it is. Knowledge graphs that use a shared ontology will be more interoperable. Given that ontologies are formal representations, they can further be used to

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-28.md
# 2. 論文整理及概覽
[[OntoLTCn： A Chinese Text Oriented Semi-auto Ontology Knowledge Discovery Tool|OntoLTCn: A Chinese Text Oriented Semi-auto Ontology Knowledge Discovery Tool]]  
[[Approximate Reasoning for Large-Scale ABox in OWL DL Based on Neural-Symbolic Learning]]  
张异卓, 周璐, 孙燕, 郑丰杰, 徐凤芹及李宇航. 「辨证论治思想指导下的中医主题词自动标引模型构建」. 中国中医药信息杂志 29, 期 8 (2022年): 18–23. https://doi.org/10.19879/j.cnki.1005-5304.202109202.

==問題==
根據上文，Ontology是什麼?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2588572
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-07.md\n# 2. 測試[[LLaMA2]]\n中文支援不佳，嘗試使用中文微調專案[[Chinese-LLaMA-Alpaca-2]]\n及webui專案[[text-generation-webui]]\n設定參考[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh)\n- 須解決簡體中文的問題', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-07.md', '標題1': '2. 測試[[LLaMA2]]'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-22.md\n# 5. 試用 [[Obsidian-copilot]] 及 [[obsidian-smart-connections]]\n- 都不太支援中文，要想辦法', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-22.md', '標題1': '5. 試用 [[Obsidian-copilot]] 及 [[obsidian-smart-connections]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-07.md
# 2. 測試[[LLaMA2]]
中文支援不佳，嘗試使用中文微調專案[[Chinese-LLaMA-Alpaca-2]]
及webui專案[[text-generation-webui]]
設定參考[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh)
- 須解決簡體中文的問題

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-22.md
# 5. 試用 [[Obsidian-copilot]] 及 [[obsidian-smart-connections]]
- 都不太支援中文，要想辦法

==問題==
根據上文，llama支援中文嗎?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1619676
float32
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 19%|█▉        | 7/36 [01:28<06:02, 12.49s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 22%|██▏       | 8/36 [01:40<05:47, 12.40s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 25%|██▌       | 9/36 [01:51<05:23, 11.96s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 28%|██▊       | 10/36 [02:06<05:36, 12.94s/it][Document(page_content="來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md\n# [[MySQL]]匯出檔案\n參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join\n``` mysql\nmysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG\nHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;", metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md', '標題1': '[[MySQL]]匯出檔案'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md\n# [[MySQL]]三表[[join]]\n``` mysql\nSELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` FROM `standard_symptoms_table` as A RIGHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;\n```', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md', '標題1': '[[MySQL]]三表[[join]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]三表[[join]]
``` mysql
SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` FROM `standard_symptoms_table` as A RIGHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;
```

==問題==
根據上文，在mysql中如何將多張表合併?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.32915065
float32
[Document(page_content="來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md\n# [[MySQL]]匯出檔案\n參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join\n``` mysql\nmysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG\nHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;", metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md', '標題1': '[[MySQL]]匯出檔案'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md\n# [[MySQL]]三表[[join]]\n``` mysql\nSELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` FROM `standard_symptoms_table` as A RIGHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;\n```', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md', '標題1': '[[MySQL]]三表[[join]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]三表[[join]]
``` mysql
SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` FROM `standard_symptoms_table` as A RIGHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;
```

==問題==
根據上文，如何將mysql的表匯出?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1116085
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-06.md\n# 4. 在引用上實在很不方便，找了一些別的插件\nhttp://ob-plugin.eryajf.net/#/ob-plugin/01.Obsidian%E6%8F%92%E4%BB%B6%E5%91%A8%E5%88%8A%E7%AC%AC%E4%B8%80%E6%9C%9F', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-06.md', '標題1': '4. 在引用上實在很不方便，找了一些別的插件'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-30.md\n# 1. 幫宿舍電腦安裝引用套件[[obsidian-citation-plugin]]\n步驟如[[Github project/obsidian-citation-plugin|obsidian-citation-plugin]]中所寫', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-30.md', '標題1': '1. 幫宿舍電腦安裝引用套件[[obsidian-citation-plugin]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-06.md
# 4. 在引用上實在很不方便，找了一些別的插件
http://ob-plugin.eryajf.net/#/ob-plugin/01.Obsidian%E6%8F%92%E4%BB%B6%E5%91%A8%E5%88%8A%E7%AC%AC%E4%B8%80%E6%9C%9F

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-30.md
# 1. 幫宿舍電腦安裝引用套件[[obsidian-citation-plugin]]
步驟如[[Github project/obsidian-citation-plugin|obsidian-citation-plugin]]中所寫

==問題==
根據上文，什麼時候安裝了obsidian的引用外掛?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.11549372
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md\n# 4. 如何選擇port?\n參考[^2] ，選擇沒人佔用的27709  \n[^1]: https://stackoverflow.com/questions/42631509/piping-node-js-to-python\n[^2]: https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=27709', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md', '標題1': '4. 如何選擇port?'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md\n# 3. 關於瀏覽器插件的溝通方式選擇\npipe or websocket\n選擇websocket，因為javascript無法操作作業系統層級的pipe\n查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe\n理論上也確實如此，否則瀏覽器插件的權限很容易太大', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md', '標題1': '3. 關於瀏覽器插件的溝通方式選擇'})]
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 31%|███       | 11/36 [02:15<04:50, 11.61s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 33%|███▎      | 12/36 [02:29<04:57, 12.40s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 36%|███▌      | 13/36 [02:43<04:59, 13.01s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 39%|███▉      | 14/36 [02:57<04:52, 13.28s/it]Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 4. 如何選擇port?
參考[^2] ，選擇沒人佔用的27709  
[^1]: https://stackoverflow.com/questions/42631509/piping-node-js-to-python
[^2]: https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=27709

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 3. 關於瀏覽器插件的溝通方式選擇
pipe or websocket
選擇websocket，因為javascript無法操作作業系統層級的pipe
查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe
理論上也確實如此，否則瀏覽器插件的權限很容易太大

==問題==
根據上文，怎麼選擇端口的?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.35214102
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-21.md\n# 4. 開會\n- 冒號問題，如果資訊比較不重要可以刪除\n- 或者用減號、全形冒號等\n```\n▸標籤管理實作\n▸PDF抽取方法實驗及整理\n▸s2orc-doc2json、 grobid\n▸文獻閱讀: Too many tags spoil the metadata: investigating the knowledge management of scientific research with semantic web technologies(2019)\n▸其他: 冒號問題\n```', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-21.md', '標題1': '4. 開會'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-21.md\n# 4. 考量windows檔案名稱問題\nhttps://stackoverflow.com/questions/10386344/how-to-get-a-file-in-windows-with-a-colon-in-the-filename\n想辦法讓windows檔案名稱能支援論文標題。\n[Automatically convert colons in {{title}} to other symbols, such as "-"](https://github.com/hans/obsidian-citation-plugin/issues/89)\n#研究/feature', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-21.md', '標題1': '4. 考量windows檔案名稱問題'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-21.md
# 4. 開會
- 冒號問題，如果資訊比較不重要可以刪除
- 或者用減號、全形冒號等
```
▸標籤管理實作
▸PDF抽取方法實驗及整理
▸s2orc-doc2json、 grobid
▸文獻閱讀: Too many tags spoil the metadata: investigating the knowledge management of scientific research with semantic web technologies(2019)
▸其他: 冒號問題
```

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-21.md
# 4. 考量windows檔案名稱問題
https://stackoverflow.com/questions/10386344/how-to-get-a-file-in-windows-with-a-colon-in-the-filename
想辦法讓windows檔案名稱能支援論文標題。
[Automatically convert colons in {{title}} to other symbols, such as "-"](https://github.com/hans/obsidian-citation-plugin/issues/89)
#研究/feature

==問題==
根據上文，如何解決論文標題中的冒號問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.1906288
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md\n# 3. 除了降噪外其他可能影響語音識別的因素\n#靈感/語音識別\n1. 聲道\n2. 取樣率\n3. 語速\n4. bit率', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md', '標題1': '3. 除了降噪外其他可能影響語音識別的因素'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-28.md\n# 1. 關於語音辨識準確度\n![[Automatic Speech Recognition#關於準確度]]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-28.md', '標題1': '1. 關於語音辨識準確度'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-28.md
# 1. 關於語音辨識準確度
![[Automatic Speech Recognition#關於準確度]]

==問題==
根據上文，哪些因素可能會影響語音識別的準確度?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16114116
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md\n# 999. 靈感\n- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  \n[^1]: https://ithelp.ithome.com.tw/articles/10340284\n[^2]: https://github.com/huggingface/text-generation-inference/issues/1201', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md', '標題1': '999. 靈感'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-11-02.md\n# 2. 關於 [[whisper]] 的術語問題\n[這裡](https://stackoverflow.com/questions/73833916/how-can-i-give-some-hint-phrases-to-openais-whisper-asr)', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-11-02.md', '標題1': '2. 關於 [[whisper]] 的術語問題'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 999. 靈感
- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  
[^1]: https://ithelp.ithome.com.tw/articles/10340284
[^2]: https://github.com/huggingface/text-generation-inference/issues/1201

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-11-02.md
# 2. 關於 [[whisper]] 的術語問題
[這裡](https://stackoverflow.com/questions/73833916/how-can-i-give-some-hint-phrases-to-openais-whisper-asr)

==問題==
根據上文，如何微調whisper?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.106168725
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-10-03.md\n# 2. 重新點一次view裡面的顯示prefix才能正常顯示', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-10-03.md', '標題1': '2. 重新點一次view裡面的顯示prefix才能正常顯示'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-24.md\n- 多次運行的結果相同，但與我自己組起來的prompt結果不同，~~猜測是generate_prompt的問題~~ 是prompt格式的問題\n- 參考[這篇](https://stackoverflow.com/questions/77625508/how-to-activate-verbosity-in-langchain)提到可以用 `from langchain.globals import set_debug` 來debug\n- 修改HF_HUB_CACHE並使用 `$sudo chmod a+rwx -R ./` 將TGI的模型檔與transformers共用\n- 跑完TAIDE的message、transformers、手動prompt三種實驗\n- message和手動Prompt可以相同，但huggingface不行，感覺是generate_prompt的問題', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-24.md', '標題1': '2. 跑實驗'})]
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 42%|████▏     | 15/36 [03:10<04:33, 13.03s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 44%|████▍     | 16/36 [03:21<04:08, 12.42s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 47%|████▋     | 17/36 [03:30<03:38, 11.48s/it]Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-03.md
# 2. 重新點一次view裡面的顯示prefix才能正常顯示

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-24.md
- 多次運行的結果相同，但與我自己組起來的prompt結果不同，~~猜測是generate_prompt的問題~~ 是prompt格式的問題
- 參考[這篇](https://stackoverflow.com/questions/77625508/how-to-activate-verbosity-in-langchain)提到可以用 `from langchain.globals import set_debug` 來debug
- 修改HF_HUB_CACHE並使用 `$sudo chmod a+rwx -R ./` 將TGI的模型檔與transformers共用
- 跑完TAIDE的message、transformers、手動prompt三種實驗
- message和手動Prompt可以相同，但huggingface不行，感覺是generate_prompt的問題

==問題==
根據上文，如何解決protégé中的顯示問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2692792
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-25.md\n# 1. PyQt的多執行緒\n- 用單獨的thread管理PyQt\n- 用threading.event來觸發顯示\n- 用global參數來修改內容?', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-25.md', '標題1': '1. PyQt的多執行緒'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-11.md\n# 1. 修改論文\n- Multi-Source Data Analysis與Multi-source infomation management system\n- 多源資料分析主要注重統合、轉換、除錯並分析資料\n- 多源資訊管理主要目的在蒐集與管理資訊', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-11.md', '標題1': '1. 修改論文'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-25.md
# 1. PyQt的多執行緒
- 用單獨的thread管理PyQt
- 用threading.event來觸發顯示
- 用global參數來修改內容?

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-11.md
# 1. 修改論文
- Multi-Source Data Analysis與Multi-source infomation management system
- 多源資料分析主要注重統合、轉換、除錯並分析資料
- 多源資訊管理主要目的在蒐集與管理資訊

==問題==
根據上文，為甚麼系統要使用多執行緒?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.008740316
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-25.md\n# 3. 根據chrome extensione官方說明，30秒會自動將service worker關閉，因此採用25秒一次的心跳來解決這個問題[^1]\n- 之後如果確認後端不會主動傳訊息給SW，則可以考慮改為http ( 只要修改send函數應該就行了 )', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-25.md', '標題1': '3. 根據chrome extensione官方說明，30秒會自動將service worker關閉，因此採用25秒一次的心跳來解決這個問題[^1]'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-15.md\n- 感覺不是純粹切視窗或關視窗的問題，也許跟省電或其他的websocket管理有關', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-15.md', '標題1': '1. 修復匯出摘錄時會用到之前資料的問題'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-25.md
# 3. 根據chrome extensione官方說明，30秒會自動將service worker關閉，因此採用25秒一次的心跳來解決這個問題[^1]
- 之後如果確認後端不會主動傳訊息給SW，則可以考慮改為http ( 只要修改send函數應該就行了 )

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-15.md
- 感覺不是純粹切視窗或關視窗的問題，也許跟省電或其他的websocket管理有關

==問題==
根據上文，service worker幾秒後會自動關閉?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.19715488
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-28.md\n# 9. 關於chrome-extension中不允許在html中直接呼叫javascript函數\n- 因為chrome-extension不允許CSP\n- 但好像可以用[這個](https://stackoverflow.com/questions/72186787/chrome-extensions-and-csp)允許特定網站的CSP?', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-28.md', '標題1': '9. 關於chrome-extension中不允許在html中直接呼叫javascript函數'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-04.md\n- <class \'str\'>不行，<class \'bytes\'>才對\n- 交叉比對\n- 另外開一個.py，避免非同步之類的問題\n- 就算在字串前加上u也沒用\n-\n- 和[這個](https://stackoverflow.com/questions/34618149/post-unicode-string-to-web-service-using-python-requests-library)情況有點類似\n- 實際原因是，requests針對text類的body，會自動使用ISO-8859-1編碼[^1]\n- 但實測將content-type改成 `text/markdown; charset=UTF-8` 也不行\n- github上同樣有人提出，但requests目前處於盡量不修改的狀況，因此雖然python3的整個生態都使用utf-8，但仍建議在requests時使用.encode("utf-8")轉成byte來傳送處理[^2]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-04.md', '標題1': '1. 系統'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-28.md
# 9. 關於chrome-extension中不允許在html中直接呼叫javascript函數
- 因為chrome-extension不允許CSP
- 但好像可以用[這個](https://stackoverflow.com/questions/72186787/chrome-extensions-and-csp)允許特定網站的CSP?

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-04.md
- <class 'str'>不行，<class 'bytes'>才對
- 交叉比對
- 另外開一個.py，避免非同步之類的問題
- 就算在字串前加上u也沒用
-
- 和[這個](https://stackoverflow.com/questions/34618149/post-unicode-string-to-web-service-using-python-requests-library)情況有點類似
- 實際原因是，requests針對text類的body，會自動使用ISO-8859-1編碼[^1]
- 但實測將content-type改成 `text/markdown; charset=UTF-8` 也不行
- github上同樣有人提出，但requests目前處於盡量不修改的狀況，因此雖然python3的整個生態都使用utf-8，但仍建議在requests時使用.encode("utf-8")轉成byte來傳送處理[^2]

==問題==
根據上文，為什麼chrome-extension不能在html中直接呼叫javascript函數
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.109264515
float32
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 50%|█████     | 18/36 [03:44<03:40, 12.24s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 53%|█████▎    | 19/36 [03:57<03:30, 12.37s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 56%|█████▌    | 20/36 [04:09<03:15, 12.25s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 58%|█████▊    | 21/36 [04:21<03:02, 12.19s/it][Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-13.md\n# 4. 閱讀論文\n- 在這篇[^4] 論文中提到，實驗中為了在最小化幻覺和嚴格生成之間取得平衡，將GPT的溫度設為0，llama的溫度設為0.1，但論文中未提及更詳細的理由', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-13.md', '標題1': '4. 閱讀論文'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md\nendpoint _url=" http://localhost:8080/" ,\ncache = False,\nmax _new_tokens=256,\ndo _sample=False, # 關閉採樣\ntop _k=1,\ntop _p=0.99,\ntemperature=0.1, # 已經關閉採樣了所以其實設多少都沒差\n)\n```\n```\nchat_completion = client.chat.completions.create(\nmessages=message_list,\ntemperature=0,\nmax_tokens=256,\n)\n```\n- 實驗證明\n1. langchain的chat就算設定do_sample為False也不是完全貪婪，尤其top_k是必要的\n2. 以上的參數可以使結果相同\n3. 雖然相關討論的結論認為關鍵在do_sample + temperature=None[^2]，但直覺上我覺得top_k也行', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md', '標題1': '2. 實驗'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-13.md
# 4. 閱讀論文
- 在這篇[^4] 論文中提到，實驗中為了在最小化幻覺和嚴格生成之間取得平衡，將GPT的溫度設為0，llama的溫度設為0.1，但論文中未提及更詳細的理由

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
endpoint _url=" http://localhost:8080/" ,
cache = False,
max _new_tokens=256,
do _sample=False, # 關閉採樣
top _k=1,
top _p=0.99,
temperature=0.1, # 已經關閉採樣了所以其實設多少都沒差
)
```
```
chat_completion = client.chat.completions.create(
messages=message_list,
temperature=0,
max_tokens=256,
)
```
- 實驗證明
1. langchain的chat就算設定do_sample為False也不是完全貪婪，尤其top_k是必要的
2. 以上的參數可以使結果相同
3. 雖然相關討論的結論認為關鍵在do_sample + temperature=None[^2]，但直覺上我覺得top_k也行

==問題==
根據上文，ChatGPT的溫度設為多少最恰當?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.20829745
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-22.md\n# 999. 其他\n- How can we evaluate the ability of each LLM to generate Cypher?\n- tag嵌套的必要性\n- markdown的結構化 #靈感\n- 例如tab代表有\n- 可能要重新考慮nDCG來比對[[Embeddeding|嵌入]]結果\n- 可能要檢查 [[Mean Average Precision|MAP]] 的算法是否有誤\n- 以前不熟悉的關鍵字會慢慢熟悉，要怎麼應對這種情況? #靈感\n[^1]: https://github.com/microsoft/terminal/issues/14018\n[^2]: https://stackoverflow.com/questions/32127524/how-to-install-and-use-make-in-windows', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-22.md', '標題1': '999. 其他'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-01-13.md\n# 4. 沒找到什麼特別有用的免費嵌入方式', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-01-13.md', '標題1': '4. 沒找到什麼特別有用的免費嵌入方式'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-22.md
# 999. 其他
- How can we evaluate the ability of each LLM to generate Cypher?
- tag嵌套的必要性
- markdown的結構化 #靈感
- 例如tab代表有
- 可能要重新考慮nDCG來比對[[Embeddeding|嵌入]]結果
- 可能要檢查 [[Mean Average Precision|MAP]] 的算法是否有誤
- 以前不熟悉的關鍵字會慢慢熟悉，要怎麼應對這種情況? #靈感
[^1]: https://github.com/microsoft/terminal/issues/14018
[^2]: https://stackoverflow.com/questions/32127524/how-to-install-and-use-make-in-windows

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-01-13.md
# 4. 沒找到什麼特別有用的免費嵌入方式

==問題==
根據上文，嵌入有可能遇到什麼問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.090603866
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-16.md\n# 1. [[Whisper]]\n嘗試解決幻覺問題\nhttps://github.com/openai/whisper/discussions/679\n加上參數--condition_on_previous_text False  \n##  評估方式?\n根據不同面向，例如冗字、專有名詞，其他錯誤等  \n又加了一堆論文哈哈', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-16.md', '標題1': '1. [[Whisper]]'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-05.md\n# 4. 測試[[SpeechRecognition]]\n建立虛擬環境並安裝此套件，\nclone範例程式<https://github.com/Uberi/speech_recognition/blob/master/examples/microphone_recognition.py>\n1. 實驗[[Sphinx]]及[[Google Speech Recognition]]兩個語音辨識API\n安裝pocketsphinx\n2. 實驗background_listening\n1. 安裝[[PyAudio]]\n結論: 在中文精準度上需要多測試，可能要找找看[[機器學習]]方面的辨識方法。', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-05.md', '標題1': '4. 測試[[SpeechRecognition]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-16.md
# 1. [[Whisper]]
嘗試解決幻覺問題
https://github.com/openai/whisper/discussions/679
加上參數--condition_on_previous_text False  
##  評估方式?
根據不同面向，例如冗字、專有名詞，其他錯誤等  
又加了一堆論文哈哈

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-05.md
# 4. 測試[[SpeechRecognition]]
建立虛擬環境並安裝此套件，
clone範例程式<https://github.com/Uberi/speech_recognition/blob/master/examples/microphone_recognition.py>
1. 實驗[[Sphinx]]及[[Google Speech Recognition]]兩個語音辨識API
安裝pocketsphinx
2. 實驗background_listening
1. 安裝[[PyAudio]]
結論: 在中文精準度上需要多測試，可能要找找看[[機器學習]]方面的辨識方法。

==問題==
根據上文，有哪些方法可以解決語音辨識的幻聽問題
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16820273
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md\n# 3. 除了降噪外其他可能影響語音識別的因素\n#靈感/語音識別\n1. 聲道\n2. 取樣率\n3. 語速\n4. bit率', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md', '標題1': '3. 除了降噪外其他可能影響語音識別的因素'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-19.md\n# 今日計畫\n- [ ] 論文整理\n- [ ] 語音助理技術進展\n- [ ] 基於[[Knowledge Base]]的GPT似乎已存在了，檢查相關方法\nhttps://www.bilibili.com/video/BV19o4y1J7mL/?spm_id_from=333.788.recommend_more_video.18&vd_source=591675bcd42bc693ef34911801b34eb2\n- [ ] 將上課或會議內容錄音後，藉由語音辨識產生知識本體的可能性\n- [ ] 比較不同降噪間的逐字稿結果是否不同\n- [ ] 有沒有比較高效或公正的檢查標準?\n- [ ] 不同模型\n- [ ] sentence to triple的技術', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-19.md', '標題1': '今日計畫'})]
format後的prompt:D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 61%|██████    | 22/36 [04:28<02:31, 10.79s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 64%|██████▍   | 23/36 [04:39<02:19, 10.76s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 67%|██████▋   | 24/36 [05:13<03:34, 17.85s/it] Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-19.md
# 今日計畫
- [ ] 論文整理
- [ ] 語音助理技術進展
- [ ] 基於[[Knowledge Base]]的GPT似乎已存在了，檢查相關方法
https://www.bilibili.com/video/BV19o4y1J7mL/?spm_id_from=333.788.recommend_more_video.18&vd_source=591675bcd42bc693ef34911801b34eb2
- [ ] 將上課或會議內容錄音後，藉由語音辨識產生知識本體的可能性
- [ ] 比較不同降噪間的逐字稿結果是否不同
- [ ] 有沒有比較高效或公正的檢查標準?
- [ ] 不同模型
- [ ] sentence to triple的技術

==問題==
根據上文，語音辨識可以有哪些評估的方向
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.071613215
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md\n# 3. 關於瀏覽器插件的溝通方式選擇\npipe or websocket\n選擇websocket，因為javascript無法操作作業系統層級的pipe\n查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe\n理論上也確實如此，否則瀏覽器插件的權限很容易太大', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md', '標題1': '3. 關於瀏覽器插件的溝通方式選擇'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-11.md\n# 3. Vosk使用測試\n![[Vosk#0910實驗記錄]]\n#筆記用標籤/疑問 為什麼使用pip安裝後就可以使用command line tool?', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-11.md', '標題1': '3. Vosk使用測試'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 3. 關於瀏覽器插件的溝通方式選擇
pipe or websocket
選擇websocket，因為javascript無法操作作業系統層級的pipe
查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe
理論上也確實如此，否則瀏覽器插件的權限很容易太大

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-11.md
# 3. Vosk使用測試
![[Vosk#0910實驗記錄]]
#筆記用標籤/疑問 為什麼使用pip安裝後就可以使用command line tool?

==問題==
根據上文，為什麼瀏覽器插件不使用pipe?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2258542
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md\n# 3. 除了降噪外其他可能影響語音識別的因素\n#靈感/語音識別\n1. 聲道\n2. 取樣率\n3. 語速\n4. bit率', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md', '標題1': '3. 除了降噪外其他可能影響語音識別的因素'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-28.md\n# 1. 關於語音辨識準確度\n![[Automatic Speech Recognition#關於準確度]]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-28.md', '標題1': '1. 關於語音辨識準確度'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-28.md
# 1. 關於語音辨識準確度
![[Automatic Speech Recognition#關於準確度]]

==問題==
根據上文，哪些因素可能會影響語音識別？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.26710048
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-30.md\n# 3. 將宿舍電腦的 StableDiffusion 虛擬環境中的 [[pytorch]] 更新到pytorch2[^1]\n1. 切換到虛擬環境\n`.\\envs\\scripts\\activate.bat`\n2. 檢查pip路徑\n`pip --version`\n3. 參考[官網](https://pytorch.org/get-started/locally/)訊息，CUDA11.8\n`pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`\n4. 結果\n```\nInstalling collected packages: mpmath, sympy, torch, torchvision, torchaudio\nAttempting uninstall: torch\nFound existing installation: torch 1.13.1+cu117', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-30.md', '標題1': '3. 將宿舍電腦的 StableDiffusion 虛擬環境中的 [[pytorch]] 更新到pytorch2[^1]'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-07-27.md\n# 4. 嘗試[[ChatPaper2Xmind]]\n參考README\n```\ngit clone git@github.com:MasterYip/ChatPaper2Xmind.git\npip install -r requirements.txt\ngit submodule update --init --recursive\n```\n設定config.py，包含API key及LANGUAGE = "Chinese"\npython paper2xmind.py  \n報錯:\n```\nYou exceeded your current quota, please check your plan and billing details.\n```\nChatGPT要付錢啦嗚嗚嗚', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-07-27.md', '標題1': '4. 嘗試[[ChatPaper2Xmind]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-30.md
# 3. 將宿舍電腦的 StableDiffusion 虛擬環境中的 [[pytorch]] 更新到pytorch2[^1]
1. 切換到虛擬環境
`.\envs\scripts\activate.bat`
2. 檢查pip路徑
`pip --version`
3. 參考[官網](https://pytorch.org/get-started/locally/)訊息，CUDA11.8
`pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`
4. 結果
```
Installing collected packages: mpmath, sympy, torch, torchvision, torchaudio
Attempting uninstall: torch
Found existing installation: torch 1.13.1+cu117

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-27.md
# 4. 嘗試[[ChatPaper2Xmind]]
參考README
```
git clone git@github.com:MasterYip/ChatPaper2Xmind.git
pip install -r requirements.txt
git submodule update --init --recursive
```
設定config.py，包含API key及LANGUAGE = "Chinese"
python paper2xmind.py  
報錯:
```
You exceeded your current quota, please check your plan and billing details.
```
ChatGPT要付錢啦嗚嗚嗚

==問題==
根據上文，我參考了哪個教學將pytorch更新到pytorch2?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.3263341
float32
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 69%|██████▉   | 25/36 [05:24<02:53, 15.73s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 72%|███████▏  | 26/36 [05:33<02:17, 13.71s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 75%|███████▌  | 27/36 [05:47<02:04, 13.87s/it][Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-28.md\n# 999. 靈感  \n[^1]: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=key1YF/record?r1=16&h1=0\n[^2]: https://aws.amazon.com/tw/compare/the-difference-between-grpc-and-rest/', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-28.md', '標題1': '999. 靈感'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-20.md\n# 999. 靈感\n- 在[這篇](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/discussions/82)討論區中提到，幫選擇題加上「以上皆非」是一個不錯的想法\n- 關於比較模型的部分，可以用比較的方式  \n[^6]: https://medium.com/%E5%BD%BC%E5%BE%97%E6%BD%98%E7%9A%84-swift-ios-app-%E9%96%8B%E7%99%BC%E5%95%8F%E9%A1%8C%E8%A7%A3%E7%AD%94%E9%9B%86/%E7%94%A8%E8%80%81%E5%B8%AB-%E5%AD%B8%E7%94%9F%E8%BA%AB%E4%BB%BD%E5%85%8D%E8%B2%BB%E4%BD%BF%E7%94%A8-github-copilot-223236e0e0e8', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-20.md', '標題1': '999. 靈感'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-28.md
# 999. 靈感  
[^1]: https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=key1YF/record?r1=16&h1=0
[^2]: https://aws.amazon.com/tw/compare/the-difference-between-grpc-and-rest/

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-20.md
# 999. 靈感
- 在[這篇](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/discussions/82)討論區中提到，幫選擇題加上「以上皆非」是一個不錯的想法
- 關於比較模型的部分，可以用比較的方式  
[^6]: https://medium.com/%E5%BD%BC%E5%BE%97%E6%BD%98%E7%9A%84-swift-ios-app-%E9%96%8B%E7%99%BC%E5%95%8F%E9%A1%8C%E8%A7%A3%E7%AD%94%E9%9B%86/%E7%94%A8%E8%80%81%E5%B8%AB-%E5%AD%B8%E7%94%9F%E8%BA%AB%E4%BB%BD%E5%85%8D%E8%B2%BB%E4%BD%BF%E7%94%A8-github-copilot-223236e0e0e8

==問題==
根據上文，bibtex和ris差在哪？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.4384315
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-11-23.md\n# 2. 研究過程中，除了這個研究的貢獻外，在相關研究中也可以得到很多資訊\n可以在筆記中包含，提到這篇研究的研究、該研究中的說明、評價、引用編號等\n#靈感', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-11-23.md', '標題1': '2. 研究過程中，除了這個研究的貢獻外，在相關研究中也可以得到很多資訊'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-01-10.md\n# 1. [閱讀筆記](https://blog.csdn.net/Delusional/article/details/109186531)\n- 讀完一篇論文後可以用表格等方式將論文的內容簡單紀錄，包含以下資訊:\n1. 來源\n2. 研究機構Institution\n3. 論文Paper\n4. 關鍵字Topic\n5. 目標Aim\n6. 研究問題Problem to solve\n7. 解決方法Solutions\n8. 阻礙?Strength\n9. 限制\n10. 資料集\n11. 評估分數Evaluation Score\n12. 程式碼', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-01-10.md', '標題1': '1. [閱讀筆記](https://blog.csdn.net/Delusional/article/details/109186531)'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-11-23.md
# 2. 研究過程中，除了這個研究的貢獻外，在相關研究中也可以得到很多資訊
可以在筆記中包含，提到這篇研究的研究、該研究中的說明、評價、引用編號等
#靈感

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-01-10.md
# 1. [閱讀筆記](https://blog.csdn.net/Delusional/article/details/109186531)
- 讀完一篇論文後可以用表格等方式將論文的內容簡單紀錄，包含以下資訊:
1. 來源
2. 研究機構Institution
3. 論文Paper
4. 關鍵字Topic
5. 目標Aim
6. 研究問題Problem to solve
7. 解決方法Solutions
8. 阻礙?Strength
9. 限制
10. 資料集
11. 評估分數Evaluation Score
12. 程式碼

==問題==
根據上文，可以從論文的相關研究中得到什麼？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.44338506
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-01-13.md\n問題：請介紹這篇論文\n回答：\n這篇論文介紹了一個學術知識圖譜問答（KGQA）系統，該系統利用大型語言模型（LLM）以few-shot方式回答文獻資料庫中的自然語言問題。該模型通過一個基於BERT的句子編碼器識別與測試問題相關的前n個相似訓練問題，並檢索它們對應的SPARQL查詢語句。使用這些相似問題-SPARQL對作為示例，與測試問題一起創建一個提示語句，然後將提示語句傳遞給LLM進行SPARQL生成。最後，運行SPARQL查詢以對應的學術知識圖譜進行查詢，並返回答案。這個系統在SciQA測試集上達到了99.0\\%的F1分數，是Scholarly-QALD-23挑戰賽SciQA排行榜的亞軍。\n```\n```\n(myLLM) domaj@Domaj-server:~/Research/myLLM$ python step2.query.py\nDistance: [[0.49441427 0.5016975  0.50322545 0.5052259  0.51162815]]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-01-13.md', '標題1': '5. 用 [[OpenAI]] API實做簡單的檔案問答'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-10-04.md\n# 2. 找時間測試pizza.owl\n- [ ] 找時間測試pizza.owl (@2023-10-27)', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-10-04.md', '標題1': '2. 找時間測試pizza.owl'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-01-13.md
問題：請介紹這篇論文
回答：
這篇論文介紹了一個學術知識圖譜問答（KGQA）系統，該系統利用大型語言模型（LLM）以few-shot方式回答文獻資料庫中的自然語言問題。該模型通過一個基於BERT的句子編碼器識別與測試問題相關的前n個相似訓練問題，並檢索它們對應的SPARQL查詢語句。使用這些相似問題-SPARQL對作為示例，與測試問題一起創建一個提示語句，然後將提示語句傳遞給LLM進行SPARQL生成。最後，運行SPARQL查詢以對應的學術知識圖譜進行查詢，並返回答案。這個系統在SciQA測試集上達到了99.0\%的F1分數，是Scholarly-QALD-23挑戰賽SciQA排行榜的亞軍。
```
```
(myLLM) domaj@Domaj-server:~/Research/myLLM$ python step2.query.py
Distance: [[0.49441427 0.5016975  0.50322545 0.5052259  0.51162815]]

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-04.md
# 2. 找時間測試pizza.owl
- [ ] 找時間測試pizza.owl (@2023-10-27)

==問題==
根據上文，土豆挑戰是什麼？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1314348
float32
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 78%|███████▊  | 28/36 [05:56<01:38, 12.34s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 81%|████████  | 29/36 [06:08<01:24, 12.10s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 83%|████████▎ | 30/36 [06:19<01:10, 11.80s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 86%|████████▌ | 31/36 [06:25<00:50, 10.16s/it][Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-08.md\n# 1. 撰寫chrome extension\n- 關於popus.js和background.js的溝通\n- 遇到錯誤 `Unchecked runtime.lastError: The message port closed before a response was received.`\n- 經過正確的使用sendmessage的callback的第三個參數sendResponse完成完整的溝通。\n- 準確的說是service-worker，因為在版本三中並沒有background page的存在，而是改為service worker。\n- 同上，有很多用法在第二版可以用，但在第三版不能用。', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-08.md', '標題1': '1. 撰寫chrome extension'}), Document(page_content="來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md\n# 5. bug\n1. DOMException: Failed to execute 'send' on 'WebSocket': Still in CONNECTING state.\n[參考](https://stackoverflow.com/questions/23051416/uncaught-invalidstateerror-failed-to-execute-send-on-websocket-still-in-co)將傳送訊息函數包在open=>{}中，確保傳送訊息前已經建立好連線", metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md', '標題1': '5. bug'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-08.md
# 1. 撰寫chrome extension
- 關於popus.js和background.js的溝通
- 遇到錯誤 `Unchecked runtime.lastError: The message port closed before a response was received.`
- 經過正確的使用sendmessage的callback的第三個參數sendResponse完成完整的溝通。
- 準確的說是service-worker，因為在版本三中並沒有background page的存在，而是改為service worker。
- 同上，有很多用法在第二版可以用，但在第三版不能用。

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 5. bug
1. DOMException: Failed to execute 'send' on 'WebSocket': Still in CONNECTING state.
[參考](https://stackoverflow.com/questions/23051416/uncaught-invalidstateerror-failed-to-execute-send-on-websocket-still-in-co)將傳送訊息函數包在open=>{}中，確保傳送訊息前已經建立好連線

==問題==
根據上文，如何解決The message port closed before a response was received
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.062017523
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-22.md\n- 註: daemon關閉時會強制關閉，若有讀寫檔、暫存檔等需要額外處理，例如在主thread中捕捉相關的事件。  \n- ChatGPT用模擬ctrl+c的方式實現自訂義複製快捷鍵，我喜歡\n- 本來無法模擬ctrl+c，後來發現是因為模擬前沒有放開實體按鍵，使用time.sleep或keyboard.release都能解決這個問題，也不需要管理員權限  \n- 讀取當前焦點視窗\n- 暫時先考慮windows，不考慮mac和linux，因此使用pywin32  \n- [[cypher]] 的參數化查詢無法用於標籤或關係上，因此需要使用python的格式化輸入來處理\n`query = f"MATCH (n:{tagName})"`', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-22.md', '標題1': '2. python的系統級快捷鍵'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-13.md\n# 5. [[FastAPI]]\n- Python的酷套件，要找時間把系統改成這個', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-13.md', '標題1': '5. [[FastAPI]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-22.md
- 註: daemon關閉時會強制關閉，若有讀寫檔、暫存檔等需要額外處理，例如在主thread中捕捉相關的事件。  
- ChatGPT用模擬ctrl+c的方式實現自訂義複製快捷鍵，我喜歡
- 本來無法模擬ctrl+c，後來發現是因為模擬前沒有放開實體按鍵，使用time.sleep或keyboard.release都能解決這個問題，也不需要管理員權限  
- 讀取當前焦點視窗
- 暫時先考慮windows，不考慮mac和linux，因此使用pywin32  
- [[cypher]] 的參數化查詢無法用於標籤或關係上，因此需要使用python的格式化輸入來處理
`query = f"MATCH (n:{tagName})"`

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-13.md
# 5. [[FastAPI]]
- Python的酷套件，要找時間把系統改成這個

==問題==
根據上文，哪些python套件能監聽快捷鍵？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2724631
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-16.md\n`mklink "E:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin\\make.exe" "E:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin\\mingw32-make.exe"`\n- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`\n- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性\n- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要\n- [ ] 整理文獻\n- [ ] 閱讀清單', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-16.md', '標題1': '0. 今日計畫'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-04.md\n# [[SpeechBrain]]測試\n1. 新增[[conda]]虛擬環境後安裝相依套件，按照官方說明\n``` console\nconda install pip\ngit clone https://github.com/speechbrain/speechbrain/\ncd /content/speechbrain/\npip install -r requirements.txt\npip install -e .\n```', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-04.md', '標題1': '[[SpeechBrain]]測試'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-16.md
`mklink "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\make.exe" "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\mingw32-make.exe"`
- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`
- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性
- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要
- [ ] 整理文獻
- [ ] 閱讀清單

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-04.md
# [[SpeechBrain]]測試
1. 新增[[conda]]虛擬環境後安裝相依套件，按照官方說明
``` console
conda install pip
git clone https://github.com/speechbrain/speechbrain/
cd /content/speechbrain/
pip install -r requirements.txt
pip install -e .
```

==問題==
根據上文，除了pyqt外，當時還考慮哪些類似的套件？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.14854458
float32
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 89%|████████▉ | 32/36 [06:41<00:48, 12.00s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 92%|█████████▏| 33/36 [06:52<00:34, 11.47s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 94%|█████████▍| 34/36 [07:02<00:22, 11.05s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 97%|█████████▋| 35/36 [07:08<00:09,  9.54s/it][Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-16.md\n# 999. 其他\n- 根據FastAPI的文檔，建議使用Union來取代Optional功能，但範例中有點錯誤\n- 建議避免使用 `name: Optional[str]`，因為實際上name並不是可選的而是必選的\n- 就算使用 `def say_hi(name: str | None)` 也不代表不需要參數，必須要設定初始值，如 `def say_hi(name: str | None = None)`  \n[^1]: https://stackoverflow.com/questions/63872924/how-can-i-send-an-http-request-from-my-fastapi-app-to-another-site-api\n[^2]: https://scrapfly.io/blog/httpx-vs-requests-vs-aiohttp/', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-16.md', '標題1': '999. 其他'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-16.md\n# 1. 系統\n- neo4j\n- 根據[官方教學](https://neo4j.com/docs/operations-manual/current/configuration/connectors/) 修改neo4j的監聽ip讓台北電腦測試neo4j chain', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-16.md', '標題1': '1. 系統'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-16.md
# 999. 其他
- 根據FastAPI的文檔，建議使用Union來取代Optional功能，但範例中有點錯誤
- 建議避免使用 `name: Optional[str]`，因為實際上name並不是可選的而是必選的
- 就算使用 `def say_hi(name: str | None)` 也不代表不需要參數，必須要設定初始值，如 `def say_hi(name: str | None = None)`  
[^1]: https://stackoverflow.com/questions/63872924/how-can-i-send-an-http-request-from-my-fastapi-app-to-another-site-api
[^2]: https://scrapfly.io/blog/httpx-vs-requests-vs-aiohttp/

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-16.md
# 1. 系統
- neo4j
- 根據[官方教學](https://neo4j.com/docs/operations-manual/current/configuration/connectors/) 修改neo4j的監聽ip讓台北電腦測試neo4j chain

==問題==
根據上文，系統中的FastAPI監聽哪個端口？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.28215396
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md\n# 3. 找到新關鍵字(ChatGPT)\n- Multi-Source Information Management\n- RALM，重要，需要了解具體定義及其與RAG的區別', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md', '標題1': '3. 找到新關鍵字(ChatGPT)'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md\n- [ ] [NEUMAI](https://docs.neum.ai/get-started/introduction)  \n- [ ] 待實驗\n- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/\n- [ ] GEMMA\n- [ ] [[HyDE]]\n- [ ] LLM的上下文與few-shot\n- 系統\n- [ ] 設計整個架構和所需要的API需求及文件\n- [ ] 浮動視窗，類似字典', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md', '標題1': '0. 今日計畫'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
- [ ] [NEUMAI](https://docs.neum.ai/get-started/introduction)  
- [ ] 待實驗
- [ ] https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/
- [ ] GEMMA
- [ ] [[HyDE]]
- [ ] LLM的上下文與few-shot
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典

==問題==
根據上文，RALM類似什麼概念？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.04661884
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-11.md\n# 1. 修改論文\n- Multi-Source Data Analysis與Multi-source infomation management system\n- 多源資料分析主要注重統合、轉換、除錯並分析資料\n- 多源資訊管理主要目的在蒐集與管理資訊', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-11.md', '標題1': '1. 修改論文'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md\n# 3. 找到新關鍵字(ChatGPT)\n- Multi-Source Information Management\n- RALM，重要，需要了解具體定義及其與RAG的區別', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md', '標題1': '3. 找到新關鍵字(ChatGPT)'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-11.md
# 1. 修改論文
- Multi-Source Data Analysis與Multi-source infomation management system
- 多源資料分析主要注重統合、轉換、除錯並分析資料
- 多源資訊管理主要目的在蒐集與管理資訊

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

==問題==
根據上文，多源資料分析和管理差在哪？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.06321003
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-18.md\n[^10]: https://community.neo4j.com/t/import-individuals-and-relate-to-classes-in-neo4j/24567/2', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-18.md', '標題1': '999. 靈感'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-09.md\n# 1. 閱讀文獻\n- 看完並整理Dai, Zhuyun, Vincent Y. Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov, Kelvin Guu, Keith B. Hall及Ming-Wei Chang. 「Promptagator: Few-Shot Dense Retrieval From 8 Examples」. arXiv, 2022年9月23日. [https://doi.org/10.48550/arXiv.2209.11755](https://doi.org/10.48550/arXiv.2209.11755).', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-09.md', '標題1': '1. 閱讀文獻'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-18.md
[^10]: https://community.neo4j.com/t/import-individuals-and-relate-to-classes-in-neo4j/24567/2

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-09.md
# 1. 閱讀文獻
- 看完並整理Dai, Zhuyun, Vincent Y. Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov, Kelvin Guu, Keith B. Hall及Ming-Wei Chang. 「Promptagator: Few-Shot Dense Retrieval From 8 Examples」. arXiv, 2022年9月23日. [https://doi.org/10.48550/arXiv.2209.11755](https://doi.org/10.48550/arXiv.2209.11755).

==問題==
根據上文，在2024/4/17，我看完NEUMAI了嗎？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2960534
float32
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

100%|██████████| 36/36 [07:19<00:00, 10.13s/it]
100%|██████████| 36/36 [07:19<00:00, 12.22s/it]
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-27.md\n# 2. 跑實驗', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-27.md', '標題1': '2. 跑實驗'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-24.md\n# 1. [[Whisper-Finetune]]\n![[Whisper-Finetune#0924實驗]]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-24.md', '標題1': '1. [[Whisper-Finetune]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-24.md
# 1. [[Whisper-Finetune]]
![[Whisper-Finetune#0924實驗]]

==問題==
根據上文，在2024/4/17，我做了什麼實驗？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.0678077
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-14.md\n- TAIDE-llama3\n- nf4: 01:05，可filter\n- eetq: 01:06, 可filter\n- 實驗mistral-7B的fine-tune，MediaTek-Research/Breeze-7B-Instruct-v0_1\n- eetq: 基礎測試34秒，通過魔法測驗、\n-', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-14.md', '標題1': '1. 實驗'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-18.md\n# 0. 今日計畫\n- [ ] 整理文獻\n- [ ] 待實驗\n- [ ] GEMMA\n- [ ] [[HyDE]]\n- [ ] LLM的上下文與few-shot\n- 系統\n- [ ] 設計整個架構和所需要的API需求及文件\n- [ ] 浮動視窗，類似字典\n- 教育版copilot，要印英文在校證明[^6]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-18.md', '標題1': '0. 今日計畫'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-14.md
- TAIDE-llama3
- nf4: 01:05，可filter
- eetq: 01:06, 可filter
- 實驗mistral-7B的fine-tune，MediaTek-Research/Breeze-7B-Instruct-v0_1
- eetq: 基礎測試34秒，通過魔法測驗、
-

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-18.md
# 0. 今日計畫
- [ ] 整理文獻
- [ ] 待實驗
- [ ] GEMMA
- [ ] [[HyDE]]
- [ ] LLM的上下文與few-shot
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典
- 教育版copilot，要印英文在校證明[^6]

==問題==
根據上文，在2024/4/17，我實驗過gemma了嗎?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.10619263
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-07.md\n- [ ] [[HyDE]]\n- 系統\n- [ ] 設計整個架構和所需要的API需求及文件\n- [ ] 浮動視窗，類似字典', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-07.md', '標題1': '0. 今日計畫'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-18.md\n# 0. 今日計畫\n- [ ] 整理文獻\n- [ ] 待實驗\n- [ ] GEMMA\n- [ ] [[HyDE]]\n- [ ] LLM的上下文與few-shot\n- 系統\n- [ ] 設計整個架構和所需要的API需求及文件\n- [ ] 浮動視窗，類似字典\n- 教育版copilot，要印英文在校證明[^6]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-18.md', '標題1': '0. 今日計畫'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-07.md
- [ ] [[HyDE]]
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-18.md
# 0. 今日計畫
- [ ] 整理文獻
- [ ] 待實驗
- [ ] GEMMA
- [ ] [[HyDE]]
- [ ] LLM的上下文與few-shot
- 系統
- [ ] 設計整個架構和所需要的API需求及文件
- [ ] 浮動視窗，類似字典
- 教育版copilot，要印英文在校證明[^6]

==問題==
根據上文，在2024/4/17，我設計完整個架構和所需要的API需求及文件了嗎？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.12266735
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-17.md\n# 2. 試用 [[Chat RTX]]\n- 38G，好大\n- 下載好久，安裝好久，安裝一個多小時吧，包含下載模型的時間\n- 吃爆VRAM、反應不快，基本只收英文\n- 因為很卡所以沒有繼續測試下去  \n[^3]: https://www.volcengine.com/theme/3863827-W-7-1\n[^4]: https://www.pythonforbeginners.com/basics/convert-ini-to-yaml-in-python\n[^5]: https://docs.privategpt.dev/recipes/choice-of-llm/list-of-ll-ms', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-17.md', '標題1': '2. 試用 [[Chat RTX]]'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md\n- Langchain的chat參數說明在[這裡](https://api.python.langchain.com/en/latest/chat_models/langchain_community.chat_models.huggingface.ChatHuggingFace.html#langchain_community.chat_models.huggingface.ChatHuggingFace)\n- ChatGPT的Create參數說明在[這裡](https://platform.openai.com/docs/api-reference/chat/create)\n- chat_template儲存在tokenizer.config.json中，transformers的autotokenizer會自動讀取', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md', '標題1': '2. 實驗'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-17.md
# 2. 試用 [[Chat RTX]]
- 38G，好大
- 下載好久，安裝好久，安裝一個多小時吧，包含下載模型的時間
- 吃爆VRAM、反應不快，基本只收英文
- 因為很卡所以沒有繼續測試下去  
[^3]: https://www.volcengine.com/theme/3863827-W-7-1
[^4]: https://www.pythonforbeginners.com/basics/convert-ini-to-yaml-in-python
[^5]: https://docs.privategpt.dev/recipes/choice-of-llm/list-of-ll-ms

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
- Langchain的chat參數說明在[這裡](https://api.python.langchain.com/en/latest/chat_models/langchain_community.chat_models.huggingface.ChatHuggingFace.html#langchain_community.chat_models.huggingface.ChatHuggingFace)
- ChatGPT的Create參數說明在[這裡](https://platform.openai.com/docs/api-reference/chat/create)
- chat_template儲存在tokenizer.config.json中，transformers的autotokenizer會自動讀取

==問題==
根據上文，我對ChatRTX的評價是正面還是負面
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.056782953
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-21.md\n# 2. 跑實驗\n- google/gemma-2b-it\n- 約20分鐘\n- google/gemma-2b\n- 約20分鐘\n- meta-llama/Llama-2-7b-chat-hf\n- 約一小時', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-21.md', '標題1': '2. 跑實驗'}), Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-27.md\n# 2. 跑實驗', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-27.md', '標題1': '2. 跑實驗'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-21.md
# 2. 跑實驗
- google/gemma-2b-it
- 約20分鐘
- google/gemma-2b
- 約20分鐘
- meta-llama/Llama-2-7b-chat-hf
- 約一小時

來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-27.md
# 2. 跑實驗

==問題==
根據上文，在2024/4/21，我總共花了幾分鐘跑實驗
請用20個字簡潔回答問題。

None

(server) E:\Research\extension\chrome-extension>[06:41:31]python -m modules.rag

  0%|          | 0/36 [00:00<?, ?it/s]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  3%|▎         | 1/36 [00:16<09:46, 16.75s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  6%|▌         | 2/36 [00:29<08:08, 14.36s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

  8%|▊         | 3/36 [00:40<07:02, 12.81s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 11%|█         | 4/36 [00:49<06:00, 11.28s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 14%|█▍        | 5/36 [00:59<05:38, 10.91s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 17%|█▋        | 6/36 [01:05<04:39,  9.31s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 19%|█▉        | 7/36 [01:17<04:52, 10.10s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 22%|██▏       | 8/36 [01:27<04:42, 10.10s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 25%|██▌       | 9/36 [01:36<04:20,  9.64s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 28%|██▊       | 10/36 [01:50<04:43, 10.92s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 31%|███       | 11/36 [02:02<04:47, 11.51s/it]嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.03604612
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-07-24.md\n# 新增宿舍的筆記同步\n1. 參考[[Git指令]]，新增ssh key\n2. 使用ssh -T測試OK\n3. 用[[git clone]]將整份筆記下載\n4. 在Obsidian中開啟vault\n5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)\n6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題\n7. 使用以下指令重製ssh-key密碼為空\n```\nssh-keygen -p -f github_key\n```\n8. 重製為空後即可正常使用\n註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-07-24.md', '標題1': '新增宿舍的筆記同步'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-07-24.md
# 新增宿舍的筆記同步
1. 參考[[Git指令]]，新增ssh key
2. 使用ssh -T測試OK
3. 用[[git clone]]將整份筆記下載
4. 在Obsidian中開啟vault
5. [[obsidian-git]]已自動安裝完成，設定也同步完成(只有快捷鍵不知道為甚麼變成commit)
6. 但[[obsidian-git]]無法push，報錯無法連線到Obsidian sync.git，但[[Source tree]]可以，推測是ssh-key的密碼問題
7. 使用以下指令重製ssh-key密碼為空
```
ssh-keygen -p -f github_key
```
8. 重製為空後即可正常使用
註: 使用ssh-add等[[ssh agent]]功能應該也能解決，但由於ssh-add指令用錯參數導致實驗失敗，就直接將密碼重製了。

==問題==
根據上文，如何設定Obsidian同步?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.057200395
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-03.md\n>In computing, an ontology is then a concrete, formal representation—a convention—on what terms mean within the scope in which they are used (e.g., a given domain). Like all conventions, the usefulness of an ontology depends on how broadly and consistently it is adopted and how detailed it is. Knowledge graphs that use a shared ontology will be more interoperable. Given that ontologies are formal representations, they can further be used to', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-03.md', '標題1': '1. 釐清知識本體和知識圖譜的差別'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-03.md
>In computing, an ontology is then a concrete, formal representation—a convention—on what terms mean within the scope in which they are used (e.g., a given domain). Like all conventions, the usefulness of an ontology depends on how broadly and consistently it is adopted and how detailed it is. Knowledge graphs that use a shared ontology will be more interoperable. Given that ontologies are formal representations, they can further be used to

==問題==
根據上文，Ontology是什麼?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2588572
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-07.md\n# 2. 測試[[LLaMA2]]\n中文支援不佳，嘗試使用中文微調專案[[Chinese-LLaMA-Alpaca-2]]\n及webui專案[[text-generation-webui]]\n設定參考[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh)\n- 須解決簡體中文的問題', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-07.md', '標題1': '2. 測試[[LLaMA2]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-07.md
# 2. 測試[[LLaMA2]]
中文支援不佳，嘗試使用中文微調專案[[Chinese-LLaMA-Alpaca-2]]
及webui專案[[text-generation-webui]]
設定參考[https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/text-generation-webui_zh)
- 須解決簡體中文的問題

==問題==
根據上文，llama支援中文嗎?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1619676
float32
[Document(page_content="來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md\n# [[MySQL]]匯出檔案\n參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join\n``` mysql\nmysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG\nHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;", metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md', '標題1': '[[MySQL]]匯出檔案'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

==問題==
根據上文，在mysql中如何將多張表合併?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.32915065
float32
[Document(page_content="來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md\n# [[MySQL]]匯出檔案\n參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join\n``` mysql\nmysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG\nHT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;", metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-08-14.md', '標題1': '[[MySQL]]匯出檔案'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-08-14.md
# [[MySQL]]匯出檔案
參考:https://stackoverflow.com/questions/4018123/export-a-mysql-table-via-join
``` mysql
mysql> SELECT A.id as `標準症狀ID`, A.standard_symptoms as `標準症狀`, C.id as `原始症狀ID`, C.original_symptoms as `原始症狀` INTO OUTFILE '/home/zeus/result.csv' FROM `standard_symptoms_table` as A RIG
HT JOIN `symptoms_mapping_table` as B on A.id = B.standard_symptoms_ID left join `original_symptoms_table` as C on B.original_symptoms_ID = C.id;

==問題==
根據上文，如何將mysql的表匯出?
請用20個字簡潔回答問題。

D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 33%|███▎      | 12/36 [02:13<04:30, 11.29s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 36%|███▌      | 13/36 [02:19<03:42,  9.66s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 39%|███▉      | 14/36 [02:31<03:44, 10.22s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 42%|████▏     | 15/36 [02:39<03:24,  9.76s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 44%|████▍     | 16/36 [02:53<03:36, 10.83s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 47%|████▋     | 17/36 [03:03<03:22, 10.64s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 50%|█████     | 18/36 [03:13<03:11, 10.65s/it]嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1116085
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-06.md\n# 4. 在引用上實在很不方便，找了一些別的插件\nhttp://ob-plugin.eryajf.net/#/ob-plugin/01.Obsidian%E6%8F%92%E4%BB%B6%E5%91%A8%E5%88%8A%E7%AC%AC%E4%B8%80%E6%9C%9F', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-06.md', '標題1': '4. 在引用上實在很不方便，找了一些別的插件'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-06.md
# 4. 在引用上實在很不方便，找了一些別的插件
http://ob-plugin.eryajf.net/#/ob-plugin/01.Obsidian%E6%8F%92%E4%BB%B6%E5%91%A8%E5%88%8A%E7%AC%AC%E4%B8%80%E6%9C%9F

==問題==
根據上文，什麼時候安裝了obsidian的引用外掛?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.11549372
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md\n# 4. 如何選擇port?\n參考[^2] ，選擇沒人佔用的27709  \n[^1]: https://stackoverflow.com/questions/42631509/piping-node-js-to-python\n[^2]: https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=27709', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md', '標題1': '4. 如何選擇port?'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 4. 如何選擇port?
參考[^2] ，選擇沒人佔用的27709  
[^1]: https://stackoverflow.com/questions/42631509/piping-node-js-to-python
[^2]: https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?search=27709

==問題==
根據上文，怎麼選擇端口的?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.35214102
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-21.md\n# 4. 開會\n- 冒號問題，如果資訊比較不重要可以刪除\n- 或者用減號、全形冒號等\n```\n▸標籤管理實作\n▸PDF抽取方法實驗及整理\n▸s2orc-doc2json、 grobid\n▸文獻閱讀: Too many tags spoil the metadata: investigating the knowledge management of scientific research with semantic web technologies(2019)\n▸其他: 冒號問題\n```', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-21.md', '標題1': '4. 開會'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-21.md
# 4. 開會
- 冒號問題，如果資訊比較不重要可以刪除
- 或者用減號、全形冒號等
```
▸標籤管理實作
▸PDF抽取方法實驗及整理
▸s2orc-doc2json、 grobid
▸文獻閱讀: Too many tags spoil the metadata: investigating the knowledge management of scientific research with semantic web technologies(2019)
▸其他: 冒號問題
```

==問題==
根據上文，如何解決論文標題中的冒號問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.1906288
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md\n# 3. 除了降噪外其他可能影響語音識別的因素\n#靈感/語音識別\n1. 聲道\n2. 取樣率\n3. 語速\n4. bit率', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md', '標題1': '3. 除了降噪外其他可能影響語音識別的因素'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

==問題==
根據上文，哪些因素可能會影響語音識別的準確度?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16114116
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md\n# 999. 靈感\n- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  \n[^1]: https://ithelp.ithome.com.tw/articles/10340284\n[^2]: https://github.com/huggingface/text-generation-inference/issues/1201', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-05-10.md', '標題1': '999. 靈感'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-05-10.md
# 999. 靈感
- 指令微調針對聊天做過微調，也許針對基座模型做RAG微調的效果也會不錯？  
[^1]: https://ithelp.ithome.com.tw/articles/10340284
[^2]: https://github.com/huggingface/text-generation-inference/issues/1201

==問題==
根據上文，如何微調whisper?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.106168725
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-10-03.md\n# 2. 重新點一次view裡面的顯示prefix才能正常顯示', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-10-03.md', '標題1': '2. 重新點一次view裡面的顯示prefix才能正常顯示'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-10-03.md
# 2. 重新點一次view裡面的顯示prefix才能正常顯示

==問題==
根據上文，如何解決protégé中的顯示問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2692792
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-16.md\n`mklink "E:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin\\make.exe" "E:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin\\mingw32-make.exe"`\n- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`\n- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性\n- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要\n- [ ] 整理文獻\n- [ ] 閱讀清單', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-16.md', '標題1': '0. 今日計畫'})]
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 53%|█████▎    | 19/36 [03:24<03:01, 10.70s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 56%|█████▌    | 20/36 [03:37<03:01, 11.37s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 58%|█████▊    | 21/36 [03:47<02:44, 10.93s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 61%|██████    | 22/36 [04:00<02:42, 11.58s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 64%|██████▍   | 23/36 [04:12<02:30, 11.58s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 67%|██████▋   | 24/36 [04:23<02:18, 11.51s/it]Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-16.md
`mklink "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\make.exe" "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\mingw32-make.exe"`
- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`
- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性
- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要
- [ ] 整理文獻
- [ ] 閱讀清單

==問題==
根據上文，為甚麼系統要使用多執行緒?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.008740316
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-15.md\n- 感覺不是純粹切視窗或關視窗的問題，也許跟省電或其他的websocket管理有關', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-15.md', '標題1': '1. 修復匯出摘錄時會用到之前資料的問題'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-15.md
- 感覺不是純粹切視窗或關視窗的問題，也許跟省電或其他的websocket管理有關

==問題==
根據上文，service worker幾秒後會自動關閉?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.19715488
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-28.md\n# 9. 關於chrome-extension中不允許在html中直接呼叫javascript函數\n- 因為chrome-extension不允許CSP\n- 但好像可以用[這個](https://stackoverflow.com/questions/72186787/chrome-extensions-and-csp)允許特定網站的CSP?', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-28.md', '標題1': '9. 關於chrome-extension中不允許在html中直接呼叫javascript函數'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-28.md
# 9. 關於chrome-extension中不允許在html中直接呼叫javascript函數
- 因為chrome-extension不允許CSP
- 但好像可以用[這個](https://stackoverflow.com/questions/72186787/chrome-extensions-and-csp)允許特定網站的CSP?

==問題==
根據上文，為什麼chrome-extension不能在html中直接呼叫javascript函數
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.109264515
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-13.md\n# 4. 閱讀論文\n- 在這篇[^4] 論文中提到，實驗中為了在最小化幻覺和嚴格生成之間取得平衡，將GPT的溫度設為0，llama的溫度設為0.1，但論文中未提及更詳細的理由', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-13.md', '標題1': '4. 閱讀論文'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-13.md
# 4. 閱讀論文
- 在這篇[^4] 論文中提到，實驗中為了在最小化幻覺和嚴格生成之間取得平衡，將GPT的溫度設為0，llama的溫度設為0.1，但論文中未提及更詳細的理由

==問題==
根據上文，ChatGPT的溫度設為多少最恰當?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.20829745
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-22.md\n# 999. 其他\n- How can we evaluate the ability of each LLM to generate Cypher?\n- tag嵌套的必要性\n- markdown的結構化 #靈感\n- 例如tab代表有\n- 可能要重新考慮nDCG來比對[[Embeddeding|嵌入]]結果\n- 可能要檢查 [[Mean Average Precision|MAP]] 的算法是否有誤\n- 以前不熟悉的關鍵字會慢慢熟悉，要怎麼應對這種情況? #靈感\n[^1]: https://github.com/microsoft/terminal/issues/14018\n[^2]: https://stackoverflow.com/questions/32127524/how-to-install-and-use-make-in-windows', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-22.md', '標題1': '999. 其他'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-22.md
# 999. 其他
- How can we evaluate the ability of each LLM to generate Cypher?
- tag嵌套的必要性
- markdown的結構化 #靈感
- 例如tab代表有
- 可能要重新考慮nDCG來比對[[Embeddeding|嵌入]]結果
- 可能要檢查 [[Mean Average Precision|MAP]] 的算法是否有誤
- 以前不熟悉的關鍵字會慢慢熟悉，要怎麼應對這種情況? #靈感
[^1]: https://github.com/microsoft/terminal/issues/14018
[^2]: https://stackoverflow.com/questions/32127524/how-to-install-and-use-make-in-windows

==問題==
根據上文，嵌入有可能遇到什麼問題?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.090603866
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-16.md\n# 1. [[Whisper]]\n嘗試解決幻覺問題\nhttps://github.com/openai/whisper/discussions/679\n加上參數--condition_on_previous_text False  \n##  評估方式?\n根據不同面向，例如冗字、專有名詞，其他錯誤等  \n又加了一堆論文哈哈', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-16.md', '標題1': '1. [[Whisper]]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-16.md
# 1. [[Whisper]]
嘗試解決幻覺問題
https://github.com/openai/whisper/discussions/679
加上參數--condition_on_previous_text False  
##  評估方式?
根據不同面向，例如冗字、專有名詞，其他錯誤等  
又加了一堆論文哈哈

==問題==
根據上文，有哪些方法可以解決語音辨識的幻聽問題
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.16820273
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md\n# 3. 除了降噪外其他可能影響語音識別的因素\n#靈感/語音識別\n1. 聲道\n2. 取樣率\n3. 語速\n4. bit率', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md', '標題1': '3. 除了降噪外其他可能影響語音識別的因素'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

==問題==
根據上文，語音辨識可以有哪些評估的方向
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.071613215
float32
D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 69%|██████▉   | 25/36 [04:41<02:26, 13.32s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 72%|███████▏  | 26/36 [04:50<02:01, 12.18s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 75%|███████▌  | 27/36 [05:01<01:46, 11.86s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 78%|███████▊  | 28/36 [05:08<01:22, 10.31s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 81%|████████  | 29/36 [05:18<01:12, 10.33s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 83%|████████▎ | 30/36 [05:29<01:02, 10.49s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 86%|████████▌ | 31/36 [05:36<00:46,  9.39s/it][Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md\n# 3. 關於瀏覽器插件的溝通方式選擇\npipe or websocket\n選擇websocket，因為javascript無法操作作業系統層級的pipe\n查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe\n理論上也確實如此，否則瀏覽器插件的權限很容易太大', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-20.md', '標題1': '3. 關於瀏覽器插件的溝通方式選擇'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-20.md
# 3. 關於瀏覽器插件的溝通方式選擇
pipe or websocket
選擇websocket，因為javascript無法操作作業系統層級的pipe
查不太到實際說明，但參考[^1] ，看起來必須通過node.js才能使JS使用OS層級的pipe
理論上也確實如此，否則瀏覽器插件的權限很容易太大

==問題==
根據上文，為什麼瀏覽器插件不使用pipe?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.2258542
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md\n# 3. 除了降噪外其他可能影響語音識別的因素\n#靈感/語音識別\n1. 聲道\n2. 取樣率\n3. 語速\n4. bit率', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-22.md', '標題1': '3. 除了降噪外其他可能影響語音識別的因素'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-22.md
# 3. 除了降噪外其他可能影響語音識別的因素
#靈感/語音識別
1. 聲道
2. 取樣率
3. 語速
4. bit率

==問題==
根據上文，哪些因素可能會影響語音識別？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.26710048
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-30.md\n# 3. 將宿舍電腦的 StableDiffusion 虛擬環境中的 [[pytorch]] 更新到pytorch2[^1]\n1. 切換到虛擬環境\n`.\\envs\\scripts\\activate.bat`\n2. 檢查pip路徑\n`pip --version`\n3. 參考[官網](https://pytorch.org/get-started/locally/)訊息，CUDA11.8\n`pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`\n4. 結果\n```\nInstalling collected packages: mpmath, sympy, torch, torchvision, torchaudio\nAttempting uninstall: torch\nFound existing installation: torch 1.13.1+cu117', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-30.md', '標題1': '3. 將宿舍電腦的 StableDiffusion 虛擬環境中的 [[pytorch]] 更新到pytorch2[^1]'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-30.md
# 3. 將宿舍電腦的 StableDiffusion 虛擬環境中的 [[pytorch]] 更新到pytorch2[^1]
1. 切換到虛擬環境
`.\envs\scripts\activate.bat`
2. 檢查pip路徑
`pip --version`
3. 參考[官網](https://pytorch.org/get-started/locally/)訊息，CUDA11.8
`pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`
4. 結果
```
Installing collected packages: mpmath, sympy, torch, torchvision, torchaudio
Attempting uninstall: torch
Found existing installation: torch 1.13.1+cu117

==問題==
根據上文，我參考了哪個教學將pytorch更新到pytorch2?
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.3263341
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-11-15.md\n# 1. 考慮和 [[EndNote]] 連動的可能性\n- [[websocket]] 攔截\n- [[RIS]] 等引用文件\n- 文獻清單\n- 其實 [[Bibtex]] 應該更適合作為相容性最好的引用格式而非[[RIS]]', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-11-15.md', '標題1': '1. 考慮和 [[EndNote]] 連動的可能性'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-11-15.md
# 1. 考慮和 [[EndNote]] 連動的可能性
- [[websocket]] 攔截
- [[RIS]] 等引用文件
- 文獻清單
- 其實 [[Bibtex]] 應該更適合作為相容性最好的引用格式而非[[RIS]]

==問題==
根據上文，bibtex和ris差在哪？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.4384315
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-11-23.md\n# 2. 研究過程中，除了這個研究的貢獻外，在相關研究中也可以得到很多資訊\n可以在筆記中包含，提到這篇研究的研究、該研究中的說明、評價、引用編號等\n#靈感', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-11-23.md', '標題1': '2. 研究過程中，除了這個研究的貢獻外，在相關研究中也可以得到很多資訊'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-11-23.md
# 2. 研究過程中，除了這個研究的貢獻外，在相關研究中也可以得到很多資訊
可以在筆記中包含，提到這篇研究的研究、該研究中的說明、評價、引用編號等
#靈感

==問題==
根據上文，可以從論文的相關研究中得到什麼？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.44338506
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-04.md\n# 5. 土豆挑戰', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-04.md', '標題1': '5. 土豆挑戰'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-04.md
# 5. 土豆挑戰

==問題==
根據上文，土豆挑戰是什麼？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.1314348
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-12-08.md\n# 1. 撰寫chrome extension\n- 關於popus.js和background.js的溝通\n- 遇到錯誤 `Unchecked runtime.lastError: The message port closed before a response was received.`\n- 經過正確的使用sendmessage的callback的第三個參數sendResponse完成完整的溝通。\n- 準確的說是service-worker，因為在版本三中並沒有background page的存在，而是改為service worker。\n- 同上，有很多用法在第二版可以用，但在第三版不能用。', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-12-08.md', '標題1': '1. 撰寫chrome extension'})]
format後的prompt: D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 89%|████████▉ | 32/36 [05:44<00:35,  8.87s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 92%|█████████▏| 33/36 [05:55<00:28,  9.53s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 94%|█████████▍| 34/36 [06:02<00:17,  8.77s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

 97%|█████████▋| 35/36 [06:08<00:07,  7.93s/it]D:\ProgramData\Anaconda3\envs\server\Lib\site-packages\langchain_core\utils\utils.py:161: UserWarning: WARNING! seed is not default parameter.
                seed was transferred to model_kwargs.
                Please confirm that seed is what you intended.
  warnings.warn(

100%|██████████| 36/36 [06:16<00:00,  8.07s/it]
100%|██████████| 36/36 [06:16<00:00, 10.46s/it]
Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-12-08.md
# 1. 撰寫chrome extension
- 關於popus.js和background.js的溝通
- 遇到錯誤 `Unchecked runtime.lastError: The message port closed before a response was received.`
- 經過正確的使用sendmessage的callback的第三個參數sendResponse完成完整的溝通。
- 準確的說是service-worker，因為在版本三中並沒有background page的存在，而是改為service worker。
- 同上，有很多用法在第二版可以用，但在第三版不能用。

==問題==
根據上文，如何解決The message port closed before a response was received
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.062017523
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2023-09-04.md\n# [[SpeechBrain]]測試\n1. 新增[[conda]]虛擬環境後安裝相依套件，按照官方說明\n``` console\nconda install pip\ngit clone https://github.com/speechbrain/speechbrain/\ncd /content/speechbrain/\npip install -r requirements.txt\npip install -e .\n```', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2023-09-04.md', '標題1': '[[SpeechBrain]]測試'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2023-09-04.md
# [[SpeechBrain]]測試
1. 新增[[conda]]虛擬環境後安裝相依套件，按照官方說明
``` console
conda install pip
git clone https://github.com/speechbrain/speechbrain/
cd /content/speechbrain/
pip install -r requirements.txt
pip install -e .
```

==問題==
根據上文，哪些python套件能監聽快捷鍵？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.2724631
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-16.md\n`mklink "E:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin\\make.exe" "E:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin\\mingw32-make.exe"`\n- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`\n- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性\n- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要\n- [ ] 整理文獻\n- [ ] 閱讀清單', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-16.md', '標題1': '0. 今日計畫'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-16.md
`mklink "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\make.exe" "E:\Program Files\mingw-w64\x86_64-8.1.0-posix-seh-rt_v6-rev0\mingw64\bin\mingw32-make.exe"`
- `poetry install --extras "ui llms-openai llms-openai-like embeddings-huggingface vector-stores-chroma"`
- 考慮到不熟悉poetry，且該專案提供的功能包含客製化LLM設定等，並不是沒有可取代性
- 關於設定、prompt等可在系統中參考[^5]，但沒有使用的必要
- [ ] 整理文獻
- [ ] 閱讀清單

==問題==
根據上文，除了pyqt外，當時還考慮哪些類似的套件？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.14854458
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-03-16.md\n# 999. 其他\n- 根據FastAPI的文檔，建議使用Union來取代Optional功能，但範例中有點錯誤\n- 建議避免使用 `name: Optional[str]`，因為實際上name並不是可選的而是必選的\n- 就算使用 `def say_hi(name: str | None)` 也不代表不需要參數，必須要設定初始值，如 `def say_hi(name: str | None = None)`  \n[^1]: https://stackoverflow.com/questions/63872924/how-can-i-send-an-http-request-from-my-fastapi-app-to-another-site-api\n[^2]: https://scrapfly.io/blog/httpx-vs-requests-vs-aiohttp/', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-03-16.md', '標題1': '999. 其他'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-03-16.md
# 999. 其他
- 根據FastAPI的文檔，建議使用Union來取代Optional功能，但範例中有點錯誤
- 建議避免使用 `name: Optional[str]`，因為實際上name並不是可選的而是必選的
- 就算使用 `def say_hi(name: str | None)` 也不代表不需要參數，必須要設定初始值，如 `def say_hi(name: str | None = None)`  
[^1]: https://stackoverflow.com/questions/63872924/how-can-i-send-an-http-request-from-my-fastapi-app-to-another-site-api
[^2]: https://scrapfly.io/blog/httpx-vs-requests-vs-aiohttp/

==問題==
根據上文，系統中的FastAPI監聽哪個端口？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
-0.28215396
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md\n# 3. 找到新關鍵字(ChatGPT)\n- Multi-Source Information Management\n- RALM，重要，需要了解具體定義及其與RAG的區別', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md', '標題1': '3. 找到新關鍵字(ChatGPT)'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

==問題==
根據上文，RALM類似什麼概念？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.04661884
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md\n# 3. 找到新關鍵字(ChatGPT)\n- Multi-Source Information Management\n- RALM，重要，需要了解具體定義及其與RAG的區別', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-10.md', '標題1': '3. 找到新關鍵字(ChatGPT)'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-10.md
# 3. 找到新關鍵字(ChatGPT)
- Multi-Source Information Management
- RALM，重要，需要了解具體定義及其與RAG的區別

==問題==
根據上文，多源資料分析和管理差在哪？
請用20個字簡潔回答問題。

嵌入模型載入中...
嵌入模型載入完成
{'max_length': 512, 'dim': 4096}
資料庫已存在
0.06321003
float32
[Document(page_content='來自筆記:E:\\Research\\ObsidianSync\\每日筆記\\2024-04-18.md\n[^10]: https://community.neo4j.com/t/import-individuals-and-relate-to-classes-in-neo4j/24567/2', metadata={'source': 'E:\\Research\\ObsidianSync\\每日筆記\\2024-04-18.md', '標題1': '999. 靈感'})]
format後的prompt: Human: 不要使用參考文獻以外的知識或資訊。若資訊不足請回答「資訊不足」。
==參考文獻==
來自筆記:E:\Research\ObsidianSync\每日筆記\2024-04-18.md
[^10]: https://community.neo4j.com/t/import-individuals-and-relate-to-classes-in-neo4j/24567/2

==問題==
根據上文，在2024/4/17，我看完NEUMAI了嗎？
請用20個字簡潔回答問題。

